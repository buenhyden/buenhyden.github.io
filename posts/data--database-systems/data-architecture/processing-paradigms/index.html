<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Processing Types | hyunyoun's Blog</title><meta name=keywords content="Software-Engineering,Design-and-Architecture,Architecture-Styles-and-Patterns,Architecture-Styles,Data-Flow,Processing-Types,Batch-Processing,Stream-Processing,Hybrid-Processing"><meta name=description content="Batch Processing(배치 처리), Hybrid Processing(하이브리드 처리), Stream Processing(스트림 처리) 은 데이터 처리의 대표적인 방식이다. 배치 처리는 대용량 데이터를 일괄 처리하며, 스트림 처리는 실시간 데이터를 즉시 처리한다. 하이브리드 처리는 두 방식을 결합해 실시간성과 정확성을 동시에 추구한다."><meta name=author content="Me"><link rel=canonical href=https://buenhyden.github.io/posts/data--database-systems/data-architecture/processing-paradigms/><meta name=google-site-verification content="googlee06938ebbfcbac49.html"><link crossorigin=anonymous href=/assets/css/stylesheet.8762af4fa9ee176c57f72565b721f234162fc7a9c882a271e0a1f68c4e89fb34.css integrity="sha256-h2KvT6nuF2xX9yVltyHyNBYvx6nIgqJx4KH2jE6J+zQ=" rel="preload stylesheet" as=style><link rel=icon href=https://buenhyden.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://buenhyden.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://buenhyden.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://buenhyden.github.io/posts/data--database-systems/data-architecture/processing-paradigms/index.xml><link rel=alternate hreflang=en href=https://buenhyden.github.io/posts/data--database-systems/data-architecture/processing-paradigms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3156423099418350" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W8XTMYPTLC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W8XTMYPTLC")}</script><meta property="og:url" content="https://buenhyden.github.io/posts/data--database-systems/data-architecture/processing-paradigms/"><meta property="og:site_name" content="hyunyoun's Blog"><meta property="og:title" content="Processing Types"><meta property="og:description" content="Batch Processing(배치 처리), Hybrid Processing(하이브리드 처리), Stream Processing(스트림 처리) 은 데이터 처리의 대표적인 방식이다. 배치 처리는 대용량 데이터를 일괄 처리하며, 스트림 처리는 실시간 데이터를 즉시 처리한다. 하이브리드 처리는 두 방식을 결합해 실시간성과 정확성을 동시에 추구한다."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://buenhyden.github.io/images"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://buenhyden.github.io/images"><meta name=twitter:title content="Processing Types"><meta name=twitter:description content="Batch Processing(배치 처리), Hybrid Processing(하이브리드 처리), Stream Processing(스트림 처리) 은 데이터 처리의 대표적인 방식이다. 배치 처리는 대용량 데이터를 일괄 처리하며, 스트림 처리는 실시간 데이터를 즉시 처리한다. 하이브리드 처리는 두 방식을 결합해 실시간성과 정확성을 동시에 추구한다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"HY's Blog","item":"https://buenhyden.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Processing Types","item":"https://buenhyden.github.io/posts/data--database-systems/data-architecture/processing-paradigms/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://buenhyden.github.io/ accesskey=h title="Hy's Blog (Alt + H)"><img src=https://buenhyden.github.io/favicons/apple-touch-icon.png alt aria-label=logo height=35>Hy's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://buenhyden.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://buenhyden.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://buenhyden.github.io/til/ title="Today I Learned"><span>Today I Learned</span></a></li><li><a href=https://buenhyden.github.io/coding-test/ title="Coding Test"><span>Coding Test</span></a></li><li><a href=https://buenhyden.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://buenhyden.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://buenhyden.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://buenhyden.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/>HY's Blog</a></div><h1>Processing Types</h1><div class=post-description>Batch Processing(배치 처리), Hybrid Processing(하이브리드 처리), Stream Processing(스트림 처리) 은 데이터 처리의 대표적인 방식이다. 배치 처리는 대용량 데이터를 일괄 처리하며, 스트림 처리는 실시간 데이터를 즉시 처리한다. 하이브리드 처리는 두 방식을 결합해 실시간성과 정확성을 동시에 추구한다.</div></header><div class=post-content><h2 id=processing-types>Processing Types<a hidden class=anchor aria-hidden=true href=#processing-types>#</a></h2><p>데이터 처리 방식은 시스템의 요구 사항에 따라 배치 (Batch), 스트림 (Stream), 하이브리드 (Hybrid) 로 구분된다. Batch Processing 은 데이터의 대량 집계와 정확성에 적합하고, Stream Processing 은 실시간 응답성과 낮은 지연 시간에 유리하다. Hybrid Processing 은 Lambda Architecture 처럼 두 방식을 조합해 실시간성과 정확성을 모두 확보하려는 전략이다. 각각은 처리량, 지연 시간, 아키텍처 복잡도 등에서 상호 보완적이며, 시스템 목적에 따라 선택 또는 병행된다.</p><h3 id=핵심-개념>핵심 개념<a hidden class=anchor aria-hidden=true href=#핵심-개념>#</a></h3><ul><li><strong>Batch</strong>는 대용량 데이터를 정확하게 처리하고, 일정 간격으로 분석과 보고서를 생성하는 데 적합하다.</li><li><strong>Stream</strong>은 지연 없이 이벤트를 실시간 처리하고, 즉시 반응해야 하는 시스템에 사용된다.</li><li><strong>Hybrid</strong>는 두 방식의 강점을 조합하여, <strong>실시간성과 정합성</strong>이 모두 중요한 복잡한 비즈니스 도메인에서 사용된다.<br>예: <strong>이상 탐지, 실시간 사용자 분석, 추천 시스템 등</strong>.</li></ul><table><thead><tr><th>구분</th><th>Batch Processing</th><th>Stream Processing</th><th>Hybrid Processing</th></tr></thead><tbody><tr><td><strong>정의</strong></td><td>일정량의 데이터를 모아서 일괄 처리</td><td>데이터가 생성되는 즉시 실시간으로 처리</td><td>배치와 스트림 방식을 병행하여 처리</td></tr><tr><td><strong>지향점</strong></td><td><strong>정확성</strong>, <strong>정합성</strong> 중심</td><td><strong>실시간성</strong>, <strong>즉시 반응</strong> 중심</td><td><strong>정확성과 실시간성의 균형</strong></td></tr><tr><td><strong>처리 방식</strong></td><td>고정 주기 실행 (예: 하루 1 회)</td><td>이벤트 기반으로 연속 처리</td><td>배치 레이어 + 스피드 레이어 (Lambda) / 통합 레이어 (Kappa)</td></tr><tr><td><strong>주요 특징</strong></td><td>지연 허용, 대용량 처리, 분석 최적화</td><td>낮은 지연, 빠른 대응, 상태 기반 처리 가능</td><td>복합적 요구 대응, 운영 복잡도 증가</td></tr><tr><td><strong>활용 분야</strong></td><td>리포트 생성, ETL, 통계 분석</td><td>실시간 알림, 이상 탐지, 모니터링</td><td>금융 거래 분석, 사용자 행동 예측, 마케팅 실시간 반응 시스템 등</td></tr></tbody></table><h4 id=실무-기술-스택-매핑>실무 기술 스택 매핑<a hidden class=anchor aria-hidden=true href=#실무-기술-스택-매핑>#</a></h4><table><thead><tr><th>구성 요소</th><th>Batch</th><th>Stream</th><th>Hybrid (Lambda/Kappa)</th></tr></thead><tbody><tr><td><strong>엔진</strong></td><td>Apache Spark, Hadoop MapReduce, Hive</td><td>Apache Flink, Kafka Streams, Spark Streaming</td><td>Lambda: Spark + Storm / Kappa: Flink 단독 사용</td></tr><tr><td><strong>메시징 시스템</strong></td><td>Kafka, Amazon Kinesis</td><td>Kafka, Pulsar, RabbitMQ</td><td>Kafka (공통 메시지 버퍼링), Kinesis</td></tr><tr><td><strong>저장소</strong></td><td>HDFS, Amazon S3, RDBMS</td><td>NoSQL, Elasticsearch, Redis</td><td>데이터 레이크 + 실시간 인덱싱 레이어</td></tr><tr><td><strong>스케줄링</strong></td><td>Airflow, Oozie</td><td>Kafka Consumer, Flink Job</td><td>조합: Airflow + Flink / Kappa 구조에서는 Flink 단독 사용</td></tr><tr><td><strong>서빙 레이어</strong></td><td>Presto, Druid, BI 도구</td><td>Redis, Elasticsearch</td><td>Redis + Druid/ES 통합 서빙</td></tr></tbody></table><h4 id=실무-적용-사례-및-고려-사항>실무 적용 사례 및 고려 사항<a hidden class=anchor aria-hidden=true href=#실무-적용-사례-및-고려-사항>#</a></h4><table><thead><tr><th>구분</th><th>적용 사례</th><th>처리 우선순위</th><th>적합성 설명</th></tr></thead><tbody><tr><td><strong>Batch</strong></td><td>월간 리포트 생성, 로그 정제 및 보관</td><td>정합성 우선</td><td>대량 데이터 처리에 적합하며, 처리 지연 허용 가능</td></tr><tr><td><strong>Stream</strong></td><td>실시간 트래픽 분석, 센서 데이터 모니터링</td><td>반응 속도 우선</td><td>지연이 적고 상태 기반 처리가 필요한 실시간 이벤트 처리에 적합</td></tr><tr><td><strong>Hybrid</strong></td><td>광고 클릭 분석, 이상 금융 거래 탐지</td><td>정합성 + 실시간성</td><td>정확성과 즉시 반응이 동시에 필요한 복합적 시스템에 최적화</td></tr></tbody></table><h4 id=하위-처리-기준-비교>하위 처리 기준 비교<a hidden class=anchor aria-hidden=true href=#하위-처리-기준-비교>#</a></h4><table><thead><tr><th>기준</th><th>Batch</th><th>Stream</th><th>Hybrid</th></tr></thead><tbody><tr><td><strong>지연 허용 여부</strong></td><td>있음 (분 ~ 시 단위)</td><td>없음 (ms ~ s 단위)</td><td>부분 허용</td></tr><tr><td><strong>정확성</strong></td><td>✅</td><td>❌</td><td>✅</td></tr><tr><td><strong>실시간성</strong></td><td>❌</td><td>✅</td><td>✅</td></tr><tr><td><strong>구현 복잡도</strong></td><td>낮음</td><td>보통</td><td>높음</td></tr><tr><td><strong>운영 복잡도</strong></td><td>단순</td><td>보통</td><td>복잡</td></tr></tbody></table><h4 id=아키텍처-연계-요약>아키텍처 연계 요약<a hidden class=anchor aria-hidden=true href=#아키텍처-연계-요약>#</a></h4><table><thead><tr><th>처리 방식</th><th>연계 아키텍처</th><th>설명</th></tr></thead><tbody><tr><td>Batch</td><td>ETL Pipeline, Data Warehouse</td><td>데이터 수집 → 변환 → 적재 → 분석 (정기적 리포트 등)</td></tr><tr><td>Stream</td><td>Event-Driven, Reactive</td><td>실시간 이벤트 수신 및 처리, CEP 등 이벤트 흐름 중심 구조</td></tr><tr><td>Hybrid</td><td>Lambda, Kappa Architecture</td><td>Lambda: 배치 + 스피드 레이어 / Kappa: 단일 스트림 기반 배치 + 실시간 통합 구조</td></tr></tbody></table><h3 id=batch-processing-vs-stream-processing-vs-hybrid-processing-비교>Batch Processing vs. Stream Processing vs. Hybrid Processing 비교<a hidden class=anchor aria-hidden=true href=#batch-processing-vs-stream-processing-vs-hybrid-processing-비교>#</a></h3><p>각 처리 방식은 데이터의 시간적 특성과 비즈니스 요구사항에 따라 선택된다. 배치 처리는 정확성과 효율성을, 스트림 처리는 실시간성과 반응성을, 하이브리드 처리는 두 방식의 균형을 추구한다.</p><table><thead><tr><th>구분</th><th>Batch Processing</th><th>Stream Processing</th><th>Hybrid Processing</th></tr></thead><tbody><tr><td><strong>정의</strong></td><td>데이터를 일정 시간 단위로 일괄 처리</td><td>이벤트가 발생하는 즉시 데이터를 처리</td><td>배치와 스트림을 결합하여 필요에 따라 병행 처리</td></tr><tr><td><strong>데이터 처리 단위</strong></td><td>파일, 레코드 집합, 배치 단위</td><td>개별 이벤트, 메시지</td><td>배치 + 스트림 (이중 경로 또는 통합 경로)</td></tr><tr><td><strong>지연 시간 (Latency)</strong></td><td>수 분 ~ 수 시간 수준</td><td>수 밀리초 ~ 수 초 수준</td><td>상황에 따라 조절 가능 (실시간 + 정합성 보완)</td></tr><tr><td><strong>정확성 보장</strong></td><td>높음 (완전한 데이터 기반, 중복 제거 용이)</td><td>낮음/중간 (중복 처리, 지연 데이터 문제 발생 가능)</td><td>높음 (정확성 요구 처리는 배치로 보완)</td></tr><tr><td><strong>시스템 복잡성</strong></td><td>상대적으로 단순 (단일 파이프라인, 순차 처리)</td><td>복잡 (상태 관리, 시간 윈도우, 백프레셔 등)</td><td>가장 복잡 (2 가지 처리 방식 병행, 아키텍처 설계 중요)</td></tr><tr><td><strong>운영 효율성</strong></td><td>주기적 실행으로 운영 예측 용이</td><td>지속 실행, 운영자 개입 빈도 높음</td><td>자동화 없이는 운영 부담 높음</td></tr><tr><td><strong>확장성</strong></td><td>수평 확장 쉬움 (Spark, MapReduce 등 지원)</td><td>고난이도 (상태 공유, Backpressure 등 관리 필요)</td><td>스트림 처리 확장을 위한 추가 설계 필요</td></tr><tr><td><strong>데이터 일관성</strong></td><td>강한 일관성 확보 가능 (ACID 기반 설계 용이)</td><td>약한 일관성 (Eventually Consistent or At-least-once)</td><td>CQRS, 이벤트 소싱, 보상 트랜잭션 등 필요</td></tr><tr><td><strong>장애 대응력</strong></td><td>체크포인트 및 재실행 용이</td><td>복잡한 복구 메커니즘 필요 (Offset, State, Watermark 등)</td><td>복합적인 장애 처리 체계 요구</td></tr><tr><td><strong>사용 사례</strong></td><td>리포팅, 데이터 웨어하우징, 오프라인 ML 학습</td><td>IoT 센서 처리, 실시간 알림, Fraud Detection</td><td>실시간 모니터링 + 백데이터 정합성 확보가 필요한 서비스</td></tr><tr><td><strong>대표 기술 스택</strong></td><td>Spark, Hadoop, AWS Glue, Airflow</td><td>Apache Flink, Kafka Streams, NiFi</td><td>Lambda/Kappa Architecture, Spark+Flink, Flink Reprocessing</td></tr><tr><td><strong>코스트 효율성</strong></td><td>저비용 (스팟 인스턴스, 야간 처리 등 활용 가능)</td><td>고비용 (상시 실행, 메모리/CPU 소비 큼)</td><td>구조 설계에 따라 비용 급증 또는 절감 가능</td></tr><tr><td><strong>성능 최적화 포인트</strong></td><td>병렬 처리, 파티셔닝, 스케줄링 최적화</td><td>윈도우 크기 조정, 워터마크 튜닝, 백프레셔 제어</td><td>흐름 제어, 경로 분기, Serving Layer 최적화</td></tr><tr><td><strong>패턴/아키텍처</strong></td><td>Batch Sequential, Pipe-and-Filter</td><td>Stream Dataflow, Stateful Pipeline</td><td>Lambda, Kappa, Micro-Batch</td></tr></tbody></table><h4 id=강점>강점<a hidden class=anchor aria-hidden=true href=#강점>#</a></h4><table><thead><tr><th>비교 항목</th><th>배치 처리 강점</th><th>스트림 처리 강점</th><th>하이브리드 처리 강점</th></tr></thead><tbody><tr><td><strong>처리 효율성</strong></td><td>높은 처리량, 리소스 효율성</td><td>낮은 지연시간, 즉시 반응</td><td>요구사항별 최적 방식 선택</td></tr><tr><td><strong>정확성</strong></td><td>완전한 데이터로 정확한 결과</td><td>부분 데이터로 근사 결과</td><td>배치로 정확성, 스트림으로 즉시성</td></tr><tr><td><strong>복잡성</strong></td><td>단순한 아키텍처</td><td>중간 수준 복잡성</td><td>높은 복잡성</td></tr><tr><td><strong>비용</strong></td><td>낮은 인프라 비용</td><td>높은 실시간 처리 비용</td><td>중간 수준 비용</td></tr></tbody></table><h4 id=약점>약점<a hidden class=anchor aria-hidden=true href=#약점>#</a></h4><table><thead><tr><th>비교 항목</th><th>배치 처리 약점</th><th>스트림 처리 약점</th><th>하이브리드 처리 약점</th></tr></thead><tbody><tr><td><strong>실시간성</strong></td><td>높은 지연시간</td><td>상태 관리 복잡성</td><td>일관성 관리 어려움</td></tr><tr><td><strong>유연성</strong></td><td>낮은 실시간 대응력</td><td>제한적 히스토리 분석</td><td>중복 로직 유지 필요</td></tr><tr><td><strong>장애 처리</strong></td><td>배치 실패 시 재처리 부담</td><td>메시지 손실 가능성</td><td>다중 레이어 장애 처리</td></tr></tbody></table><h4 id=구조-및-아키텍처>구조 및 아키텍처<a hidden class=anchor aria-hidden=true href=#구조-및-아키텍처>#</a></h4><p>아래 다이어그램은 각 처리 방식의 데이터 흐름과 구조를 시각적으로 보여준다.</p><pre class=mermaid>flowchart TD
    subgraph Batch Processing
        A1[데이터 수집]
        A2[일괄 처리]
        A3[결과 저장 및 제공]
        A1 --&gt; A2 --&gt; A3
    end

    subgraph Hybrid Processing
        B1[데이터 수집]
        B2[배치 처리]
        B3[스트림 처리]
        B4[결과 통합 및 제공]
        B1 --&gt; B2
        B1 --&gt; B3
        B2 --&gt; B4
        B3 --&gt; B4
    end

    subgraph Stream Processing
        C1[데이터 수집]
        C2[실시간 처리]
        C3[결과 저장 및 제공]
        C1 --&gt; C2 --&gt; C3
    end
</pre><ul><li><strong>배치 처리</strong>: 데이터를 모아 일괄 처리, 결과 저장.</li><li><strong>하이브리드 처리</strong>: 데이터가 동시에 배치와 스트림 경로로 전달, 결과를 통합.</li><li><strong>스트림 처리</strong>: 데이터가 발생 즉시 실시간 처리.</li></ul><h5 id=구성-요소>구성 요소<a hidden class=anchor aria-hidden=true href=#구성-요소>#</a></h5><table><thead><tr><th>구성 요소</th><th>Batch Processing</th><th>Stream Processing</th><th>Hybrid Processing (Lambda 등)</th></tr></thead><tbody><tr><td>데이터 소스</td><td>DB, 로그, 파일</td><td>이벤트 스트림 (Kafka, MQTT 등)</td><td>이벤트 + 배치 대상</td></tr><tr><td>처리 엔진</td><td>Spark, Hadoop</td><td>Flink, Kafka Streams</td><td>Spark + Flink / Storm</td></tr><tr><td>저장소</td><td>DWH, RDBMS, S3</td><td>Redis, Elastic, Cassandra</td><td>HBase, Druid, 통합 DB</td></tr><tr><td>스케줄러</td><td>Airflow, Cron</td><td>지속 실행 or Trigger 기반</td><td>Batch: 주기 실행 / Stream: 지속 실행</td></tr><tr><td>사용자 응답계층</td><td>BI 도구, Data Studio</td><td>실시간 대시보드, Alert</td><td>응답 인터페이스에서 통합된 결과 제공</td></tr></tbody></table><h4 id=작동-원리-및-데이터-흐름>작동 원리 및 데이터 흐름<a hidden class=anchor aria-hidden=true href=#작동-원리-및-데이터-흐름>#</a></h4><ul><li><strong>Batch</strong>: 느리지만 강력한 집계/분석용 처리 방식, 대규모 로그 분석이나 ETL 에 적합</li><li><strong>Stream</strong>: 실시간 반응이 필요한 모니터링, 알림 시스템 등에 필수적이며, 상태 기반 처리가 핵심</li><li><strong>Hybrid</strong>: 실시간성과 정확성을 동시에 만족하고자 할 때, 아키텍처 복잡도가 높은 대신 유연한 처리 가능</li></ul><h5 id=batch-processing>Batch Processing<a hidden class=anchor aria-hidden=true href=#batch-processing>#</a></h5><pre class=mermaid>sequenceDiagram
    participant Source
    participant Collector
    participant BatchEngine
    participant Storage
    participant BI

    Source-&gt;&gt;Collector: Raw Data 수집 (Log, DB, File)
    Collector-&gt;&gt;BatchEngine: 주기적 전달
    BatchEngine-&gt;&gt;Storage: 결과 저장
    BI-&gt;&gt;Storage: 쿼리
</pre><hr><p><strong>배치 처리 작동 원리:</strong></p><ol><li><strong>데이터 축적</strong>: 일정 기간 동안 데이터 수집 및 저장</li><li><strong>배치 생성</strong>: 처리 단위로 데이터 그룹화</li><li><strong>병렬 처리</strong>: 다수 노드에서 동시 처리</li><li><strong>결과 통합</strong>: 개별 결과를 최종 결과로 병합</li><li><strong>결과 저장</strong>: 처리된 데이터를 목적지에 저장</li></ol><h5 id=stream-processing>Stream Processing<a hidden class=anchor aria-hidden=true href=#stream-processing>#</a></h5><pre class=mermaid>sequenceDiagram
    participant EventSource
    participant StreamProcessor
    participant Storage
    participant Dashboard

    EventSource-&gt;&gt;StreamProcessor: 실시간 이벤트 전송
    StreamProcessor-&gt;&gt;Storage: 처리 결과 저장
    Dashboard-&gt;&gt;Storage: 실시간 데이터 조회
</pre><hr><p><strong>스트림 처리 작동 원리:</strong></p><ol><li><strong>연속 수집</strong>: 실시간으로 데이터 스트림 수신</li><li><strong>윈도우 처리</strong>: 시간 또는 크기 기반 윈도우 적용</li><li><strong>상태 관리</strong>: 과거 이벤트 정보 유지 및 활용</li><li><strong>즉시 처리</strong>: 수신과 동시에 처리 로직 적용</li><li><strong>실시간 출력</strong>: 처리 결과 즉시 전달</li></ol><h5 id=hybrid-processing>Hybrid Processing<a hidden class=anchor aria-hidden=true href=#hybrid-processing>#</a></h5><pre class=mermaid>sequenceDiagram
    participant Source
    participant BatchLayer
    participant SpeedLayer
    participant Serving
    participant Client

    Source-&gt;&gt;BatchLayer: 주기적 배치 데이터 전달
    Source-&gt;&gt;SpeedLayer: 실시간 데이터 전달
    BatchLayer--&gt;&gt;Serving: 정확한 결과
    SpeedLayer--&gt;&gt;Serving: 실시간 결과
    Client-&gt;&gt;Serving: 통합 결과 요청
    Serving--&gt;&gt;Client: 응답
</pre><h3 id=구현-기법-비교>구현 기법 비교<a hidden class=anchor aria-hidden=true href=#구현-기법-비교>#</a></h3><table><thead><tr><th><strong>처리 방식</strong></th><th><strong>구현 기법</strong></th><th><strong>핵심 구성 요소</strong></th><th><strong>주요 목적</strong></th><th><strong>대표 예시</strong></th></tr></thead><tbody><tr><td><strong>Batch</strong></td><td>MapReduce</td><td>Mapper, Reducer, Shuffling</td><td>대규모 데이터 집계 및 분산 처리</td><td>Hadoop, Hive 로그 분석</td></tr><tr><td></td><td>Batch Window</td><td>시간/이벤트 기준 배치 윈도우</td><td>정해진 주기 데이터 처리</td><td>Spark Batch Job, Flume Sink</td></tr><tr><td></td><td>Micro-Batch</td><td>짧은 간격의 배치 윈도우 + 배치 엔진</td><td>배치와 실시간의 절충</td><td>Spark Streaming (DStream), Azure Stream Analytics</td></tr><tr><td><strong>Stream</strong></td><td>Event Time Processing</td><td>Timestamp, Watermark, Allowed Lateness</td><td>이벤트 발생 기준의 정확한 시간 처리</td><td>Flink Event Time 집계, 실시간 금융 거래 처리</td></tr><tr><td></td><td>Windowing (Tumbling/Sliding)</td><td>고정 또는 중첩된 시간창 (Fixed/Sliding Window)</td><td>시간 또는 이벤트 기준 집계</td><td>5 분 매출 집계, IoT 스트림 데이터</td></tr><tr><td></td><td>Stateful Processing</td><td>상태 저장소, State Backend, Checkpoint, Recovery</td><td>상태 기반 처리, 세션 집계, 중복 제거</td><td>Kafka Streams Session Store, Flink Keyed State</td></tr><tr><td></td><td>Backpressure Handling</td><td>Buffer, Flow Control, Async I/O</td><td>처리 속도 초과 제어 및 안정성 확보</td><td>Flink, Akka Streams</td></tr><tr><td><strong>Hybrid</strong></td><td>Lambda Architecture</td><td>Batch Layer + Speed Layer + Serving Layer</td><td>정확성 (배치) + 최신성 (실시간) 병행</td><td>Spark + Storm / Spark Streaming + Kafka</td></tr><tr><td></td><td>Kappa Architecture</td><td>단일 스트림 레이어 + Event Replay 기반 처리</td><td>단순화된 구조에서 재처리까지 일관성 처리</td><td>Kafka + Flink 기반 전체 파이프라인</td></tr><tr><td></td><td>Replay-Based Processing</td><td>Kafka Offset Reset, Stateless Processor</td><td>비즈니스 로직 변경 시 재처리 지원</td><td>모델 교체 후 전체 예측 재계산</td></tr><tr><td></td><td>Unified Stream-Batch Engine</td><td>Streaming-first 엔진에서 배치 지원 (Flink, Beam 등)</td><td>두 처리 방식의 일관된 실행 모델 구현</td><td>Flink Unified Pipeline, Apache Beam</td></tr></tbody></table><h4 id=실무적-고려-요소-포함>실무적 고려 요소 포함<a hidden class=anchor aria-hidden=true href=#실무적-고려-요소-포함>#</a></h4><table><thead><tr><th>구현 기법</th><th>실무 고려사항</th></tr></thead><tbody><tr><td>Micro-Batch</td><td>정확한 실시간성은 부족하나 운영이 용이하고 기존 배치 구조와의 호환성이 좋음</td></tr><tr><td>Event Time Processing</td><td>타임스탬프 신뢰도, 워터마크 설정 전략 등 운영 파라미터의 신중한 조정 필요</td></tr><tr><td>Stateful Processing</td><td>상태의 크기 증가와 복구 전략, 상태 저장소 구성 등 복잡한 운영 고려 필요</td></tr><tr><td>Replay-Based Processing</td><td>데이터 손실 없이 유연한 재처리 가능하나, 저장 비용 및 재처리 지연 시간 고려 필요</td></tr><tr><td>Lambda/Kappa 구조</td><td>장단점 명확, 목적에 따라 선택 필요 (정확성 우선이면 Lambda, 단순성 우선이면 Kappa)</td></tr></tbody></table><h4 id=batch-processing-1>Batch Processing<a hidden class=anchor aria-hidden=true href=#batch-processing-1>#</a></h4><h5 id=spark-batch-pyspark>Spark Batch (PySpark)<a hidden class=anchor aria-hidden=true href=#spark-batch-pyspark>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1> 1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2> 2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3> 3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4> 4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5> 5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6> 6</a>
</span><span class=lnt id=hl-4-7><a class=lnlinks href=#hl-4-7> 7</a>
</span><span class=lnt id=hl-4-8><a class=lnlinks href=#hl-4-8> 8</a>
</span><span class=lnt id=hl-4-9><a class=lnlinks href=#hl-4-9> 9</a>
</span><span class=lnt id=hl-4-10><a class=lnlinks href=#hl-4-10>10</a>
</span><span class=lnt id=hl-4-11><a class=lnlinks href=#hl-4-11>11</a>
</span><span class=lnt id=hl-4-12><a class=lnlinks href=#hl-4-12>12</a>
</span><span class=lnt id=hl-4-13><a class=lnlinks href=#hl-4-13>13</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>SparkSession</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Spark 세션 생성</span>
</span></span><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span><span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;BatchExample&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CSV 데이터 로드</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>csv</span><span class=p>(</span><span class=s2>&#34;data.csv&#34;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>inferSchema</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 그룹 집계</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=s2>&#34;category&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=s2>&#34;amount&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 결과 저장</span>
</span></span><span class=line><span class=cl><span class=n>result</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>csv</span><span class=p>(</span><span class=s2>&#34;output/result.csv&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=stream-processing-1>Stream Processing<a hidden class=anchor aria-hidden=true href=#stream-processing-1>#</a></h4><h5 id=kafka-소비--상태-관리-python--kafka-python--redis>Kafka 소비 + 상태 관리 (Python + Kafka-python + Redis)<a hidden class=anchor aria-hidden=true href=#kafka-소비--상태-관리-python--kafka-python--redis>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-5-1><a class=lnlinks href=#hl-5-1> 1</a>
</span><span class=lnt id=hl-5-2><a class=lnlinks href=#hl-5-2> 2</a>
</span><span class=lnt id=hl-5-3><a class=lnlinks href=#hl-5-3> 3</a>
</span><span class=lnt id=hl-5-4><a class=lnlinks href=#hl-5-4> 4</a>
</span><span class=lnt id=hl-5-5><a class=lnlinks href=#hl-5-5> 5</a>
</span><span class=lnt id=hl-5-6><a class=lnlinks href=#hl-5-6> 6</a>
</span><span class=lnt id=hl-5-7><a class=lnlinks href=#hl-5-7> 7</a>
</span><span class=lnt id=hl-5-8><a class=lnlinks href=#hl-5-8> 8</a>
</span><span class=lnt id=hl-5-9><a class=lnlinks href=#hl-5-9> 9</a>
</span><span class=lnt id=hl-5-10><a class=lnlinks href=#hl-5-10>10</a>
</span><span class=lnt id=hl-5-11><a class=lnlinks href=#hl-5-11>11</a>
</span><span class=lnt id=hl-5-12><a class=lnlinks href=#hl-5-12>12</a>
</span><span class=lnt id=hl-5-13><a class=lnlinks href=#hl-5-13>13</a>
</span><span class=lnt id=hl-5-14><a class=lnlinks href=#hl-5-14>14</a>
</span><span class=lnt id=hl-5-15><a class=lnlinks href=#hl-5-15>15</a>
</span><span class=lnt id=hl-5-16><a class=lnlinks href=#hl-5-16>16</a>
</span><span class=lnt id=hl-5-17><a class=lnlinks href=#hl-5-17>17</a>
</span><span class=lnt id=hl-5-18><a class=lnlinks href=#hl-5-18>18</a>
</span><span class=lnt id=hl-5-19><a class=lnlinks href=#hl-5-19>19</a>
</span><span class=lnt id=hl-5-20><a class=lnlinks href=#hl-5-20>20</a>
</span><span class=lnt id=hl-5-21><a class=lnlinks href=#hl-5-21>21</a>
</span><span class=lnt id=hl-5-22><a class=lnlinks href=#hl-5-22>22</a>
</span><span class=lnt id=hl-5-23><a class=lnlinks href=#hl-5-23>23</a>
</span><span class=lnt id=hl-5-24><a class=lnlinks href=#hl-5-24>24</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>kafka</span> <span class=kn>import</span> <span class=n>KafkaConsumer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>redis</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Kafka 소비자 설정</span>
</span></span><span class=line><span class=cl><span class=n>consumer</span> <span class=o>=</span> <span class=n>KafkaConsumer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;sensor-data&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bootstrap_servers</span><span class=o>=</span><span class=s1>&#39;localhost:9092&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>value_deserializer</span><span class=o>=</span><span class=k>lambda</span> <span class=n>m</span><span class=p>:</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Redis로 상태 저장</span>
</span></span><span class=line><span class=cl><span class=n>r</span> <span class=o>=</span> <span class=n>redis</span><span class=o>.</span><span class=n>StrictRedis</span><span class=p>(</span><span class=n>host</span><span class=o>=</span><span class=s1>&#39;localhost&#39;</span><span class=p>,</span> <span class=n>port</span><span class=o>=</span><span class=mi>6379</span><span class=p>,</span> <span class=n>db</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>message</span> <span class=ow>in</span> <span class=n>consumer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>message</span><span class=o>.</span><span class=n>value</span>
</span></span><span class=line><span class=cl>    <span class=n>sensor_id</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=s2>&#34;sensor_id&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>value</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s2>&#34;value&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Redis에 누적값 저장</span>
</span></span><span class=line><span class=cl>    <span class=n>prev</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>r</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>sensor_id</span><span class=p>)</span> <span class=ow>or</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>r</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>sensor_id</span><span class=p>,</span> <span class=n>prev</span> <span class=o>+</span> <span class=n>value</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Sensor </span><span class=si>{</span><span class=n>sensor_id</span><span class=si>}</span><span class=s2> Total: </span><span class=si>{</span><span class=n>prev</span> <span class=o>+</span> <span class=n>value</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=nodejs-스트림-처리-중첩-슬라이딩-윈도우>Node.js 스트림 처리 (중첩 슬라이딩 윈도우)<a hidden class=anchor aria-hidden=true href=#nodejs-스트림-처리-중첩-슬라이딩-윈도우>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-6-1><a class=lnlinks href=#hl-6-1> 1</a>
</span><span class=lnt id=hl-6-2><a class=lnlinks href=#hl-6-2> 2</a>
</span><span class=lnt id=hl-6-3><a class=lnlinks href=#hl-6-3> 3</a>
</span><span class=lnt id=hl-6-4><a class=lnlinks href=#hl-6-4> 4</a>
</span><span class=lnt id=hl-6-5><a class=lnlinks href=#hl-6-5> 5</a>
</span><span class=lnt id=hl-6-6><a class=lnlinks href=#hl-6-6> 6</a>
</span><span class=lnt id=hl-6-7><a class=lnlinks href=#hl-6-7> 7</a>
</span><span class=lnt id=hl-6-8><a class=lnlinks href=#hl-6-8> 8</a>
</span><span class=lnt id=hl-6-9><a class=lnlinks href=#hl-6-9> 9</a>
</span><span class=lnt id=hl-6-10><a class=lnlinks href=#hl-6-10>10</a>
</span><span class=lnt id=hl-6-11><a class=lnlinks href=#hl-6-11>11</a>
</span><span class=lnt id=hl-6-12><a class=lnlinks href=#hl-6-12>12</a>
</span><span class=lnt id=hl-6-13><a class=lnlinks href=#hl-6-13>13</a>
</span><span class=lnt id=hl-6-14><a class=lnlinks href=#hl-6-14>14</a>
</span><span class=lnt id=hl-6-15><a class=lnlinks href=#hl-6-15>15</a>
</span><span class=lnt id=hl-6-16><a class=lnlinks href=#hl-6-16>16</a>
</span><span class=lnt id=hl-6-17><a class=lnlinks href=#hl-6-17>17</a>
</span><span class=lnt id=hl-6-18><a class=lnlinks href=#hl-6-18>18</a>
</span><span class=lnt id=hl-6-19><a class=lnlinks href=#hl-6-19>19</a>
</span><span class=lnt id=hl-6-20><a class=lnlinks href=#hl-6-20>20</a>
</span><span class=lnt id=hl-6-21><a class=lnlinks href=#hl-6-21>21</a>
</span><span class=lnt id=hl-6-22><a class=lnlinks href=#hl-6-22>22</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-javascript data-lang=javascript><span class=line><span class=cl><span class=kr>const</span> <span class=p>{</span> <span class=nx>Transform</span> <span class=p>}</span> <span class=o>=</span> <span class=nx>require</span><span class=p>(</span><span class=s1>&#39;stream&#39;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>let</span> <span class=nx>buffer</span> <span class=o>=</span> <span class=p>[];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kr>const</span> <span class=nx>slidingWindow</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>Transform</span><span class=p>({</span>
</span></span><span class=line><span class=cl>  <span class=nx>objectMode</span><span class=o>:</span> <span class=kc>true</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nx>transform</span><span class=p>(</span><span class=nx>chunk</span><span class=p>,</span> <span class=nx>encoding</span><span class=p>,</span> <span class=nx>callback</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>buffer</span><span class=p>.</span><span class=nx>push</span><span class=p>(</span><span class=nx>chunk</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=nx>buffer</span><span class=p>.</span><span class=nx>length</span> <span class=o>&gt;</span> <span class=mi>5</span><span class=p>)</span> <span class=nx>buffer</span><span class=p>.</span><span class=nx>shift</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kr>const</span> <span class=nx>average</span> <span class=o>=</span> <span class=nx>buffer</span><span class=p>.</span><span class=nx>reduce</span><span class=p>((</span><span class=nx>acc</span><span class=p>,</span> <span class=nx>val</span><span class=p>)</span> <span class=p>=&gt;</span> <span class=nx>acc</span> <span class=o>+</span> <span class=nb>Number</span><span class=p>(</span><span class=nx>val</span><span class=p>),</span> <span class=mi>0</span><span class=p>)</span> <span class=o>/</span> <span class=nx>buffer</span><span class=p>.</span><span class=nx>length</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nx>console</span><span class=p>.</span><span class=nx>log</span><span class=p>(</span><span class=s2>&#34;Moving Average:&#34;</span><span class=p>,</span> <span class=nx>average</span><span class=p>.</span><span class=nx>toFixed</span><span class=p>(</span><span class=mi>2</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nx>callback</span><span class=p>(</span><span class=kc>null</span><span class=p>,</span> <span class=nx>chunk</span><span class=p>);</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 예시 스트림
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>require</span><span class=p>(</span><span class=s1>&#39;fs&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>.</span><span class=nx>createReadStream</span><span class=p>(</span><span class=s1>&#39;data.txt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>.</span><span class=nx>pipe</span><span class=p>(</span><span class=nx>require</span><span class=p>(</span><span class=s1>&#39;split&#39;</span><span class=p>)())</span> <span class=c1>// 한 줄씩
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=p>.</span><span class=nx>pipe</span><span class=p>(</span><span class=nx>slidingWindow</span><span class=p>);</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=hybrid-processing-1>Hybrid Processing<a hidden class=anchor aria-hidden=true href=#hybrid-processing-1>#</a></h4><h5 id=lambda-architecture-구성-예-batch--stream>Lambda Architecture 구성 예 (Batch + Stream)<a hidden class=anchor aria-hidden=true href=#lambda-architecture-구성-예-batch--stream>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-7-1><a class=lnlinks href=#hl-7-1> 1</a>
</span><span class=lnt id=hl-7-2><a class=lnlinks href=#hl-7-2> 2</a>
</span><span class=lnt id=hl-7-3><a class=lnlinks href=#hl-7-3> 3</a>
</span><span class=lnt id=hl-7-4><a class=lnlinks href=#hl-7-4> 4</a>
</span><span class=lnt id=hl-7-5><a class=lnlinks href=#hl-7-5> 5</a>
</span><span class=lnt id=hl-7-6><a class=lnlinks href=#hl-7-6> 6</a>
</span><span class=lnt id=hl-7-7><a class=lnlinks href=#hl-7-7> 7</a>
</span><span class=lnt id=hl-7-8><a class=lnlinks href=#hl-7-8> 8</a>
</span><span class=lnt id=hl-7-9><a class=lnlinks href=#hl-7-9> 9</a>
</span><span class=lnt id=hl-7-10><a class=lnlinks href=#hl-7-10>10</a>
</span><span class=lnt id=hl-7-11><a class=lnlinks href=#hl-7-11>11</a>
</span><span class=lnt id=hl-7-12><a class=lnlinks href=#hl-7-12>12</a>
</span><span class=lnt id=hl-7-13><a class=lnlinks href=#hl-7-13>13</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Batch Layer: Spark로 집계</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pyspark.sql</span> <span class=kn>import</span> <span class=n>SparkSession</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span><span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&#34;BatchAggregation&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>batch_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>json</span><span class=p>(</span><span class=s2>&#34;historical_data.json&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>agg</span> <span class=o>=</span> <span class=n>batch_df</span><span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=s2>&#34;user_id&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>agg</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>parquet</span><span class=p>(</span><span class=s2>&#34;batch_output/&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stream Layer: 실시간 Kafka 스트림 처리</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>kafka</span> <span class=kn>import</span> <span class=n>KafkaConsumer</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>msg</span> <span class=ow>in</span> <span class=n>KafkaConsumer</span><span class=p>(</span><span class=s1>&#39;realtime-data&#39;</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=o>=</span><span class=s1>&#39;localhost:9092&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Kafka 메시지 실시간 처리</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Streaming msg:&#34;</span><span class=p>,</span> <span class=n>msg</span><span class=o>.</span><span class=n>value</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=replay-based-kafka-기반-재처리>Replay-Based (Kafka 기반 재처리)<a hidden class=anchor aria-hidden=true href=#replay-based-kafka-기반-재처리>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-8-1><a class=lnlinks href=#hl-8-1> 1</a>
</span><span class=lnt id=hl-8-2><a class=lnlinks href=#hl-8-2> 2</a>
</span><span class=lnt id=hl-8-3><a class=lnlinks href=#hl-8-3> 3</a>
</span><span class=lnt id=hl-8-4><a class=lnlinks href=#hl-8-4> 4</a>
</span><span class=lnt id=hl-8-5><a class=lnlinks href=#hl-8-5> 5</a>
</span><span class=lnt id=hl-8-6><a class=lnlinks href=#hl-8-6> 6</a>
</span><span class=lnt id=hl-8-7><a class=lnlinks href=#hl-8-7> 7</a>
</span><span class=lnt id=hl-8-8><a class=lnlinks href=#hl-8-8> 8</a>
</span><span class=lnt id=hl-8-9><a class=lnlinks href=#hl-8-9> 9</a>
</span><span class=lnt id=hl-8-10><a class=lnlinks href=#hl-8-10>10</a>
</span><span class=lnt id=hl-8-11><a class=lnlinks href=#hl-8-11>11</a>
</span><span class=lnt id=hl-8-12><a class=lnlinks href=#hl-8-12>12</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>kafka</span> <span class=kn>import</span> <span class=n>KafkaConsumer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>consumer</span> <span class=o>=</span> <span class=n>KafkaConsumer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;events&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bootstrap_servers</span><span class=o>=</span><span class=s1>&#39;localhost:9092&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>auto_offset_reset</span><span class=o>=</span><span class=s1>&#39;earliest&#39;</span><span class=p>,</span>  <span class=c1># 과거부터 다시 읽기</span>
</span></span><span class=line><span class=cl>    <span class=n>enable_auto_commit</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>message</span> <span class=ow>in</span> <span class=n>consumer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>event</span> <span class=o>=</span> <span class=n>message</span><span class=o>.</span><span class=n>value</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Reprocessing Event: </span><span class=si>{</span><span class=n>event</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=실무-사용-예시>실무 사용 예시<a hidden class=anchor aria-hidden=true href=#실무-사용-예시>#</a></h3><table><thead><tr><th><strong>처리 방식</strong></th><th><strong>산업/도메인</strong></th><th><strong>활용 목적</strong></th><th><strong>주요 기술/구성</strong></th><th><strong>기대 효과</strong></th></tr></thead><tbody><tr><td><strong>배치 처리</strong></td><td>금융</td><td>일일 정산, 회계 보고서 생성</td><td>Spark, Hadoop, Airflow, BigQuery</td><td>정확한 집계, 규정 준수, 비용 효율성</td></tr><tr><td></td><td>미디어</td><td>대규모 콘텐츠 분석</td><td>EMR, Spark, Cloud Storage</td><td>리소스 절약, 비동기 분석, 스케일 아웃 최적화</td></tr><tr><td></td><td>이커머스</td><td>전일 구매 트렌드 분석</td><td>Dataflow, Snowflake</td><td>전략적 의사결정 지원, 대규모 데이터 정합성 보장</td></tr><tr><td><strong>스트림 처리</strong></td><td>금융</td><td>실시간 사기 탐지</td><td>Kafka, Flink, Redis</td><td>즉시 차단, 사용자 보호, 손실 최소화</td></tr><tr><td></td><td>제조</td><td>장비 상태 예측 정비</td><td>Flink, MQTT, Grafana</td><td>고장 방지, 유지보수 비용 절감</td></tr><tr><td></td><td>통신</td><td>네트워크 품질 모니터링</td><td>Kafka, Flink, Prometheus</td><td>실시간 장애 감지 및 SLA 유지</td></tr><tr><td></td><td>의료</td><td>환자 생체 신호 실시간 모니터링</td><td>Kafka, InfluxDB, Telegraf</td><td>응급 상황 대응, 생명 보호</td></tr><tr><td></td><td>IoT</td><td>센서 데이터 실시간 분석</td><td>Spark Streaming, AWS Kinesis</td><td>지연 없는 제어, 트렌드 기반 반응</td></tr><tr><td><strong>하이브리드 처리</strong></td><td>이커머스</td><td>개인화 추천, 사용자 행동 분석</td><td>Lambda Architecture (Kafka + Spark + Flink)</td><td>실시간 반응성과 모델 정밀도 동시 확보</td></tr><tr><td></td><td>광고</td><td>캠페인 성과 분석</td><td>Kafka Streams + Batch Aggregator</td><td>실시간 클릭 분석 + 배치 보고</td></tr><tr><td></td><td>헬스케어</td><td>환자 기록 + 실시간 모니터링</td><td>Kappa 또는 Lambda 기반 처리</td><td>장기 기록 보존 + 즉각 경보</td></tr><tr><td></td><td>금융</td><td>거래 이상 탐지 + 규제 보고서 생성</td><td>Flink + Spark + PostgreSQL Outbox Pattern</td><td>지속 모니터링 + 배치 기반 분석 보정</td></tr></tbody></table><ul><li><strong>배치 처리</strong>는 정밀한 분석, 정기 보고, 대규모 데이터에 유리</li><li><strong>스트림 처리</strong>는 실시간 반응성과 지연 최소화가 핵심인 도메인에 최적</li><li><strong>하이브리드 처리</strong>는 실시간성과 정확성을 동시에 요구하는 복합 시나리오에 적합</li></ul><h3 id=도전-과제-및-해결-방안>도전 과제 및 해결 방안<a hidden class=anchor aria-hidden=true href=#도전-과제-및-해결-방안>#</a></h3><table><thead><tr><th>카테고리</th><th>도전 과제</th><th>주요 원인</th><th>영향</th><th>해결 방안 요약</th></tr></thead><tbody><tr><td><strong>데이터 일관성</strong></td><td>스트림 처리의 정확성 확보</td><td>실시간 처리 중 네트워크 지연, 장애, 병렬성 이슈</td><td>중복 처리, 누락 처리, 잘못된 비즈니스 인사이트</td><td>체크포인트, Exactly-once 보장, 이벤트 소싱, 트랜잭션 관리</td></tr><tr><td></td><td>하이브리드 간 동기화</td><td>배치 - 스트림 간 처리 시간/정책 차이</td><td>데이터 충돌, 보정 작업 증가</td><td>CQRS, Materialized View, 보상 트랜잭션, 이벤트 재처리 기반 정합성 확보</td></tr><tr><td><strong>성능 최적화</strong></td><td>지연 시간 최적화</td><td>I/O 병목, 상태 관리 비용, 과도한 처리량 요구</td><td>SLA 미달성, 사용자 체감 속도 저하</td><td>백프레셔 관리, 파티셔닝, 캐싱, 직렬화 최적화, 수평 확장</td></tr><tr><td></td><td>실시간 처리 병목</td><td>계산 복잡성 증가, 메모리 압박, 이벤트 버스트</td><td>처리량 저하, 장애 가능성</td><td>슬라이딩 윈도우 조정, 워터마크 튜닝, 워커 확장, 리소스 기반 자동 스케일링</td></tr><tr><td><strong>복잡성 관리</strong></td><td>운영 복잡도 증가</td><td>배치/스트림 이중 관리, 다중 기술 스택 도입</td><td>운영비 증가, 변경 비용 상승</td><td>구조 표준화, 통합 관찰성 (Observability), 아키텍처 단순화, 문서화</td></tr><tr><td></td><td>장애 대응 복잡성</td><td>상호 의존 서비스, 비표준 오류 처리</td><td>장애 전파, MTTR 증가</td><td>분산 추적, 장애 시뮬레이션 (Chaos), Circuit Breaker, 자동 장애 격리</td></tr><tr><td><strong>비용/자원 효율화</strong></td><td>인프라 낭비</td><td>고정된 리소스 할당, 오버프로비저닝</td><td>비용 초과, 확장 제약</td><td>오토스케일링, 예약 인스턴스, 클라우드 네이티브 기반 아키텍처, 비용 추적 도구 활용</td></tr><tr><td></td><td>중복 인프라 구성</td><td>Lambda 스타일 구조의 이중 저장, 이중 처리</td><td>ROI 저하, 운영 부담</td><td>Kappa 기반 구조 전환, Data Lake 활용, ETL+Stream 통합</td></tr><tr><td><strong>운영 안정성</strong></td><td>복구/재처리 어려움</td><td>상태 관리 미비, 로그 미보존, 무상태 처리</td><td>데이터 손실, 복구 지연</td><td>Kafka 기반 리플레이, 이벤트 로그 장기 저장, 체크포인트/스냅샷 기반 복구</td></tr><tr><td></td><td>테스트/배포 리스크</td><td>데이터 의존적 연산, 시간 민감 로직</td><td>릴리즈 실패, 데이터 훼손</td><td>Canary Release, Blue-Green Deployment, 데이터 샘플 기반 테스트</td></tr></tbody></table><h3 id=실무에서-효과적으로-적용하기-위한-고려사항-및-주의할-점>실무에서 효과적으로 적용하기 위한 고려사항 및 주의할 점<a hidden class=anchor aria-hidden=true href=#실무에서-효과적으로-적용하기-위한-고려사항-및-주의할-점>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>고려 항목</strong></th><th><strong>설명</strong></th><th><strong>권장 사항</strong></th></tr></thead><tbody><tr><td><strong>적용 전략</strong></td><td>데이터 특성 분석</td><td>데이터 발생 패턴 (주기성, 폭증 등) 과 실시간 요구 수준 분석</td><td>요구사항에 따라 Batch, Stream, Hybrid 중 적절히 선택</td></tr><tr><td></td><td>정합성 요구 수준</td><td>데이터 정확도/일관성 우선인지 속도 우선인지 판단</td><td>회계/금융 등은 Batch or Hybrid, 사용자 반응성은 Stream 우선</td></tr><tr><td></td><td>재처리 가능성 여부</td><td>과거 데이터의 정정 또는 반복 처리 요구 여부</td><td>Stream 은 로그 기반 보존 전략 필수, Hybrid 는 Batch 로 보완</td></tr><tr><td><strong>운영/안정성</strong></td><td>장애 복구 전략</td><td>시스템 장애 발생 시 데이터 손실 없이 복구 가능 구조 설계</td><td>Stream 처리 시 Checkpoint, DLQ 구성 필수, Batch 는 재처리 기반</td></tr><tr><td></td><td>상태 관리 전략</td><td>상태 기반 필터 사용 시 복구 가능한 외부 상태 저장소 확보</td><td>Flink StateBackend, Kafka Offset Commit, DB 기반 상태 외부화</td></tr><tr><td></td><td>운영 복잡도</td><td>시스템 관리/배포/모니터링의 복잡성에 대한 감내 가능성 분석</td><td>리소스 부족 시 단순 구조 선호 (ex. 단일 처리 방식), 운영팀 규모 고려</td></tr><tr><td><strong>성능</strong></td><td>처리량 최적화</td><td>대용량 처리 시 배치 크기, 파티셔닝, 병렬성 등 조정 필요</td><td>병렬 처리 최적화, 적절한 리소스 사용률 유지 (예: CPU 80% 이하)</td></tr><tr><td></td><td>지연시간 관리</td><td>서비스 수준 협약 (SLA) 을 만족시키기 위한 반응 시간 기준 설정</td><td>실시간성 요구 시 Stream, 지연 허용 시 Batch, 보완은 Hybrid 로</td></tr><tr><td><strong>확장성</strong></td><td>수평 확장 지원 여부</td><td>데이터 증가 시 노드 추가로 처리량 확장 가능 구조 설계</td><td>Kafka/Flink 기반 수평 확장 구조 설계, 자동 스케일링 정책 적용</td></tr><tr><td></td><td>리소스 사용 최적화</td><td>CPU, 메모리, 네트워크 등 리소스 활용률 조절 및 동적 할당</td><td>Auto-scaling, Container 기반 격리 구조, 리소스 모니터링 필수</td></tr><tr><td><strong>모니터링</strong></td><td>상태 추적 / 로깅</td><td>실시간 데이터 흐름/에러 상황 추적 및 분석 가능성 확보</td><td>Prometheus, Grafana, Jaeger 등으로 Pipeline 상태 시각화</td></tr><tr><td></td><td>SLA 기반 감시 체계</td><td>시스템 장애 및 성능 저하 시 자동 경고/회복 처리 가능 구조 필요</td><td>임계값 초과 시 알람, 복구 자동화 구성 (e.g., Flink Job Failure Recovery)</td></tr></tbody></table><h3 id=최적화-고려사항-및-주의점>최적화 고려사항 및 주의점<a hidden class=anchor aria-hidden=true href=#최적화-고려사항-및-주의점>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>항목</strong></th><th><strong>설명</strong></th><th><strong>권장사항</strong></th></tr></thead><tbody><tr><td><strong>리소스 최적화</strong></td><td>메모리 관리</td><td>메모리 부족으로 인한 GC 지연 및 OOM 방지</td><td>메모리 프로파일링, GC 튜닝, Stateful 연산 최소화</td></tr><tr><td></td><td>CPU 활용</td><td>연산 집중 로직 병목 해소, 멀티코어 활용 극대화</td><td>비효율적 알고리즘 제거, 연산 분산, 연산 우선순위 기반 재구성</td></tr><tr><td></td><td>리소스 스케일링</td><td>처리 부하에 따라 자원 동적 조정 필요</td><td>Auto Scaling, Container Orchestration, 워커 조정</td></tr><tr><td><strong>네트워크 최적화</strong></td><td>데이터 이동 최소화</td><td>노드 간 네트워크 트래픽이 성능에 미치는 영향 큼</td><td>데이터 로컬리티 최적화, 압축, 캐시 전략 도입</td></tr><tr><td><strong>저장소 최적화</strong></td><td>스토리지 효율성</td><td>디스크 I/O 병목 제거 및 조회 최적화 필요</td><td>파티셔닝, 버킷화, 인덱싱, 컬럼형 저장소 (Parquet, ORC 등) 도입</td></tr><tr><td><strong>파이프라인 설계</strong></td><td>처리 파이프라인 최적화</td><td>병목 지점 제거 및 작업 흐름 재조정</td><td>병렬 처리 도입, DAG 구조 최적화, backpressure 핸들링</td></tr><tr><td></td><td>배치 스케줄링</td><td>Job 실행 시기, 우선순위에 따라 전체 처리 지연 발생 가능</td><td>SLA 기반 우선순위 조정, 리소스 예약 기반 스케줄링</td></tr><tr><td><strong>스트림 전략</strong></td><td>윈도우 처리 전략</td><td>슬라이딩/텀블링 윈도우에 따라 처리량과 지연 차이 존재</td><td>처리 목적에 따른 윈도우 선택 및 크기 조절</td></tr><tr><td></td><td>파티셔닝 전략</td><td>Key skew 가 발생할 경우 성능 급감</td><td>해시 기반 파티셔닝, 키 분산 전략, 리밸런싱 로직 도입</td></tr><tr><td></td><td>체크포인팅 주기</td><td>너무 짧으면 오버헤드↑, 너무 길면 장애 복구 느림</td><td>이벤트량 기반 주기 조정, Incremental Checkpointing</td></tr><tr><td><strong>정합성 & 복구</strong></td><td>데이터 정합성 유지</td><td>스트림 & 배치 병합 시 일관성 확보 필요</td><td>버전 관리된 서빙 레이어, CDC + 보정 파이프라인 구축</td></tr><tr><td></td><td>장애 복구</td><td>실패 시 지점 복구 및 중복 방지 필요</td><td>Exactly-once, Checkpoint + State Backend 설계</td></tr><tr><td><strong>성능 지표 관리</strong></td><td>처리 지연 최소화</td><td>낮은 지연 보장 위해 처리 경로와 연산 최적화 필요</td><td>비동기 처리, 워커 수 조정, 연산 재구성</td></tr><tr><td></td><td>처리량 (Throughput) 개선</td><td>단위 시간당 처리량 증가로 전체 성능 향상</td><td>병렬도 증가, 연산 분할, Kafka partition tuning</td></tr><tr><td></td><td>백프레셔 대응</td><td>처리 속도 불균형 시 시스템 불안정 발생</td><td>Flink 의 backpressure 모니터링, 처리 속도 기반 동적 버퍼 조절</td></tr></tbody></table><h3 id=주제별-주목할-내용>주제별 주목할 내용<a hidden class=anchor aria-hidden=true href=#주제별-주목할-내용>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>항목</strong></th><th><strong>내용 요약</strong></th></tr></thead><tbody><tr><td><strong>처리 구조</strong></td><td>처리 경로</td><td><strong>Batch</strong>: 일괄 처리<strong>Stream</strong>: 실시간 처리<strong>Hybrid</strong>: 배치 + 스트림 통합 (예: Lambda, Kappa 구조)</td></tr><tr><td></td><td>실시간성</td><td>스트림 처리 방식이 지연 시간과 반응성이 가장 우수</td></tr><tr><td></td><td>복잡성</td><td>하이브리드는 복잡한 운영 관리 및 동기화 로직 필요 (운영 난이도 ↑)</td></tr><tr><td></td><td>일관성</td><td>배치 및 하이브리드는 고정된 스케줄과 데이터 스냅샷으로 상대적으로 높은 데이터 품질 보장</td></tr><tr><td><strong>아키텍처 패턴</strong></td><td>Lambda Architecture</td><td>배치 + 스트림 레이어를 각각 운용하며 정확성과 실시간성을 모두 확보하는 구조</td></tr><tr><td></td><td>Kappa Architecture</td><td>단일 스트림 경로로 단순한 구조, 유지보수 용이</td></tr><tr><td><strong>핵심 기술 스택</strong></td><td>Apache Kafka</td><td>고신뢰 이벤트 브로커, 모든 처리 방식의 중심 기술 (Event Sourcing / Reprocessing 기반)</td></tr><tr><td></td><td>Apache Flink</td><td>진정한 실시간 처리 및 상태 기반 처리 지원. Hybrid 처리에 적합</td></tr><tr><td></td><td>Apache Spark</td><td>마이크로배치 기반의 스트림 처리도 가능한 통합형 프레임워크</td></tr><tr><td><strong>처리 패러다임</strong></td><td>이벤트 시간 처리 (Event Time)</td><td>정확한 시간 기반 분석을 위해 이벤트 발생 시각 기준 처리</td></tr><tr><td></td><td>상태 관리</td><td>Stateful 처리로 과거 이벤트/상태 기반의 정밀한 연산 가능 (예: 세션 집계, 중복 제거)</td></tr><tr><td><strong>운영 특성</strong></td><td>체크포인팅</td><td>상태 저장 및 복구를 위한 메커니즘. 장애 대비 필수 구성요소</td></tr><tr><td></td><td>정확히 한 번 처리</td><td>&ldquo;Exactly-Once&rdquo; 보장 처리로 데이터 중복 방지 및 일관성 유지</td></tr><tr><td></td><td>백프레셔 제어</td><td>처리량 초과 시 흐름을 제어하여 안정적 운영을 보장 (Flink, Kafka 등에서 기본 지원)</td></tr></tbody></table><h3 id=반드시-학습해야할-내용>반드시 학습해야할 내용<a hidden class=anchor aria-hidden=true href=#반드시-학습해야할-내용>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>주제</strong></th><th><strong>핵심 항목</strong></th><th><strong>설명</strong></th></tr></thead><tbody><tr><td><strong>기초 이론</strong></td><td>데이터 처리 모델</td><td>Batch vs Stream vs Hybrid</td><td>각 처리 방식의 원리, 장단점, 처리 흐름 구조 비교</td></tr><tr><td></td><td>분산 시스템 이론</td><td>CAP 정리</td><td>일관성 (Consistency), 가용성 (Availability), 분할 내성 (Partition Tolerance) 간 트레이드오프</td></tr><tr><td></td><td>시간 처리 모델</td><td>Event Time vs Processing Time</td><td>이벤트 정확한 시계열 분석 및 지연 시간 처리의 차이 이해</td></tr><tr><td></td><td>이벤트 기반 설계</td><td>Event Sourcing, CQRS</td><td>상태 저장 방식과 읽기/쓰기 분리 구조 이해</td></tr><tr><td><strong>아키텍처 스타일</strong></td><td>데이터 플로우 아키텍처</td><td>Pipe-and-Filter, Stream, Lambda/Kappa</td><td>데이터 흐름 기반 처리 스타일, 계층별 처리 방식 설계 전략</td></tr><tr><td></td><td>마이크로서비스 설계</td><td>서비스 분해, 메시징, 경량화</td><td>각 서비스 독립 실행 및 배포 가능하게 구성, 메시지 기반 연결</td></tr><tr><td><strong>기술 스택</strong></td><td>스트림 처리 프레임워크</td><td>Kafka Streams, Flink, Spark Streaming</td><td>실시간 데이터 분석 및 이벤트 기반 처리 엔진</td></tr><tr><td></td><td>배치 처리 프레임워크</td><td>Spark, Hadoop, Airflow</td><td>대량 데이터 집계, ETL, 정합성 기반 처리 프레임워크</td></tr><tr><td></td><td>메시지 브로커</td><td>Kafka, RabbitMQ, Pulsar</td><td>비동기 메시지 큐 및 실시간 데이터 파이프라인 구축 도구</td></tr><tr><td><strong>운영 및 장애 대응</strong></td><td>장애 복구 전략</td><td>Checkpointing, Replay, DLQ</td><td>스트림 중단 없이 복구 가능한 구조 설계, 메시지 재처리 전략</td></tr><tr><td></td><td>운영 관측 가능성</td><td>Metrics, Logs, Tracing</td><td>성능 모니터링 및 장애 분석을 위한 관측 지표 활용 (e.g., Kafka Lag, Flink Job Status 등)</td></tr><tr><td></td><td>리소스 사용량 최적화</td><td>Auto-scaling, Partitioning</td><td>처리량에 따라 동적으로 확장 및 분할 처리 설계</td></tr><tr><td><strong>성능 최적화</strong></td><td>병렬 처리 전략</td><td>Multi-threading, Worker Pool</td><td>필터 및 파이프라인 단위 병렬 처리 설계</td></tr><tr><td></td><td>캐싱 전략</td><td>Local/Distributed Cache</td><td>지연시간 감소 및 반복 연산 회피용 캐시 활용</td></tr><tr><td></td><td>데이터 파티셔닝</td><td>Key 기반 분산 처리</td><td>데이터를 논리적 단위로 나누어 확장성과 병렬성 확보</td></tr><tr><td></td><td>배치 최적화</td><td>윈도우 기반 처리, Batch Size 조정</td><td>처리 단위 최적화를 통한 처리 효율성 향상</td></tr></tbody></table><hr><h2 id=용어-정리>용어 정리<a hidden class=anchor aria-hidden=true href=#용어-정리>#</a></h2><table><thead><tr><th><strong>대분류</strong></th><th><strong>소분류</strong></th><th><strong>용어</strong></th><th><strong>설명</strong></th></tr></thead><tbody><tr><td><strong>처리 방식</strong></td><td>주요 처리 유형</td><td><strong>Batch Processing</strong></td><td>데이터를 일정 주기로 모아 일괄 처리하는 방식. 지연이 허용되는 대용량 처리에 적합</td></tr><tr><td></td><td></td><td><strong>Stream Processing</strong></td><td>데이터가 도착하자마자 실시간으로 처리하는 방식. 지연에 민감한 시스템에 적합</td></tr><tr><td></td><td></td><td><strong>Hybrid Processing</strong></td><td>Batch 와 Stream 을 통합하여 정확성과 지연 시간의 균형을 추구</td></tr><tr><td></td><td>세부 처리 기술</td><td><strong>Micro-Batch</strong></td><td>소규모 배치를 사용해 준실시간 처리를 수행하는 방식. Spark Streaming 등에서 사용</td></tr><tr><td></td><td>시간 단위 처리</td><td><strong>Tumbling Window</strong></td><td>고정 시간 간격으로 데이터를 집계하는 윈도우 방식</td></tr><tr><td></td><td></td><td><strong>Sliding Window</strong></td><td>중첩된 시간 구간으로 연속적인 집계를 수행하는 방식</td></tr><tr><td></td><td>시간 기준</td><td><strong>Event Time</strong></td><td>데이터가 실제 발생한 시간 기준으로 처리</td></tr><tr><td></td><td></td><td><strong>Processing Time</strong></td><td>시스템이 데이터를 수신 및 처리한 시간 기준</td></tr><tr><td></td><td></td><td><strong>Watermark</strong></td><td>늦게 도착한 이벤트 처리를 위해 정의하는 시간 기준점</td></tr><tr><td><strong>아키텍처</strong></td><td>패턴 및 구조</td><td><strong>Lambda Architecture</strong></td><td>Batch + Stream Layer 를 병렬로 운용하는 구조. 정확성 중심</td></tr><tr><td></td><td></td><td><strong>Kappa Architecture</strong></td><td>단일 스트림 파이프라인 기반의 구조. 단순성과 유지보수 용이성 중심</td></tr><tr><td></td><td>구성 요소</td><td><strong>Batch Layer</strong></td><td>(Lambda) 정기적 일괄 처리 수행 계층</td></tr><tr><td></td><td></td><td><strong>Speed Layer</strong></td><td>(Lambda) 최신 데이터를 빠르게 처리하는 계층</td></tr><tr><td></td><td></td><td><strong>Serving Layer</strong></td><td>사용자 쿼리에 응답 가능한 상태를 저장하는 계층 (공통)</td></tr><tr><td><strong>상태 관리 및 보장</strong></td><td>상태 저장 방식</td><td><strong>Checkpointing</strong></td><td>장애 복구를 위해 상태를 주기적으로 저장하는 기법</td></tr><tr><td></td><td></td><td><strong>State Backend</strong></td><td>Flink 등에서 사용되는 상태 저장소 (e.g., RocksDB)</td></tr><tr><td></td><td>메시지 처리 보장</td><td><strong>Exactly Once</strong></td><td>각 이벤트가 정확히 한 번만 처리되도록 보장</td></tr><tr><td></td><td></td><td><strong>At Least Once</strong></td><td>이벤트가 최소 한 번 이상 처리되는 보장 방식</td></tr><tr><td><strong>플랫폼/도구</strong></td><td>스트리밍 플랫폼</td><td><strong>Apache Kafka</strong></td><td>고신뢰 분산 메시징 시스템. 스트림 처리 및 재처리에 핵심 플랫폼</td></tr><tr><td></td><td></td><td><strong>Apache Flink</strong></td><td>상태 기반의 실시간 스트림 처리 프레임워크. 정확한 이벤트 처리 보장</td></tr><tr><td></td><td></td><td><strong>Apache Spark</strong></td><td>대규모 배치 및 마이크로배치 기반의 스트림 처리 가능</td></tr><tr><td><strong>운영 및 성능</strong></td><td>운영 전략</td><td><strong>Checkpoint</strong></td><td>처리 중간 상태 저장을 통해 장애 복구 가능</td></tr><tr><td></td><td></td><td><strong>Backpressure</strong></td><td>처리 속도보다 빠른 유입 시 흐름 제어. 시스템 안정성을 위한 필수 메커니즘</td></tr><tr><td></td><td></td><td><strong>Latency</strong></td><td>데이터 처리 완료까지 걸리는 시간 (지연 시간)</td></tr><tr><td></td><td></td><td><strong>Throughput</strong></td><td>단위 시간당 처리 가능한 데이터 양</td></tr><tr><td><strong>분산 처리 전략</strong></td><td>스케일 전략</td><td><strong>Partitioning</strong></td><td>데이터를 샤드별로 분산 처리하여 병렬성과 확장성을 확보</td></tr><tr><td></td><td></td><td><strong>Sharding</strong></td><td>데이터베이스를 수평으로 나눠 저장 및 처리하는 전략</td></tr><tr><td></td><td></td><td><strong>Rebalancing</strong></td><td>작업 부하를 클러스터 노드 간에 재분배하는 과정</td></tr></tbody></table><hr><h2 id=참고-및-출처>참고 및 출처<a hidden class=anchor aria-hidden=true href=#참고-및-출처>#</a></h2><ul><li><a href=https://rivery.io/blog/batch-vs-stream-processing-pros-and-cons-2/>Batch Processing vs. Stream Processing: A Comprehensive Guide – Rivery</a></li><li><a href=https://atlan.com/batch-processing-vs-stream-processing/>Batch Processing vs Stream Processing: Key Differences for 2025 – Atlan</a></li><li><a href=https://www.geeksforgeeks.org/difference-between-batch-processing-and-stream-processing/>Difference between Batch Processing and Stream Processing – GeeksforGeeks</a></li><li><a href=https://www.datacamp.com/blog/batch-vs-stream-processing>Batch vs Stream Processing: When to Use Each and Why It Matters – DataCamp</a></li><li><a href=https://www.snowflake.com/guides/batch-vs-stream-processing>Batch vs Stream Processing: Differences and Use Cases – Snowflake</a></li><li><a href=https://www.confluent.io/learn/stream-processing/>What is Stream Processing? – Confluent</a></li><li><a href=https://www.databricks.com/glossary/batch-processing>Batch vs. Stream vs. Real‑Time Data Processing – Databricks</a></li><li><a href=https://nightlies.apache.org/flink/flink-docs-master/>Apache Flink Documentation – Apache Flink</a></li><li><a href=https://kafka.apache.org/>Apache Kafka Official Site – Apache Kafka</a></li><li><a href=https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html>Spark Structured Streaming Guide – Apache Spark</a></li><li><a href=https://www.kai-waehner.de/blog/2024/12/02/top-trends-for-data-streaming-with-apache-kafka-and-flink-in-2025/>Top Trends for Data Streaming with Apache Kafka and Flink in 2025 – Kai Waehner</a></li><li><a href=https://en.wikipedia.org/wiki/Lambda_architecture>Lambda Architecture – Wikipedia</a></li><li><a href=https://hazelcast.com/foundations/software-architecture/kappa-architecture/>Kappa Architecture Overview – Hazelcast</a></li><li><a href=https://towardsdatascience.com/batch-vs-stream-processing-4ca1d8e0c5b0>Batch vs. Stream Processing – Towards Data Science</a></li></ul><hr></div><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Batch Processing</h2></header><div class=entry-content><p>Batch Processing 배치 처리 (Batch Processing) 는 여러 데이터 작업을 묶어 한 번에 처리하는 데이터 처리 방식이다. 이는 주로 대용량 데이터 집계, 변환, 백업, 보고서 생성 등 반복적이고 대규모 작업에 적용된다. 배치 처리는 데이터 흐름 아키텍처의 한 형태로, 자동화, 확장성, 일관성, 오류 복구 등에서 강점을 가지며, 실시간 처리와는 다른 효율성과 안정성을 제공한다. 현대 IT 시스템에서는 분산 처리, 스케줄링, 장애 복구 등과 결합되어 다양한 산업에서 핵심 역할을 수행한다.
배경 대규모 데이터가 실시간으로 처리될 필요가 없을 때, 리소스 효율성과 자동화, 신뢰성을 위해 배치 처리 방식이 도입됨. 초기 메인프레임 환경에서부터 현대의 분산 시스템, 클라우드 환경까지 널리 사용됨. 목적 및 필요성 주요 목적
...</p></div><footer class=entry-footer><span title='2025-02-01 03:23:00 +0000 UTC'>February 1, 2025</span>&nbsp;·&nbsp;26 min&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Batch Processing" href=https://buenhyden.github.io/posts/data--database-systems/data-architecture/processing-paradigms/batch-processing/></a></article></main><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script><footer class=footer><span>&copy; 2025 <a href=https://buenhyden.github.io/>hyunyoun's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>