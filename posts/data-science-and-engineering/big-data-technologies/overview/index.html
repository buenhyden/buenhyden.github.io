<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Data Science and Engineering Overview | hyunyoun's Blog</title><meta name=keywords content="Data-Science-and-Engineering,Overview"><meta name=description content="Data Science and Engineering 은 데이터로부터 비즈니스 가치를 창출하기 위해 데이터 수집, 저장, 처리, 분석의 전체 생명주기를 다루는 융합 분야로, 데이터 파이프라인 구축, 머신러닝 모델 개발, MLOps 운영을 포괄하여 조직의 데이터 기반 의사결정을 지원한다."><meta name=author content="Me"><link rel=canonical href=https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/overview/><meta name=google-site-verification content="googlee06938ebbfcbac49.html"><link crossorigin=anonymous href=/assets/css/stylesheet.a9863521b3bd3c240bc506f46b95e3c06ccef2ae37f529d5f99bdaef442bccce.css integrity="sha256-qYY1IbO9PCQLxQb0a5XjwGzO8q439SnV+Zva70QrzM4=" rel="preload stylesheet" as=style><link rel=icon href=https://buenhyden.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://buenhyden.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://buenhyden.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/overview/index.xml><link rel=alternate hreflang=en href=https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/overview/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3156423099418350" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W8XTMYPTLC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W8XTMYPTLC")}</script><meta property="og:url" content="https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/overview/"><meta property="og:site_name" content="hyunyoun's Blog"><meta property="og:title" content="Data Science and Engineering Overview"><meta property="og:description" content="Data Science and Engineering 은 데이터로부터 비즈니스 가치를 창출하기 위해 데이터 수집, 저장, 처리, 분석의 전체 생명주기를 다루는 융합 분야로, 데이터 파이프라인 구축, 머신러닝 모델 개발, MLOps 운영을 포괄하여 조직의 데이터 기반 의사결정을 지원한다."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://buenhyden.github.io/images"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://buenhyden.github.io/images"><meta name=twitter:title content="Data Science and Engineering Overview"><meta name=twitter:description content="Data Science and Engineering 은 데이터로부터 비즈니스 가치를 창출하기 위해 데이터 수집, 저장, 처리, 분석의 전체 생명주기를 다루는 융합 분야로, 데이터 파이프라인 구축, 머신러닝 모델 개발, MLOps 운영을 포괄하여 조직의 데이터 기반 의사결정을 지원한다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"HY's Blog","item":"https://buenhyden.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Big Data","item":"https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/"},{"@type":"ListItem","position":4,"name":"Data Science and Engineering Overview","item":"https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/overview/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://buenhyden.github.io/ accesskey=h title="Hy's Blog (Alt + H)"><img src=https://buenhyden.github.io/favicons/apple-touch-icon.png alt aria-label=logo height=35>Hy's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://buenhyden.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://buenhyden.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://buenhyden.github.io/til/ title="Today I Learned"><span>Today I Learned</span></a></li><li><a href=https://buenhyden.github.io/coding-test/ title="Coding Test"><span>Coding Test</span></a></li><li><a href=https://buenhyden.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://buenhyden.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://buenhyden.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://buenhyden.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/>HY's Blog</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/data-science-and-engineering/big-data-technologies/>Big Data</a></div><h1>Data Science and Engineering Overview</h1><div class=post-description>Data Science and Engineering 은 데이터로부터 비즈니스 가치를 창출하기 위해 데이터 수집, 저장, 처리, 분석의 전체 생명주기를 다루는 융합 분야로, 데이터 파이프라인 구축, 머신러닝 모델 개발, MLOps 운영을 포괄하여 조직의 데이터 기반 의사결정을 지원한다.</div></header><div class=post-content><h2 id=data-science-and-engineering>Data Science and Engineering<a hidden class=anchor aria-hidden=true href=#data-science-and-engineering>#</a></h2><p>데이터 과학 및 엔지니어링은 데이터 라이프사이클에 기반한 협업 분야이다.<br>데이터 엔지니어는 데이터 수집 (Ingestion), 변환 (ETL/ELT), 저장 (Data Lake/Warehousing), 제공 (API/ML 모델 입력) 을 설계·구축하며, 데이터 과학자는 통계, 머신러닝·딥러닝, 시각화를 통해 비즈니스 인사이트를 도출한다. 두 역할의 협업은 이상치 처리, 피처 엔지니어링, 실험 설계, 모델 운영 (MLOps) 을 통해 데이터 기반 시스템의 확장성과 정확성을 보장한다. 신뢰성 높은 데이터 아키텍처가 기반이 되며, 도구로는 Spark, Kafka, Airflow, Databricks, TensorFlow 등이 사용된다.</p><h3 id=핵심-개념>핵심 개념<a hidden class=anchor aria-hidden=true href=#핵심-개념>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>개념</strong></th><th><strong>설명</strong></th></tr></thead><tbody><tr><td><strong>1. 데이터 사이언스 (Data Science)</strong></td><td>데이터 과학 (Data Science)</td><td>데이터로부터 패턴·인사이트·예측을 도출하는 학문. 통계학, 머신러닝, 시각화 포함.</td></tr><tr><td></td><td>머신러닝 (Machine Learning)</td><td>데이터를 기반으로 예측/판단을 자동화하는 알고리즘. 분류, 회귀, 클러스터링 등 포함.</td></tr><tr><td></td><td>피처 엔지니어링 (Feature Engineering)</td><td>모델 성능 향상을 위한 유의미한 특성 추출 및 가공 기법.</td></tr><tr><td></td><td>CRISP-DM</td><td>데이터 마이닝 및 분석 프로젝트 수행을 위한 표준 프로세스 (6 단계 모델).</td></tr><tr><td><strong>2. 데이터 엔지니어링 (Data Engineering)</strong></td><td>데이터 엔지니어링</td><td>데이터 수집, 저장, 처리, 전송을 위한 시스템과 파이프라인 구축 및 운영.</td></tr><tr><td></td><td>데이터 파이프라인 (Data Pipeline)</td><td>데이터 흐름 자동화를 위한 시스템. 수집 → 처리 → 저장 → 전달.</td></tr><tr><td></td><td>ETL / ELT</td><td>ETL: 추출 - 변환 - 적재 / ELT: 추출 - 적재 - 변환 방식. 데이터 전처리 전략.</td></tr><tr><td></td><td>데이터 아키텍처 (Data Architecture)</td><td>데이터의 저장·이동·구조를 설계하는 프레임워크. 예: 레이크, 웨어하우스, 허브 등.</td></tr><tr><td></td><td>데이터 레이크 vs 웨어하우스</td><td>Data Lake: 비정형 중심 저장소 / DW: 구조화된 분석 중심 저장소.</td></tr><tr><td><strong>3. 분석 및 시각화 (Analytics)</strong></td><td>데이터 분석 (Data Analysis)</td><td>데이터를 정제·변환·시각화하여 통찰 도출. BI 도구, 시각화 프레임워크와 함께 사용.</td></tr><tr><td></td><td>빅데이터 (Big Data)</td><td>전통적 DB 로 처리 불가능한 대용량·다양성·속도를 지닌 데이터. Hadoop, Spark 등으로 처리.</td></tr><tr><td><strong>4. 시스템/플랫폼 운영 (Operations)</strong></td><td>MLOps</td><td>머신러닝 모델의 배포, 운영, 모니터링 및 재학습 자동화. DevOps 와 ML 의 통합 문화.</td></tr><tr><td></td><td>분산 컴퓨팅 (Distributed Computing)</td><td>대규모 데이터 처리를 위한 분산형 시스템 설계. Spark, Hadoop 등이 대표적.</td></tr><tr><td><strong>5. 거버넌스 및 라이프사이클 (Governance)</strong></td><td>데이터 수명주기 (Data Lifecycle)</td><td>데이터의 생성, 수집, 저장, 분석, 폐기까지 전 과정의 흐름 및 관리.</td></tr></tbody></table><p><strong>엔지니어링</strong>은 데이터 흐름의 기반 (수집→처리→저장→제공) 을 구축하고,<strong>과학</strong>은 이를 분석·예측하여 비즈니스 인사이트를 추출한다.<br>최신 기술은 <strong>자동화, 실시간성, 확장성, 품질 보증, 거버넌스</strong>에 집중되고 있으며, 전략적으로는 <strong>MLOps, Data Mesh, Kappa Architecture</strong> 등의 적용이 실무를 진화시키고 있다.</p><h3 id=배경>배경<a hidden class=anchor aria-hidden=true href=#배경>#</a></h3><p><strong>데이터 과학 및 엔지니어링</strong>은 빅데이터, 클라우드, IoT, 인공지능 등 신기술의 발전과 함께 등장한 분야로, 데이터 기반 의사결정과 비즈니스 혁신의 핵심 역할을 담당한다.</p><h3 id=목적-및-필요성>목적 및 필요성<a hidden class=anchor aria-hidden=true href=#목적-및-필요성>#</a></h3><ul><li><strong>데이터 기반 의사결정:</strong><br>데이터로부터 인사이트를 도출해 비즈니스, 과학, 공공 분야 등에서 의사결정을 지원한다.</li><li><strong>비즈니스 혁신 및 경쟁력 강화:</strong><br>데이터 분석을 통해 새로운 서비스 개발, 고객 경험 개선, 비용 절감 등이 가능하다.</li><li><strong>인프라 구축 및 관리:</strong><br>대규모 데이터를 효율적으로 수집, 저장, 처리, 분석할 수 있는 인프라가 필요하다.</li></ul><h3 id=주요-기능-및-역할>주요 기능 및 역할<a hidden class=anchor aria-hidden=true href=#주요-기능-및-역할>#</a></h3><ul><li><strong>데이터 수집 및 저장:</strong><br>다양한 소스로부터 데이터를 수집, 저장한다.</li><li><strong>데이터 처리 및 변환:</strong><br>데이터를 정제, 변환, 통합하여 분석 가능한 형태로 만든다.</li><li><strong>데이터 분석 및 시각화:</strong><ul><li>데이터로부터 인사이트를 도출하고, 이를 시각화하여 전달한다.</li></ul></li><li><strong>인프라 설계 및 관리:</strong><ul><li>데이터 파이프라인, 데이터 웨어하우스, 데이터 레이크 등 인프라를 설계·관리한다.</li></ul></li></ul><h3 id=특징>특징<a hidden class=anchor aria-hidden=true href=#특징>#</a></h3><ul><li><strong>융합적 접근:</strong><br>컴퓨터 과학, 통계, 수학, 비즈니스 지식이 융합된다.</li><li><strong>실무 중심:</strong><br>실제 데이터와 문제를 다루는 실무 경험이 중요하다.</li><li><strong>지속적 진화:</strong><br>빅데이터, 인공지능, 클라우드 등 신기술과 함께 빠르게 진화한다.</li></ul><h3 id=핵심-원칙>핵심 원칙<a hidden class=anchor aria-hidden=true href=#핵심-원칙>#</a></h3><ul><li><strong>데이터 품질:</strong><br>데이터의 정확성, 완전성, 일관성, 신뢰성을 보장한다.</li><li><strong>확장성:</strong><br>대규모 데이터를 효율적으로 처리할 수 있도록 시스템을 설계한다.</li><li><strong>보안 및 프라이버시:</strong><br>데이터 보호와 개인정보 보호를 위한 조치를 마련한다.</li><li><strong>자동화:</strong><br>데이터 수집, 처리, 분석 과정을 자동화하여 효율성을 높인다.</li></ul><h3 id=주요-원리>주요 원리<a hidden class=anchor aria-hidden=true href=#주요-원리>#</a></h3><p>현대 데이터 아키텍처의 기본 원칙으로는 확장성, 유연성, 보안이 있다:</p><ol><li><strong>확장성 (Scalability)</strong>: 데이터 볼륨 증가에 따른 수직적, 수평적 확장 지원</li><li><strong>유연성 (Flexibility)</strong>: 새로운 데이터 소스와 기술 통합 지원</li><li><strong>보안 (Security)</strong>: 모든 레벨에서 데이터 보안 및 접근 제어</li><li><strong>데이터 접근성</strong>: 필요시 사용자가 데이터에 접근할 수 있도록 보장</li></ol><h3 id=데이터-파이프라인>데이터 파이프라인<a hidden class=anchor aria-hidden=true href=#데이터-파이프라인>#</a></h3><ul><li><strong>데이터 파이프라인</strong>: 데이터가 소스에서 목적지 (분석 시스템) 까지 자동으로 흐르는 구조.<br>수집→스테이징→처리→저장→소비 흐름을 가지며, 설계 원칙에 따라 모듈화되고 확장 가능하며 신뢰성을 갖추어야 한다.</li><li><strong>단계별 흐름</strong>:<ol><li><strong>수집 (Ingestion)</strong>: API, 로그, 센서 등에서 원시 데이터 획득</li><li><strong>스테이징 (Staging/Raw 저장소)</strong>: 간단한 정제 후 원본 저장</li><li><strong>정제 및 처리 (Preparation/Transform)</strong>: ETL/ELT, 이상치 제거, 스키마 통합</li><li><strong>저장 및 제공 (Storage/Serving)</strong>: Data Lake &lt;-> Data Warehouse</li><li><strong>소비 (Consumption)</strong>: 분석, BI, 머신러닝, 애플리케이션</li></ol></li></ul><pre class=mermaid>flowchart LR
  src[Data Source] --&gt; ingest[Ingestion]
  ingest --&gt; staging[Raw Zone]
  staging --&gt; transform[ETL/ELT Transform]
  transform --&gt; storage[Data Lake / Warehouse]
  storage --&gt; consume[BI / ML / Apps]
</pre><h4 id=전체-아키텍처-개요>전체 아키텍처 개요<a hidden class=anchor aria-hidden=true href=#전체-아키텍처-개요>#</a></h4><p>데이터 과학 및 엔지니어링 아키텍처는 아래 계층들로 구성된다:</p><table><thead><tr><th>계층</th><th>주요 요소</th><th>설명</th></tr></thead><tbody><tr><td><strong>데이터 수집</strong></td><td>Kafka, Flume, API</td><td>원시 데이터 스트리밍/배치 수집</td></tr><tr><td><strong>스테이징/스테이지존</strong></td><td>S3, HDFS, Blob</td><td>원천 데이터를 임시 보관</td></tr><tr><td><strong>처리</strong></td><td>Spark, Flink, Beam</td><td>정제, 피처 생성, 배치/스트리밍 처리</td></tr><tr><td><strong>저장 및 제공</strong></td><td>Data Lake, DW, OLAP, NoSQL</td><td>분석/머신러닝 모델 준비된 데이터 보관</td></tr><tr><td><strong>오케스트레이션</strong></td><td>Airflow, Luigi, Argo</td><td>파이프라인 워크플로우 관리</td></tr><tr><td><strong>모델 및 소비 계층</strong></td><td>Jupyter, Tensorflow Serving, PowerBI</td><td>ML 모델 배포, 분석, 시각화</td></tr><tr><td><strong>메타·보안·모니터링</strong></td><td>Data Catalog, Lineage, IAM, Audit</td><td>데이터 거버넌스와 보안 체계 관리</td></tr></tbody></table><pre class=mermaid>graph TD
  subgraph Data Ingestion
    A[Source Systems] --&gt; B[Kafka / API / Batch Load]
  end
  subgraph Landing Zone
    B --&gt; C[&#34;Raw Storage (S3/HDFS)&#34;]
  end
  subgraph Processing
    C --&gt; D[ETL/ELT Spark/Flink]
    D --&gt; E[Feature Store]
  end
  subgraph Storage &amp; Serving
    E --&gt; F[Data Warehouse / OLAP]
    E --&gt; G[ML Model Training]
  end
  subgraph Consumption
    F --&gt; H[BI / Dashboards]
    G --&gt; I[Model Serving / Predictions]
  end
  subgraph Governance &amp; Orchestration
    D --&gt; J[Airflow Orchestration]
    C --&gt; K[Data Catalog &amp; Lineage]
    All --&gt; L[IAM / Audit / Monitoring]
  end
</pre><h3 id=구현-기법>구현 기법<a hidden class=anchor aria-hidden=true href=#구현-기법>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>기법</strong></th><th><strong>정의</strong></th><th><strong>구성 요소</strong></th><th><strong>목적</strong></th><th><strong>대표 기술/툴</strong></th><th><strong>실무 적용 예시</strong></th></tr></thead><tbody><tr><td><strong>데이터 이동/수집</strong></td><td>ETL (Extract → Transform → Load)</td><td>데이터를 정제 후 적재하는 전통적 파이프라인 방식</td><td>추출 모듈, 변환 로직, 적재 모듈</td><td>품질 높은 데이터 적재</td><td>Airflow, Spark, dbt, Talend</td><td>CRM 데이터 → DWH 로 이관</td></tr><tr><td></td><td>ELT (Extract → Load → Transform)</td><td>대용량 데이터를 원본 그대로 적재 후 나중에 변환</td><td>저장소, 인메모리 처리 엔진</td><td>클라우드 분석, 스케일 대응</td><td>Snowflake, BigQuery, dbt</td><td>IoT 원시 데이터 → S3 후 Spark 로 변환</td></tr><tr><td></td><td>데이터 수집 자동화</td><td>다양한 소스에서 실시간/정기 데이터 수집 자동화</td><td>커넥터, API, 데이터 브로커</td><td>반복작업 자동화</td><td>Apache NiFi, Fivetran</td><td>SaaS → DB 연동</td></tr><tr><td><strong>데이터 처리</strong></td><td>배치 처리 (Batch Processing)</td><td>일정 시간 단위로 데이터를 일괄 처리</td><td>스케줄러, 처리 모듈, 적재</td><td>대용량 집계, 리소스 최적화</td><td>Airflow, Spark, Cron</td><td>일일 매출 집계 리포트 생성</td></tr><tr><td></td><td>스트림 처리 (Stream Processing)</td><td>실시간 이벤트 기반 데이터 처리</td><td>Kafka, Flink, Spark Streaming</td><td>실시간 탐지, 즉시 반응</td><td>Kafka, Flink, AWS Kinesis</td><td>실시간 이상 거래 탐지</td></tr><tr><td></td><td>분산 처리 (Distributed Processing)</td><td>대규모 데이터의 병렬/분산 처리</td><td>클러스터, 처리 노드, 스케줄러</td><td>고성능 처리, 확장성</td><td>Apache Spark, Hadoop</td><td>대규모 로그 분석 (TB 단위)</td></tr><tr><td><strong>머신러닝 운영</strong></td><td>MLOps</td><td>모델 배포 및 운영 자동화</td><td>모델 등록, 모니터링, 재학습</td><td>모델 재현성, 지속 운영</td><td>MLflow, Kubeflow, Vertex AI</td><td>예측 모델 자동 재배포</td></tr><tr><td></td><td>Feature Store</td><td>머신러닝 특성 저장소 관리</td><td>피처 등록, 버전 관리, API</td><td>일관된 특성 제공</td><td>Feast, Tecton</td><td>고객 피처 공유 및 서빙</td></tr><tr><td><strong>데이터 관리</strong></td><td>데이터 거버넌스</td><td>메타데이터, 계보, 권한, 품질 관리</td><td>Data Catalog, IAM, Lineage 엔진</td><td>컴플라이언스, 감사 추적</td><td>Apache Atlas, Amundsen, DataHub</td><td>GDPR 대응을 위한 개인정보 흐름 추적</td></tr><tr><td></td><td>자동화 오케스트레이션</td><td>파이프라인 워크플로우 자동 실행</td><td>DAG, 트리거, 에러 핸들러</td><td>신뢰성 높은 처리 자동화</td><td>Airflow, Prefect, Argo</td><td>DAG 기반 ETL 흐름 설계</td></tr><tr><td><strong>데이터 활용/소비</strong></td><td>데이터 시각화 및 분석</td><td>분석 결과를 시각화 및 공유</td><td>대시보드, 시각화 도구</td><td>인사이트 전달</td><td>Tableau, Power BI, matplotlib</td><td>KPI 분석 보고서 생성</td></tr><tr><td></td><td>모델 서빙</td><td>실시간/배치로 모델 결과 제공</td><td>Serving API, 컨테이너</td><td>예측 결과 서비스</td><td>TensorFlow Serving, FastAPI</td><td>추천 API + 웹 서비스 연동</td></tr></tbody></table><ul><li><strong>ETL/ELT 구분</strong>은 데이터 처리 위치와 방식에 따라 성능 및 유연성에서 차이가 난다.</li><li><strong>배치 vs 스트림 처리</strong>는 데이터 발생 주기와 분석 목적에 따라 선택한다.</li><li><strong>MLOps</strong>는 개발 - 운영 간 협업을 강화하며, <strong>Feature Store</strong>는 재현성과 협업의 핵심 도구이다.</li><li><strong>오케스트레이션 툴</strong>은 단일 작업뿐 아니라 장애 대응, 의존성 처리, 재시도 정책까지 관리 가능하다.</li></ul><h3 id=장단점>장단점<a hidden class=anchor aria-hidden=true href=#장단점>#</a></h3><h4 id=장점>장점<a hidden class=anchor aria-hidden=true href=#장점>#</a></h4><table><thead><tr><th>항목</th><th>설명</th></tr></thead><tbody><tr><td><strong>데이터 기반 의사결정</strong></td><td>정량적 인사이트로 전략적 판단을 지원하고 비즈니스 혁신 유도</td></tr><tr><td><strong>비즈니스 가치 창출</strong></td><td>데이터 분석을 통해 수익 창출 기회를 도출하고 신사업 가능성 발굴</td></tr><tr><td><strong>자동화 및 재현성</strong></td><td>ETL/ELT 파이프라인과 오케스트레이션으로 반복 가능하고 안정적인 처리 구현</td></tr><tr><td><strong>운영 효율성 향상</strong></td><td>자동화된 흐름으로 수작업 최소화, 처리 시간 단축</td></tr><tr><td><strong>예측 분석 가능</strong></td><td>머신러닝 기반 분석을 통해 수요 예측, 트렌드 분석 가능</td></tr><tr><td><strong>확장성</strong></td><td>클라우드 기반 인프라 및 분산 처리로 데이터 증가에도 유연 대응</td></tr><tr><td><strong>협업 강화</strong></td><td>Feature Store, 메타데이터 관리 등을 통해 데이터 과학자·엔지니어 간 협업 용이</td></tr><tr><td><strong>모델 일관성 유지</strong></td><td>데이터 정의 및 파이프라인 일관성 유지로 재현 가능하고 안정적인 모델 운영 가능</td></tr></tbody></table><h4 id=단점>단점<a hidden class=anchor aria-hidden=true href=#단점>#</a></h4><table><thead><tr><th>단점 항목</th><th>설명</th><th>해결 방안</th></tr></thead><tbody><tr><td><strong>초기 비용 부담</strong></td><td>인프라, 도구, 인력 확보 등 초기 구축에 상당한 비용 발생</td><td>🔧 단계적 도입, 클라우드 관리형 서비스 활용, PaaS 기반 요금 최적화</td></tr><tr><td><strong>기술 스택 복잡성</strong></td><td>다양한 도구와 컴포넌트로 인해 시스템 통합 및 설계 복잡</td><td>🔧 IaC + CI/CD 도입, 표준화된 도구/플랫폼 채택, 오케스트레이션 도구 활용</td></tr><tr><td><strong>성능 병목 가능성</strong></td><td>병렬성 부족, 비효율적 파이프라인 구성으로 처리 지연 발생</td><td>🔧 병렬 처리 및 캐싱 적용, Spark/Dask 등 분산 처리 도입, 성능 분석 도구 활용</td></tr><tr><td><strong>데이터 품질 문제</strong></td><td>불완전·부정확한 데이터로 인해 분석 결과 신뢰성 저하</td><td>🔧 데이터 표준화, 품질 관리 프로세스 수립, 데이터 거버넌스 및 자동 품질 진단 시스템</td></tr><tr><td><strong>보안 및 개인정보 위험</strong></td><td>민감 데이터 처리로 인해 유출, 위변조, 법적 이슈 발생</td><td>🔧 암호화, 접근 제어 (RBAC/ABAC), 데이터 마스킹 및 보안 감사 체계 구축</td></tr><tr><td><strong>전문 인력 부족</strong></td><td>데이터 엔지니어·과학자 확보 어려움, 운영 부담 가중</td><td>🔧 내부 교육 프로그램 운영, 외부 전문가와 파트너십, 기술 문서화 및 협업 체계 강화</td></tr><tr><td><strong>유지보수 및 운영 복잡도</strong></td><td>파이프라인 버전 충돌, 의존성 문제, 시스템 관리 부담</td><td>🔧 모듈화 설계, 로깅 및 테스트 자동화, 통합 모니터링 및 운영 대시보드 구축</td></tr></tbody></table><h3 id=문제점-및-해결-방안>문제점 및 해결 방안<a hidden class=anchor aria-hidden=true href=#문제점-및-해결-방안>#</a></h3><table><thead><tr><th>문제/과제 항목</th><th>설명</th><th>대응 방안</th></tr></thead><tbody><tr><td><strong>스키마 불일치</strong></td><td>소스 시스템 변경, 예외값 등으로 인해 데이터 스키마가 변형되어 ETL 오류 발생</td><td>Apache Avro/Protobuf 사용, 스키마 레지스트리 도입, 유효성 검증 자동화</td></tr><tr><td><strong>모델 편향 및 공정성 문제</strong></td><td>학습 데이터의 불균형으로 인해 모델이 특정 그룹에 편향되는 현상</td><td>SHAP, LIME 등 해석 가능한 모델 도구 활용, 데이터 리샘플링 및 편향 탐지</td></tr><tr><td><strong>로그 누락 및 추적 불가</strong></td><td>로깅 설정 미흡으로 장애 발생 시 디버깅 곤란</td><td>JSON 기반 구조화 로그, 필수 필드 체크 자동화, 로깅 테스트 포함 CI</td></tr><tr><td><strong>모델 운영 불일치</strong></td><td>실험 환경 (Jupyter) 과 운영 환경이 달라 모델 일관성 문제 발생</td><td>MLflow + Docker 기반 모델 배포 자동화, 모델 아티팩트 버전 관리</td></tr><tr><td><strong>협업 불일치</strong></td><td>데이터 엔지니어와 데이터 과학자 간의 흐름·표준·책임이 불명확</td><td>Feature Store, 데이터 버전 관리 (Git), 데이터 카탈로그 및 역할 정의</td></tr><tr><td><strong>데이터 통합 복잡도</strong></td><td>다양한 포맷 및 저장소에서 수집된 데이터를 통합 처리하는 데 구조적 문제</td><td>표준 포맷 (CSV, JSON, Parquet) 통일, API 기반 ETL, 가상 데이터 레이어 활용</td></tr></tbody></table><h3 id=도전-과제>도전 과제<a hidden class=anchor aria-hidden=true href=#도전-과제>#</a></h3><table><thead><tr><th>도전 과제</th><th>설명</th><th>해결 방안</th></tr></thead><tbody><tr><td><strong>실시간 처리 확장</strong></td><td>배치 중심 구조에서 스트리밍 처리 전환이 요구됨</td><td>Kafka + Flink 기반 스트리밍 아키텍처, Auto-scaling 및 Circuit Breaker 적용</td></tr><tr><td><strong>데이터 거버넌스 고도화</strong></td><td>컴플라이언스, 접근 통제, 변경 이력 추적 등의 필요성 증가</td><td>Data Lineage, RBAC 정책, 감사 로그 및 변경 추적 도구 도입</td></tr><tr><td><strong>확장성 기반 재설계</strong></td><td>기존 시스템이 수평 확장을 고려하지 않은 구조일 경우 병목 발생</td><td>컨테이너 기반 마이크로서비스, 메시지 큐 기반 비동기 처리</td></tr><tr><td><strong>하이브리드 환경 전환</strong></td><td>온프레미스 ↔ 클라우드/멀티클라우드 환경으로 전환하는 복잡성</td><td>점진적 마이그레이션 전략, 클라우드 네이티브 도구 채택 (Terraform, Helm 등)</td></tr><tr><td><strong>AI 통합 및 운영 자동화 (MLOps)</strong></td><td>ML 실험/검증/배포/모니터링의 자동화가 미흡</td><td>MLflow + Airflow, Feature Store, 컨테이너 기반 MLOps 파이프라인 구축</td></tr></tbody></table><h3 id=분류-기준에-따른-종류-및-유형>분류 기준에 따른 종류 및 유형<a hidden class=anchor aria-hidden=true href=#분류-기준에-따른-종류-및-유형>#</a></h3><table><thead><tr><th><strong>분류 카테고리</strong></th><th><strong>분류 기준</strong></th><th><strong>유형</strong></th><th><strong>설명</strong></th><th><strong>대표 사용 사례</strong></th></tr></thead><tbody><tr><td><strong>1. 처리 방식 (Processing Method)</strong></td><td>처리 유형</td><td><strong>배치 처리 (Batch Processing)</strong></td><td>일정 주기로 대량의 데이터를 일괄 처리하는 방식</td><td>일일 보고서 생성, 야간 ETL, 월간 매출 통계</td></tr><tr><td></td><td></td><td><strong>스트림 처리 (Stream Processing)</strong></td><td>실시간으로 데이터가 유입되는 즉시 처리</td><td>실시간 로그 분석, 이상 탐지, 실시간 알림</td></tr><tr><td></td><td></td><td><strong>마이크로 배치 (Micro-batch)</strong></td><td>짧은 시간 간격으로 작은 데이터 묶음을 처리</td><td>Spark Structured Streaming 기반 준실시간 처리</td></tr><tr><td><strong>2. 아키텍처 스타일 (Architectural Style)</strong></td><td>설계 구조</td><td><strong>람다 아키텍처 (Lambda)</strong></td><td>배치 + 스트림 처리를 통합하여 정확성과 실시간성 동시 보장</td><td>복합 분석 플랫폼 (예: Fraud detection + 집계 리포트)</td></tr><tr><td></td><td></td><td><strong>카파 아키텍처 (Kappa)</strong></td><td>스트림 처리만을 중심으로 모든 분석을 처리</td><td>이벤트 기반 분석 시스템 (IoT, 실시간 피드)</td></tr><tr><td></td><td></td><td><strong>델타 아키텍처 (Delta)</strong></td><td>데이터 레이크에 ACID 트랜잭션과 변경 이력 기능을 결합한 아키텍처</td><td>데이터 분석 및 ML 학습 이력 관리 (예: Databricks Delta Lake)</td></tr><tr><td><strong>3. 파이프라인 구조 (Pipeline Structure)</strong></td><td>구성 방식</td><td><strong>모놀리식 (Monolithic)</strong></td><td>ETL 전 과정을 하나의 덩어리로 구성</td><td>단일 서버 기반 ETL 시스템</td></tr><tr><td></td><td></td><td><strong>모듈형 (Modular)</strong></td><td>각 단계 (Extract, Transform, Load) 를 분리한 구조</td><td>Airflow, Prefect 기반의 단계별 파이프라인 구성</td></tr><tr><td></td><td></td><td><strong>마이크로서비스 기반 (Microservices)</strong></td><td>각 파이프라인 기능을 독립적인 서비스로 구성</td><td>이벤트 기반 데이터 처리 시스템 (Kafka + Kafka Connect 등)</td></tr><tr><td><strong>4. 배포 환경 (Deployment Environment)</strong></td><td>인프라 환경</td><td><strong>온프레미스 (On-premise)</strong></td><td>자체 IDC 혹은 사내 인프라를 통한 운영</td><td>금융기관 내부망 분석 시스템, 내부 보안 시스템</td></tr><tr><td></td><td></td><td><strong>클라우드 (Cloud)</strong></td><td>퍼블릭 클라우드의 관리형 서비스를 활용한 배포</td><td>AWS Glue, Google Dataflow, Azure Synapse</td></tr><tr><td></td><td></td><td><strong>하이브리드 (Hybrid)</strong></td><td>온프레미스와 클라우드를 병행하여 구성</td><td>점진적 클라우드 이전, 민감 정보는 내부 처리, 나머지 외부 분석</td></tr><tr><td><strong>5. 저장 구조 (Storage Architecture)</strong></td><td>저장 방식</td><td><strong>데이터 웨어하우스 (Data Warehouse)</strong></td><td>정형 데이터를 정제하여 저장하는 OLAP 최적화 구조</td><td>Snowflake, BigQuery, Amazon Redshift 등</td></tr><tr><td></td><td></td><td><strong>데이터 레이크 (Data Lake)</strong></td><td>원시 데이터를 다양한 포맷으로 저장 가능, 정형/비정형 포함</td><td>S3 + Athena, Azure Data Lake, GCP Cloud Storage</td></tr><tr><td></td><td></td><td><strong>데이터 메쉬 (Data Mesh)</strong></td><td>도메인 중심 데이터 분산 및 자율 운영 구조</td><td>대규모 조직의 부서별 자체 데이터 파이프라인 운영 구조</td></tr><tr><td><strong>6. 오케스트레이션 방식 (Orchestration Strategy)</strong></td><td>실행 트리거</td><td><strong>스케줄 기반 (Scheduling)</strong></td><td>지정된 시간/주기로 파이프라인을 실행</td><td>Cron + Airflow DAGs, 정기 리포트 생성</td></tr><tr><td></td><td></td><td><strong>이벤트 기반 (Event-driven)</strong></td><td>이벤트 발생 시 파이프라인이 트리거됨</td><td>Kafka 이벤트 → S3 적재 → 알림 전송</td></tr><tr><td></td><td></td><td><strong>워크플로우 기반 (Workflow-centric)</strong></td><td>여러 작업 간 의존성 정의 및 조건부 흐름 구성</td><td>DAG 기반 다단계 워크플로우 (예: Airflow, Dagster 등)</td></tr><tr><td><strong>7. 데이터 소스 (Data Source Type)</strong></td><td>데이터 구조 유형</td><td><strong>구조화 데이터 (Structured)</strong></td><td>스키마가 명확한 데이터 (예: RDB, CSV)</td><td>고객 DB, ERP 시스템 데이터</td></tr><tr><td></td><td></td><td><strong>반구조화 데이터 (Semi-structured)</strong></td><td>JSON, XML 등 계층 구조가 있으나 스키마가 유동적인 데이터</td><td>웹 로그, 센서 로그, API 응답 데이터</td></tr><tr><td></td><td></td><td><strong>비구조화 데이터 (Unstructured)</strong></td><td>이미지, 동영상, PDF 등 스키마가 없는 데이터</td><td>문서 인식 처리, 영상 분석, 텍스트 마이닝</td></tr><tr><td><strong>8. 분석 목적 (Analytics Goal)</strong></td><td>분석 목표</td><td><strong>기술 분석 (Descriptive)</strong></td><td>과거 데이터 요약 및 시각화 분석</td><td>매출 리포트, 사용자 행동 분석</td></tr><tr><td></td><td></td><td><strong>예측 분석 (Predictive)</strong></td><td>머신러닝을 통해 미래 예측</td><td>수요 예측, 이탈 예측</td></tr><tr><td></td><td></td><td><strong>설명 분석 (Explainable)</strong></td><td>인사이트 도출, 인과 관계 설명 중심 분석</td><td>KPI 영향 요인 분석, 원인 분석 리포트</td></tr><tr><td></td><td></td><td><strong>탐색적 분석 (Exploratory)</strong></td><td>데이터 구조 및 분포 탐색</td><td>신규 비즈니스 모델 탐색, 가설 수립을 위한 탐색적 분석</td></tr><tr><td><strong>9. 산업 도메인 (Industry Vertical)</strong></td><td>적용 산업</td><td><strong>금융 (Finance)</strong></td><td>거래 분석, 사기 탐지, 규제 준수 분석</td><td>AML, 리스크 관리 시스템</td></tr><tr><td></td><td></td><td><strong>제조 (Manufacturing)</strong></td><td>품질 예측, 생산 최적화</td><td>설비 예지 정비, 불량률 분석</td></tr><tr><td></td><td></td><td><strong>의료 (Healthcare)</strong></td><td>환자 데이터 분석, 예후 예측</td><td>질병 예측, EMR 분석</td></tr><tr><td></td><td></td><td><strong>공공 (Public Sector)</strong></td><td>행정/통계 데이터 활용</td><td>인구통계 분석, 교통 데이터 시뮬레이션</td></tr></tbody></table><h3 id=실무-적용-예시>실무 적용 예시<a hidden class=anchor aria-hidden=true href=#실무-적용-예시>#</a></h3><table><thead><tr><th><strong>도메인</strong></th><th><strong>활용 목적</strong></th><th><strong>주요 기술 스택</strong></th><th><strong>활용 방식</strong></th><th><strong>비즈니스 효과</strong></th></tr></thead><tbody><tr><td><strong>전자상거래</strong></td><td>개인화 추천, 구매 전환율 향상</td><td>Kafka, Spark, Redis, TensorFlow</td><td>사용자 행동 분석 + 추천 모델 실시간 서빙</td><td>매출 증가, 이탈률 감소, 고객 만족도 향상</td></tr><tr><td><strong>금융</strong></td><td>실시간 이상 거래 탐지, 리스크 분석</td><td>Flink, Elasticsearch, ML 모델, Kafka</td><td>스트리밍 데이터 기반 이상 패턴 감지 및 자동 알림</td><td>사기 거래 차단, 리스크 대응 시간 단축</td></tr><tr><td><strong>제조업</strong></td><td>장비 이상 예측, 생산성 최적화</td><td>IoT, Time Series DB, SageMaker, MQTT</td><td>센서 데이터 수집 → ML 기반 예지 정비 → 생산 계획 최적화</td><td>다운타임 감소, 유지보수 비용 절감</td></tr><tr><td><strong>헬스케어</strong></td><td>환자 모니터링, 진단 보조</td><td>HL7 FHIR, Apache NiFi, PowerBI, AutoML</td><td>실시간 생체 데이터 분석, 병원 진단 기록 기반 보조 진단 시스템 구축</td><td>응급상황 조기 감지, 의료 서비스 품질 향상</td></tr><tr><td><strong>리테일/유통</strong></td><td>판매 트렌드 분석, 재고 최적화</td><td>Spark, Delta Lake, Tableau, Feature Store</td><td>지역별/제품별 매출 패턴 분석 → 재고 정책 자동화</td><td>재고 비용 절감, 공급망 효율성 개선</td></tr><tr><td><strong>미디어/콘텐츠</strong></td><td>콘텐츠 소비 패턴 분석, 사용자 반응 예측</td><td>Hadoop, TensorFlow, Keras</td><td>사용자 시청 이력 분석 + 시청률 예측 모델 학습</td><td>프로그램/광고 효율 최적화, 고객 타겟팅 정확도 향상</td></tr><tr><td><strong>광고/마케팅</strong></td><td>캠페인 반응 예측, 고객 세분화</td><td>Airflow, Feast, ML 모델, A/B 테스트 플랫폼</td><td>실험군 기반 캠페인 테스트 + 클릭률/전환율 예측</td><td>광고 ROI 향상, 예산 최적 분배</td></tr><tr><td><strong>물류/운송</strong></td><td>경로 최적화, 배송 ETA 예측</td><td>GPS API, Graph Algorithms, XGBoost</td><td>실시간 교통 데이터 + 과거 배송 패턴 분석 → 동적 경로 추천</td><td>배송 지연 감소, 연료비 절감, 고객 만족도 향상</td></tr><tr><td><strong>공공/정부</strong></td><td>인구 통계 기반 정책 수립, 공공 안전 예측</td><td>GIS 데이터, Spark, 머신러닝 기반 통계 분석 도구</td><td>범죄 발생 예측, 인구밀도 기반 자원 재배치</td><td>정책 효율화, 사회적 비용 절감</td></tr><tr><td><strong>에너지/환경</strong></td><td>에너지 수요 예측, 이상 소비 탐지</td><td>Smart Meter + IoT, 시계열 예측 모델, 데이터 레이크</td><td>에너지 사용 패턴 분석 + 이상 탐지 → 부하 분산 및 요금 최적화</td><td>전력 낭비 감소, 탄소 배출 절감</td></tr></tbody></table><ul><li><strong>Data Science and Engineering</strong>은 <strong>도메인별 특화 목적</strong>에 따라 기술을 달리하며 적용된다.</li><li><strong>단일 기술이 아닌 조합된 파이프라인</strong> (데이터 수집 → 처리 → 분석 → 시각화/예측) 이 실무 효과를 창출한다.</li><li>핵심은 <strong>데이터를 통한 자동화된 의사결정과 가치 창출</strong>이다.</li></ul><h3 id=활용-사례>활용 사례<a hidden class=anchor aria-hidden=true href=#활용-사례>#</a></h3><h4 id=사례-1-우버의-실시간-위치-추적-시스템>사례 1: 우버의 실시간 위치 추적 시스템<a hidden class=anchor aria-hidden=true href=#사례-1-우버의-실시간-위치-추적-시스템>#</a></h4><p><strong>시스템 구성</strong>:</p><pre class=mermaid>graph TB
    subgraph &#34;데이터 수집&#34;
        A1[드라이버 앱] --&gt; B1[Kafka]
        A2[승객 앱] --&gt; B1
        A3[GPS 센서] --&gt; B1
    end
    
    subgraph &#34;실시간 처리&#34;
        B1 --&gt; C1[Apache Flink]
        C1 --&gt; C2[위치 매칭 알고리즘]
        C2 --&gt; C3[ETA 계산]
    end
    
    subgraph &#34;데이터 저장&#34;
        C3 --&gt; D1[Redis Cache]
        C3 --&gt; D2[Cassandra]
        C3 --&gt; D3[Hadoop HDFS]
    end
    
    subgraph &#34;서비스&#34;
        D1 --&gt; E1[실시간 매칭 API]
        D2 --&gt; E2[운전자 대시보드]
        D3 --&gt; E3[분석 리포트]
    end
</pre><p><strong>Workflow</strong>:</p><ol><li>모바일 앱에서 GPS 위치 데이터를 Kafka 로 스트리밍 전송</li><li>Flink 가 실시간으로 위치 데이터를 처리하여 승객 - 드라이버 매칭</li><li>Redis 에 실시간 위치 정보 캐싱으로 빠른 응답 제공</li><li>Cassandra 에 운행 기록 저장, HDFS 에 장기 분석용 데이터 보관</li></ol><p><strong>Data Science and Engineering 의 역할</strong>:</p><ul><li><strong>데이터 엔지니어링</strong>: 초당 수백만 건의 위치 데이터 실시간 처리 파이프라인 구축</li><li><strong>데이터 과학</strong>: 최적 경로 알고리즘, 수요 예측 모델, 동적 가격 책정 모델 개발</li><li><strong>MLOps</strong>: 실시간 매칭 모델의 지속적 모니터링 및 성능 최적화</li></ul><h4 id=사례-2-금융권-이상-거래-탐지-시스템>사례 2: 금융권 이상 거래 탐지 시스템<a hidden class=anchor aria-hidden=true href=#사례-2-금융권-이상-거래-탐지-시스템>#</a></h4><p><strong>시스템 구성:</strong></p><ul><li>데이터 소스: 거래 DB, 로그</li><li>데이터 수집: Kafka</li><li>데이터 저장: Hadoop</li><li>데이터 처리: Spark</li><li>데이터 분석: Python, Scikit-learn</li><li>시각화: Tableau</li></ul><p><strong>Workflow:</strong></p><ul><li>거래 데이터 수집 → 데이터 저장 → 데이터 처리 → 이상 거래 탐지 모델링 → 탐지 결과 시각화 및 보고</li></ul><p><strong>역할:</strong></p><ul><li>데이터 엔지니어: 데이터 수집, 저장, 처리 인프라 구축</li><li>데이터 과학자: 이상 거래 탐지 모델 개발 및 분석</li><li>비즈니스 분석가: 분석 결과 해석 및 보고</li></ul><pre class=mermaid>graph TD
    A[거래 DB/로그] --&gt; B[Kafka]
    B --&gt; C[Hadoop]
    C --&gt; D[Spark]
    D --&gt; E[Python/Scikit-learn]
    E --&gt; F[Tableau]
</pre><h3 id=실무에서-효과적으로-적용하기-위한-고려사항-및-주의할-점>실무에서 효과적으로 적용하기 위한 고려사항 및 주의할 점<a hidden class=anchor aria-hidden=true href=#실무에서-효과적으로-적용하기-위한-고려사항-및-주의할-점>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>고려사항</strong></th><th><strong>주의할 점</strong></th><th><strong>권장사항</strong></th></tr></thead><tbody><tr><td><strong>1. 데이터 품질 및 거버넌스</strong></td><td>데이터 오류, 누락, 중복</td><td>이상 데이터로 인한 분석 왜곡</td><td>데이터 표준화, 자동 검증 프로세스, 데이터 계약 (Data Contract) 체계 도입</td></tr><tr><td></td><td>민감 데이터 보호 및 규제 대응</td><td>GDPR, CCPA 등 법률 미준수 위험</td><td>필드 단위 암호화, 접근 제어, 마스킹, 감사 로그 및 법적 준수 체크리스트 적용</td></tr><tr><td><strong>2. 인프라 및 확장성</strong></td><td>대규모 처리 및 비용 효율성</td><td>과도한 초기 인프라 투자 또는 스케일링 한계</td><td>클라우드 기반 확장성 확보 (예: AWS Glue, GCP Dataflow), 분산처리 프레임워크 활용</td></tr><tr><td></td><td>시스템 복원력 및 장애 대응</td><td>재처리 복잡성, 장애 발생 시 추적 어려움</td><td>상태 기반 DAG (Airflow), Retry 정책, 체크포인트 및 장애 복구 자동화</td></tr><tr><td><strong>3. 협업 및 조직 체계</strong></td><td>데이터 팀 간 협력 (엔지니어, 분석가 등)</td><td>부서 간 사일로 (Silo), 책임 불명확</td><td>명확한 역할 분담 (R&amp;R), 정기적인 크로스펑셔널 회의, 협업 도구 (Git, Notion 등) 활용</td></tr><tr><td></td><td>모델 및 파이프라인 버전 관리</td><td>스키마 불일치, 모델 재현성 부족</td><td>Git + DVC(Data Version Control) 병행, 모델 아티팩트 관리 체계 도입</td></tr><tr><td><strong>4. 워크플로우 및 자동화</strong></td><td>ETL 오류 및 파이프라인 신뢰성</td><td>수동 복구, 실패 처리 누락</td><td>워크플로우 기반 설계 (DAG), 오류 감지 자동화, 로그 기반 모니터링</td></tr><tr><td></td><td>모델 운영 자동화 (MLOps)</td><td>실험과 운영 환경 간 불일치</td><td>MLflow, CI/CD, 컨테이너 기반 모델 배포 및 운영 관측 시스템 구축</td></tr><tr><td><strong>5. 기술 선정 및 관리 전략</strong></td><td>도구/프레임워크 선택 전략</td><td>과도한 도구 사용 → 기술 부채</td><td>요구사항 기반 최소 구성, 검증된 오픈소스 및 커뮤니티 지원 도구 우선 활용</td></tr><tr><td></td><td>모니터링 및 관측 가능성 강화</td><td>장애 조기 탐지 실패, SLA 미준수</td><td>Prometheus + Grafana, 알림 시스템 (Slack, Opsgenie 등) 통합</td></tr></tbody></table><h3 id=최적화하기-위한-고려사항-및-주의할-점>최적화하기 위한 고려사항 및 주의할 점<a hidden class=anchor aria-hidden=true href=#최적화하기-위한-고려사항-및-주의할-점>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>고려사항</strong></th><th><strong>주의할 점</strong></th><th><strong>권장사항</strong></th></tr></thead><tbody><tr><td><strong>1. 성능 최적화</strong></td><td>대용량 데이터 처리 속도 개선</td><td>병목 현상, GC 과다, 메모리 부족 등</td><td>파티셔닝, 조인 조건 최적화, 인덱싱, 컬럼 기반 포맷 사용 (Parquet/ORC), 캐싱 전략 설계</td></tr><tr><td></td><td>병렬 처리 구성 및 DAG 최적화</td><td>태스크 과다 생성 또는 비효율적 분산 처리</td><td>Spark Executor 병렬도 조절, 병렬 Task 수 제한, Broadcast Join 활용</td></tr><tr><td></td><td>포맷 및 I/O 최적화</td><td>불필요한 중복 데이터 로드</td><td>Parquet, ORC 등 압축 컬럼 포맷 사용, Selective Column Load 적용</td></tr><tr><td><strong>2. 비용 최적화</strong></td><td>클라우드/인프라 비용 절감</td><td>유휴 리소스 미회수로 인한 비용 낭비</td><td>자동 스케일링, 예약 인스턴스 활용, 비용 모니터링 지표 기반 리소스 리사이징</td></tr><tr><td></td><td>서버리스 vs 클러스터형 비용 비교</td><td>트래픽 예측 실패 시 과금 폭증 가능성</td><td>스팟 인스턴스, 서버리스 (Fargate/Cloud Run) 기반 자동 처리 구성</td></tr><tr><td><strong>3. 데이터 품질 관리</strong></td><td>지속적인 데이터 유효성 유지</td><td>이상치, 결측치, 포맷 오류 발생 가능성</td><td>자동화된 품질 진단 도구 (Great Expectations, Deequ), 정제 워크플로우 구성</td></tr><tr><td></td><td>데이터 재현성 및 일관성 확보</td><td>이력 불일치, 시간차로 인한 분석 왜곡</td><td>데이터 스냅샷 관리, DVC 기반 버전 추적, Feature Store 활용</td></tr><tr><td><strong>4. 모델 및 분석 최적화</strong></td><td>모델 성능 튜닝 및 정확도 개선</td><td>과적합 또는 과소적합, 학습 속도 저하</td><td>하이퍼파라미터 자동 탐색 (Optuna, Ray Tune), 모델 앙상블, Early Stopping 적용</td></tr><tr><td></td><td>모델 운영 재현성 확보</td><td>실험 환경과 서빙 환경 불일치</td><td>MLflow, Docker 기반 모델 패키징, 컨테이너 기반 배포 및 검증 테스트 적용</td></tr><tr><td><strong>5. 협업 및 운영 체계</strong></td><td>데이터 및 모델 버전 관리</td><td>스키마 변경/모델 변경으로 인한 시스템 불안정</td><td>Git + DVC + DBT 연계, 스키마 체인지 테스트 자동화</td></tr><tr><td></td><td>프로세스 표준화 및 협업 효율화</td><td>팀 간 의사소통 부재, 파이프라인 중복 개발</td><td>공통 템플릿 (예: YAML 파이프라인 정의), 공통 저장소 관리, 표준화된 문서 작성 (Data Contract 등)</td></tr><tr><td><strong>6. 보안 및 접근 통제</strong></td><td>운영 데이터에 대한 접근 보호</td><td>데이터 유출, 무단 접근 위험</td><td>Field-level 암호화, Zero Trust 보안 모델, RBAC/ABAC 정책 기반 IAM 설계</td></tr><tr><td></td><td>작업 기록 및 모니터링 강화</td><td>감사 로그 누락 또는 장애 조기 탐지 실패</td><td>로그 중앙 수집 + 이상 탐지 연계, 실시간 알림 및 복구 자동화 (PagerDuty, Slack 연동)</td></tr></tbody></table><h3 id=주제와-관련하여-주목할-내용>주제와 관련하여 주목할 내용<a hidden class=anchor aria-hidden=true href=#주제와-관련하여-주목할-내용>#</a></h3><table><thead><tr><th><strong>분류</strong></th><th><strong>항목</strong></th><th><strong>설명</strong></th><th><strong>주요 기술/도구</strong></th></tr></thead><tbody><tr><td><strong>핵심 영역</strong></td><td>데이터 과학</td><td>머신러닝, 통계 분석을 기반으로 데이터에서 인사이트를 추출하고 예측 모델을 구축</td><td>scikit-learn, TensorFlow, XGBoost</td></tr><tr><td></td><td>데이터 엔지니어링</td><td>데이터 수집 → 처리 → 저장 → 전달까지 전체 파이프라인 구성 및 운영</td><td>Apache Airflow, Kafka, dbt, Spark</td></tr><tr><td></td><td>빅데이터</td><td>대용량, 고속, 다양성 (3V) 을 갖춘 데이터의 저장 및 처리 체계</td><td>Hadoop, Spark, Presto, ClickHouse</td></tr><tr><td></td><td>MLOps</td><td>모델 학습부터 배포, 모니터링, 롤백까지 전 주기 자동화 및 관리</td><td>MLflow, Kubeflow, SageMaker, BentoML</td></tr><tr><td></td><td>데이터 거버넌스</td><td>데이터 품질 확보, 접근 제어, 표준화 및 법적 준수를 위한 관리 체계</td><td>Data Catalog, Great Expectations, Amundsen, Collibra</td></tr><tr><td><strong>신기술 동향</strong></td><td>제로 ETL (Zero ETL)</td><td>소스 시스템에서 목적지로 데이터 이동 없이 직접 분석 가능 (클라우드 통합 서비스로 구현)</td><td>AWS Aurora → Redshift, GCP BigQuery Omni 등</td></tr><tr><td></td><td>실시간 AI/ML</td><td>스트리밍 데이터에 대해 실시간 추론 수행, 즉시 반응이 필요한 시스템에 적용</td><td>Kafka + Flink + TensorFlow Serving</td></tr><tr><td></td><td>데이터 패브릭</td><td>멀티/하이브리드 클라우드 환경에서 통합된 데이터 관리와 접근 제어를 지원하는 가상 데이터 계층 구조</td><td>IBM Data Fabric, Talend Data Fabric, Starburst</td></tr><tr><td></td><td>데이터 메시 (Data Mesh)</td><td>도메인 중심 데이터 분산 소유와 자율 운영을 지원하는 조직적 접근 방식</td><td>팀 단위의 데이터 제품 개발 구조, DDD 기반 데이터 관리</td></tr><tr><td><strong>표준 및 최적화 전략</strong></td><td>OpenLineage</td><td>데이터 처리 흐름과 계보 (lineage) 추적을 위한 오픈 표준 프로토콜</td><td>Apache Airflow, dbt, Marquez 연동 가능</td></tr><tr><td></td><td>Apache Iceberg</td><td>대용량 데이터를 위한 테이블 포맷으로, 스키마 진화, ACID 트랜잭션, 시간여행 등을 지원</td><td>AWS Athena, Snowflake, Dremio 등과 호환</td></tr><tr><td></td><td>OmegaConf</td><td>YAML 기반 설정 및 하이퍼파라미터 관리 프레임워크로, 재현성과 구성 관리에 유리</td><td>ML 실험 재현, 다양한 config 환경 통합 관리에 활용</td></tr><tr><td></td><td>델타 레이크</td><td>ACID 트랜잭션, 타임 트래블, 병합 처리 등 지원하는 Lakehouse 스토리지 계층</td><td>Databricks Delta Lake, Apache Hudi, Apache Iceberg</td></tr><tr><td></td><td>컬럼형 저장소</td><td>분석 쿼리 최적화를 위한 컬럼 기반 데이터 포맷, 저장 효율 및 조회 성능 향상</td><td>Parquet, ORC, Arrow 등</td></tr><tr><td></td><td>인메모리 컴퓨팅</td><td>디스크 I/O 를 최소화하고 빠른 처리 성능을 제공하는 메모리 기반 처리 아키텍처</td><td>Apache Spark, Redis, Memcached, Dask</td></tr></tbody></table><ul><li><strong>핵심 기술 5 가지</strong>: 데이터 과학, 엔지니어링, 빅데이터, MLOps, 거버넌스</li><li><strong>신기술 4 가지</strong>: Zero ETL, Real-time ML, Data Fabric, Data Mesh</li><li><strong>최적화/표준 6 가지</strong>: OpenLineage, Iceberg, OmegaConf, Delta Lake, Parquet/ORC, Spark/Redis 기반 인메모리</li></ul><h3 id=추가-학습-영역>추가 학습 영역<a hidden class=anchor aria-hidden=true href=#추가-학습-영역>#</a></h3><table><thead><tr><th><strong>카테고리</strong></th><th><strong>설명</strong></th><th><strong>세부 학습 주제</strong></th></tr></thead><tbody><tr><td><strong>1. 고급 분석 및 통계 기법</strong></td><td>복잡한 현상 예측, 비즈니스 의사결정 지원</td><td>시계열 분석, 베이지안 추론, 인과 추론, 실험 설계 (DOE), 생존 분석</td></tr><tr><td><strong>2. 분산 및 병렬 컴퓨팅</strong></td><td>대규모 데이터 처리 최적화, 계산 시간 단축</td><td>Apache Spark, Dask, Ray, 병렬 알고리즘, 클러스터 스케줄링 (FIFO, FAIR)</td></tr><tr><td><strong>3. 실시간 데이터 시스템</strong></td><td>실시간 처리 및 이벤트 기반 아키텍처 구축</td><td>Kafka, Pulsar, Flink, Kinesis, Stream Processing 패턴, 지연 최소화 설계</td></tr><tr><td><strong>4. 클라우드 데이터 인프라</strong></td><td>확장 가능한 데이터 파이프라인을 위한 클라우드 환경 설계 및 운영</td><td>AWS Glue, Azure Data Factory, GCP Dataflow, IAM, 비용 최적화, 네트워크 설계</td></tr><tr><td><strong>5. 머신러닝 운영화 (MLOps)</strong></td><td>모델 개발 → 배포 → 모니터링 전체 수명 주기 자동화</td><td>MLflow, Kubeflow, SageMaker, Feature Store, 모델 Drift 감지, 재학습 트리거 설정</td></tr><tr><td><strong>6. 데이터 거버넌스 및 규제 대응</strong></td><td>데이터 품질·보안·정책 준수 관리 체계 구축</td><td>Data Catalog, Data Lineage, GDPR/CCPA, Data Quality Rules, 데이터 계약 (Data Contract)</td></tr><tr><td><strong>7. 데이터 파이프라인 자동화 및 DevOps</strong></td><td>인프라 및 워크플로우 자동화, 효율적인 운영 체계</td><td>Airflow, Prefect, Terraform, Kubernetes, CI/CD for ETL/MLOps</td></tr><tr><td><strong>8. 데이터 시각화 및 커뮤니케이션</strong></td><td>복잡한 분석 결과를 효과적으로 전달하고 인사이트 제공</td><td>Tableau, PowerBI, Plotly, Superset, 대시보드 설계 원칙, 스토리텔링 기반 데이터 전달</td></tr><tr><td><strong>9. 메타데이터 및 계보 관리</strong></td><td>데이터 흐름 및 의미적 문맥 추적으로 재현성과 통제력 향상</td><td>OpenLineage, Marquez, Amundsen, 유스케이스 기반 계보 추적 전략</td></tr><tr><td><strong>10. 데이터 아키텍처 및 설계 패턴</strong></td><td>유연하고 확장 가능한 분석 아키텍처 설계 기반 지식</td><td>Data Lakehouse, Data Mesh, Data Fabric, Lambda/Kappa/Delta 아키텍처 비교 분석</td></tr></tbody></table><hr><h2 id=용어-정리>용어 정리<a hidden class=anchor aria-hidden=true href=#용어-정리>#</a></h2><table><thead><tr><th><strong>카테고리</strong></th><th><strong>용어</strong></th><th><strong>설명</strong></th></tr></thead><tbody><tr><td><strong>1. 핵심 개념</strong></td><td>Data Science</td><td>데이터를 분석하여 인사이트를 도출하는 학문 및 실무 영역</td></tr><tr><td></td><td>Data Engineering</td><td>데이터 파이프라인, 저장소, 인프라를 설계·구축하는 기술 영역</td></tr><tr><td></td><td>Machine Learning</td><td>데이터를 학습하여 분류, 예측, 추천 등을 수행하는 알고리즘 기반 기술</td></tr><tr><td></td><td>Big Data</td><td>대용량, 고속, 다양한 구조의 데이터를 처리하는 기술/환경 (3V: Volume, Velocity, Variety)</td></tr><tr><td><strong>2. 데이터 처리 방식</strong></td><td>Batch Processing</td><td>일정 주기로 대량 데이터를 일괄 처리하는 방식</td></tr><tr><td></td><td>Stream Processing</td><td>데이터를 실시간으로 처리하는 방식</td></tr><tr><td></td><td>Micro-batch</td><td>짧은 간격의 작은 배치를 지속적으로 처리하여 준실시간성을 확보하는 방식</td></tr><tr><td><strong>3. 데이터 아키텍처</strong></td><td>Lambda Architecture</td><td>배치 + 스트림 처리를 병행하여 실시간성과 정확성을 모두 확보하는 아키텍처</td></tr><tr><td></td><td>Kappa Architecture</td><td>전체 데이터를 스트림 처리로만 처리하는 단순화된 구조의 아키텍처</td></tr><tr><td></td><td>Data Mesh</td><td>각 도메인이 자체적으로 데이터 제품을 책임지는 분산형 아키텍처 패러다임</td></tr><tr><td></td><td>Data Lakehouse</td><td>데이터 레이크와 데이터 웨어하우스의 장점을 결합한 통합 아키텍처</td></tr><tr><td><strong>4. 저장소 및 포맷</strong></td><td>Columnar Storage</td><td>컬럼 단위로 데이터를 저장하여 분석 쿼리 성능을 높이는 저장 방식</td></tr><tr><td></td><td>Delta Lake</td><td>ACID 트랜잭션 및 타임 트래블 기능을 제공하는 스토리지 계층</td></tr><tr><td></td><td>Apache Iceberg</td><td>대용량 테이블을 위한 개방형 포맷, 스키마 진화 및 시간 기반 쿼리 지원</td></tr><tr><td></td><td>ACID 트랜잭션</td><td>데이터 무결성을 보장하는 데이터베이스 트랜잭션 속성 (Atomicity, Consistency, Isolation, Durability)</td></tr><tr><td><strong>5. 워크플로우/운영</strong></td><td>DAG (Directed Acyclic Graph)</td><td>순환이 없는 방향성 그래프로 작업 흐름과 의존 관계를 표현하는 구조</td></tr><tr><td></td><td>Orchestration</td><td>작업 실행 순서와 의존성 관리를 자동화하는 시스템 (예: Airflow)</td></tr><tr><td></td><td>Containerization</td><td>실행 환경을 컨테이너에 패키징하여 어디서나 일관된 배포를 가능하게 하는 기술</td></tr><tr><td></td><td>Infrastructure as Code (IaC)</td><td>인프라 구성을 코드로 정의하고 형상 관리하는 방식 (예: Terraform)</td></tr><tr><td><strong>6. 머신러닝 운영 (MLOps)</strong></td><td>MLOps</td><td>머신러닝 모델 개발부터 배포, 모니터링까지 자동화하는 접근 방식</td></tr><tr><td></td><td>MLflow</td><td>실험 추적, 모델 배포, 서빙, 모니터링을 통합한 오픈소스 플랫폼</td></tr><tr><td></td><td>Feature Store</td><td>모델 학습과 예측에서 공통 피처를 저장하고 재사용하는 저장소 시스템</td></tr><tr><td></td><td>Data Drift</td><td>운영 중인 입력 데이터의 분포가 훈련 데이터와 달라지는 현상</td></tr><tr><td></td><td>Model Drift</td><td>시간이 지나며 모델 성능이 감소하는 현상</td></tr><tr><td><strong>7. 품질/거버넌스/보안</strong></td><td>Data Governance</td><td>품질, 보안, 표준화, 규제 준수를 포함한 데이터 전반의 관리 체계</td></tr><tr><td></td><td>Data Lineage</td><td>데이터의 출처, 흐름, 변환 이력을 추적하여 신뢰성과 투명성을 확보하는 방법</td></tr><tr><td></td><td>Data Profiling</td><td>데이터의 특성을 자동 분석하여 품질 문제를 탐지하는 프로세스</td></tr><tr><td></td><td>Schema Validation</td><td>데이터가 정의된 구조를 정확히 따르는지 확인하는 검증 절차</td></tr><tr><td></td><td>Zero Trust</td><td>네트워크 내외부를 구분하지 않고 모든 접근을 검증하는 보안 모델</td></tr><tr><td></td><td>Data Masking</td><td>민감 정보를 난독화하거나 대체하여 보안성을 확보하는 기법</td></tr><tr><td></td><td>RBAC (Role-Based Access Control)</td><td>역할 기반으로 시스템/데이터 접근 권한을 제어하는 방식</td></tr><tr><td><strong>8. 버전/설정 관리</strong></td><td>DVC (Data Version Control)</td><td>Git 과 연동된 데이터 및 모델 버전 관리 도구</td></tr><tr><td></td><td>OmegaConf</td><td>ML 실험 및 서비스 환경 설정을 구조화된 방식으로 관리하는 Python 기반 설정 프레임워크</td></tr></tbody></table><hr><h2 id=참고-및-출처>참고 및 출처<a hidden class=anchor aria-hidden=true href=#참고-및-출처>#</a></h2><h3 id=학술-자료>학술 자료<a hidden class=anchor aria-hidden=true href=#학술-자료>#</a></h3><ul><li><a href=http://cs.unibo.it/~danilo.montesi/CBD/Beatriz/10.1.1.198.5133.pdf>CRISP-DM: Towards a Standard Process Model for Data Mining</a></li><li><a href=https://www.sciencedirect.com/science/article/pii/S2212827119302239>DMME: Data Mining Methodology for Engineering Applications</a></li><li><a href=https://www.researchgate.net/publication/384999724_The_Evolution_of_CRISP-DM_for_Data_Science_Methods_Processes_and_Frameworks>The Evolution of CRISP-DM for Data Science</a></li></ul><h3 id=산업-표준-및-가이드>산업 표준 및 가이드<a hidden class=anchor aria-hidden=true href=#산업-표준-및-가이드>#</a></h3><ul><li><a href=https://ml-ops.org/content/mlops-principles>MLOps Principles - ML-Ops.org</a></li><li><a href=https://www.ibm.com/think/topics/data-architecture>Data Architecture Best Practices - IBM</a></li><li><a href=https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning>MLOps: Continuous Delivery and Automation - Google Cloud</a></li><li><a href=https://airbyte.com/data-engineering-resources/data-architecture-principles>Data Architecture Principles - Airbyte</a></li></ul><h3 id=기술-문서-및-플랫폼-설명>기술 문서 및 플랫폼 설명<a hidden class=anchor aria-hidden=true href=#기술-문서-및-플랫폼-설명>#</a></h3><ul><li><a href=https://airbyte.com/data-engineering-resources/etl-architecture>ETL Pipeline Architecture - Airbyte</a></li><li><a href=https://www.montecarlodata.com/blog-data-pipeline-architecture-explained/>Data Pipeline Architecture Explained - Monte Carlo</a></li><li><a href=https://aws.amazon.com/what-is/mlops/>What is MLOps? - AWS</a></li><li><a href=https://www.databricks.com/glossary/mlops>MLOps Definition and Benefits - Databricks</a></li><li><a href=https://www.snowflake.com/guides/etl-pipeline/>What Is an ETL Pipeline? - Snowflake</a></li><li><a href=https://mlflow.org/>MLflow 공식 문서</a></li><li><a href=https://feast.dev/>Feast Feature Store</a></li><li><a href=https://microsoft.github.io/MLOps/>Microsoft MLOps Stack</a></li></ul><h3 id=교육-및-실습-자료>교육 및 실습 자료<a hidden class=anchor aria-hidden=true href=#교육-및-실습-자료>#</a></h3><ul><li><a href=https://github.com/DataTalksClub/data-engineering-zoomcamp>Data Engineering Zoomcamp - DataTalksClub</a></li><li><a href=https://www.coursera.org/specializations/mlops-machine-learning-duke>MLOps Specialization - Coursera</a></li><li><a href=https://www.sv-europe.com/crisp-dm-methodology/>CRISP-DM Methodology - Smart Vision Europe</a></li><li><a href=https://github.com/danielbeach/data-engineering-practice>Data Engineering Practice Problems - GitHub</a></li></ul><h3 id=업계-동향-및-실무-통찰>업계 동향 및 실무 통찰<a hidden class=anchor aria-hidden=true href=#업계-동향-및-실무-통찰>#</a></h3><ul><li><a href=https://www.velvetech.com/blog/data-engineering-challenges/>Data Engineering Challenges - Velvetech</a></li><li><a href=https://www.glassflow.dev/blog/top-10-data-engineers-scientists-pain-points-2024>Top 10 Data Engineering Challenges - GlassFlow</a></li><li><a href=https://nexla.com/data-engineering-best-practices/data-management-best-practices/>Data Management Best Practices - Nexla</a></li><li><a href=https://moderndatastack.xyz/>Modern Data Stack Trends</a></li></ul><h3 id=교육-과정-및-전공-비교>교육 과정 및 전공 비교<a hidden class=anchor aria-hidden=true href=#교육-과정-및-전공-비교>#</a></h3><ul><li><a href=https://www.dsu.edu.in/engineering/cse-data-science>Computer Science and Engineering (Data Science) - DSU</a></li><li><a href=https://www.springernature.com/gp/researchers/the-source/blog/blogposts-communicating-research/data-science-and-engineering-challenges-and-opportunities/24602518>Data Science and Engineering: Challenges and Opportunities - Springer Nature</a></li><li><a href=https://www.dataexpertise.in/data-engineering-key-concepts/>Data Engineering Key Concepts - DataExpertise</a></li><li><a href=https://pwskills.com/blog/data-science-engineers/>Data Science Engineer Role - PW Skills</a></li><li><a href=https://sunscrapers.com/blog/data-engineering-vs-data-science-comparison/>Data Engineering vs Data Science - Sunscrapers</a></li><li><a href=https://firsteigen.com/blog/7-data-engineering-principles-you-should-be-aware-of/>Data Engineering Principles - FirstEigen</a></li><li><a href=https://www.scribd.com/document/456756664/DS-Workflow>Architecture of Data Science Projects - Scribd</a></li><li><a href=https://en.wikipedia.org/wiki/Computer_science_and_engineering>Computer Science and Engineering - Wikipedia</a></li><li><a href=https://www.rknec.edu/course/computer-science-and-engineering-data-science/>Computer Science and Engineering (Data Science) - RK NEC</a></li><li><a href=https://www.manipal.edu/mu/campuses/mahe-bengaluru/academics/institution-list/mitblr/program-list/btech/btech-computer-science-data-science1.html>BTech CSE (Data Science) - Manipal University</a></li><li><a href=https://engx.space/global/en/blog/data-science-vs-computer-science>Data Science vs Computer Science - EngX</a></li><li><a href=https://bestcolleges.indiatoday.in/news-detail/choosing-between-data-science-and-computer-science-engineering-degrees>Choosing Between Data Science and CS Engineering - India Today</a></li></ul><hr></div></main><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script><footer class=footer><span>&copy; 2025 <a href=https://buenhyden.github.io/>hyunyoun's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>