<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Data Engineering | hyunyoun's Blog</title><meta name=keywords content="Computer-Science,Computer-Engineering,Data-Engineering"><meta name=description content="원시 데이터를 수집, 저장, 처리하여 분석 가능한 형태로 변환하는 과정을 다루는 분야"><meta name=author content="Me"><link rel=canonical href=https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/><meta name=google-site-verification content="googlee06938ebbfcbac49.html"><link crossorigin=anonymous href=/assets/css/stylesheet.a9863521b3bd3c240bc506f46b95e3c06ccef2ae37f529d5f99bdaef442bccce.css integrity="sha256-qYY1IbO9PCQLxQb0a5XjwGzO8q439SnV+Zva70QrzM4=" rel="preload stylesheet" as=style><link rel=icon href=https://buenhyden.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://buenhyden.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://buenhyden.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/index.xml><link rel=alternate hreflang=en href=https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3156423099418350" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W8XTMYPTLC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W8XTMYPTLC")}</script><meta property="og:url" content="https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/"><meta property="og:site_name" content="hyunyoun's Blog"><meta property="og:title" content="Data Engineering"><meta property="og:description" content="원시 데이터를 수집, 저장, 처리하여 분석 가능한 형태로 변환하는 과정을 다루는 분야"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://buenhyden.github.io/images"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://buenhyden.github.io/images"><meta name=twitter:title content="Data Engineering"><meta name=twitter:description content="원시 데이터를 수집, 저장, 처리하여 분석 가능한 형태로 변환하는 과정을 다루는 분야"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"HY's Blog","item":"https://buenhyden.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Data Engineering","item":"https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://buenhyden.github.io/ accesskey=h title="Hy's Blog (Alt + H)"><img src=https://buenhyden.github.io/favicons/apple-touch-icon.png alt aria-label=logo height=35>Hy's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://buenhyden.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://buenhyden.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://buenhyden.github.io/til/ title="Today I Learned"><span>Today I Learned</span></a></li><li><a href=https://buenhyden.github.io/coding-test/ title="Coding Test"><span>Coding Test</span></a></li><li><a href=https://buenhyden.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://buenhyden.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://buenhyden.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://buenhyden.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/>HY's Blog</a></div><h1>Data Engineering</h1><div class=post-description>원시 데이터를 수집, 저장, 처리하여 분석 가능한 형태로 변환하는 과정을 다루는 분야</div></header><div class=post-content><h2 id=data-engineering>Data Engineering<a hidden class=anchor aria-hidden=true href=#data-engineering>#</a></h2><h3 id=1-주제의-분류-적합성>1. 주제의 분류 적합성<a hidden class=anchor aria-hidden=true href=#1-주제의-분류-적합성>#</a></h3><p>데이터 엔지니어링 (Data Engineering) 은 데이터 수집, 저장, 처리, 분석을 위한 인프라 구축 및 관리에 초점을 맞춘 분야로, 컴퓨터 과학 및 공학 (Computer Science and Engineering) 의 핵심 하위 분야로 분류됩니다. 이는 소프트웨어 개발, 시스템 설계, 알고리즘 최적화 등과 밀접하게 연관되어 있습니다 [1][7].</p><hr><h3 id=2-200-자-내외-요약-설명>2. 200 자 내외 요약 설명<a hidden class=anchor aria-hidden=true href=#2-200-자-내외-요약-설명>#</a></h3><p>데이터 엔지니어링은 데이터 파이프라인 설계, ETL(Extract-Transform-Load) 프로세스 구축, 데이터 저장소 관리 등을 통해 분석·AI 모델에 필요한 고품질 데이터를 제공하는 분야입니다. 데이터 엔지니어는 구조화/비구조화 데이터를 처리하며, 2025 년에는 AI 통합, 실시간 처리, LakeDB 등 기술이 주목받고 있습니다 [4][5][8].</p><hr><h3 id=3-200-자-내외-개요>3. 200 자 내외 개요<a hidden class=anchor aria-hidden=true href=#3-200-자-내외-개요>#</a></h3><p>데이터 엔지니어링은 데이터의 수집·정제·저장·전달을 체계화하여 분석 및 의사결정을 지원합니다. 주요 구성 요소로는 데이터 레이크, 웨어하우스, ETL 도구, 분산 처리 프레임워크 (Spark, Hadoop) 가 있으며, 최신 트렌드로는 AI 기반 자동화, 데이터 메시 (Data Mesh), 엣지 컴퓨팅이 부상합니다. 실무에서는 확장성·보안·효율성을 고려한 인프라 설계가 핵심입니다 [3][6][9].</p><hr><h3 id=4-핵심-개념>4. 핵심 개념<a hidden class=anchor aria-hidden=true href=#4-핵심-개념>#</a></h3><ul><li><strong>ETL/ELT</strong>: 데이터 추출·변환·적재 프로세스 [3].</li><li><strong>데이터 파이프라인</strong>: 데이터 흐름을 자동화하는 시스템 [7].</li><li><strong>데이터 레이크</strong>: 원시 데이터 저장소 (S3, Hadoop)[9].</li><li><strong>데이터 웨어하우스</strong>: 정제된 데이터 분석용 저장소 (Redshift, BigQuery)[9].</li><li><strong>분산 처리</strong>: 대용량 데이터 병렬 처리 (Spark, Flink)[3].</li><li><strong>데이터 거버넌스</strong>: 품질·보안·규정 준수 관리 [4].</li></ul><hr><h3 id=5-주요-내용-정리>5. 주요 내용 정리<a hidden class=anchor aria-hidden=true href=#5-주요-내용-정리>#</a></h3><h4 id=목적-및-필요성>목적 및 필요성<a hidden class=anchor aria-hidden=true href=#목적-및-필요성>#</a></h4><ul><li><strong>데이터 접근성</strong>: 분석·AI 모델에 신뢰할 수 있는 데이터 제공 [7].</li><li><strong>효율성</strong>: 자동화를 통한 처리 시간 단축 [3].</li><li><strong>규모 확장</strong>: 대량 데이터 처리 인프라 구축 [9].</li></ul><h4 id=주요-기능-및-역할>주요 기능 및 역할<a hidden class=anchor aria-hidden=true href=#주요-기능-및-역할>#</a></h4><ul><li><strong>데이터 수집</strong>: API, 로그 파일, 센서 등에서 데이터 추출 [3].</li><li><strong>정제·변환</strong>: 노이즈 제거, 형식 표준화 [3].</li><li><strong>저장·관리</strong>: 데이터 레이크·웨어하우스 운영 [9].</li><li><strong>모니터링</strong>: 파이프라인 성능·오류 감시 [6].</li></ul><h4 id=특징>특징<a hidden class=anchor aria-hidden=true href=#특징>#</a></h4><ul><li><strong>확장성</strong>: 클라우드 기반 수평 확장 [5].</li><li><strong>실시간 처리</strong>: Kafka, Flink 활용 [4].</li><li><strong>다양한 데이터 형식</strong>: 정형·비정형 (텍스트, 이미지) 지원 [3].</li></ul><h4 id=핵심-원칙>핵심 원칙<a hidden class=anchor aria-hidden=true href=#핵심-원칙>#</a></h4><ul><li><strong>신뢰성</strong>: 데이터 정확성 보장 [6].</li><li><strong>유연성</strong>: 변화하는 요구사항 대응 [9].</li><li><strong>보안</strong>: 암호화·접근 제어 [4].</li></ul><h4 id=주요-원리-및-작동-원리>주요 원리 및 작동 원리<a hidden class=anchor aria-hidden=true href=#주요-원리-및-작동-원리>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[데이터 소스] → [수집] → [정제] → [저장] → [처리] → [분석/AI]
</span></span></code></pre></td></tr></table></div></div><ul><li><p><strong>Spark 처리 예시</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1>1</a>
</span><span class=lnt id=hl-1-2><a class=lnlinks href=#hl-1-2>2</a>
</span><span class=lnt id=hl-1-3><a class=lnlinks href=#hl-1-3>3</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>csv</span><span class=p>(</span><span class=s2>&#34;s3://data-lake/raw&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df_clean</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s2>&#34;quality&#34;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mf>0.8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df_clean</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>parquet</span><span class=p>(</span><span class=s2>&#34;s3://data-lake/processed&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li></ul><h4 id=구조-및-아키텍처>구조 및 아키텍처<a hidden class=anchor aria-hidden=true href=#구조-및-아키텍처>#</a></h4><ul><li><strong>계층 구조</strong>:<ol><li><strong>수집 계층</strong>: Kafka, Flume</li><li><strong>저장 계층</strong>: S3(레이크), Redshift(웨어하우스)</li><li><strong>처리 계층</strong>: Spark, Airflow</li><li><strong>서비스 계층</strong>: API·대시보드 [9].</li></ol></li></ul><h4 id=구성-요소>구성 요소<a hidden class=anchor aria-hidden=true href=#구성-요소>#</a></h4><table><thead><tr><th>구성 요소</th><th>설명</th></tr></thead><tbody><tr><td>수집 도구</td><td>Apache NiFi, Kafka</td></tr><tr><td>저장소</td><td>HDFS, Snowflake</td></tr><tr><td>처리 엔진</td><td>Spark, Flink</td></tr><tr><td>오케스트레이션</td><td>Airflow, Luigi</td></tr></tbody></table><h4 id=장점과-단점>장점과 단점<a hidden class=anchor aria-hidden=true href=#장점과-단점>#</a></h4><table><thead><tr><th>구분</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>✅ 장점</td><td>확장성</td><td>클라우드·분산 처리로 대량 데이터 지원</td></tr><tr><td></td><td>자동화</td><td>반복 작업 효율화</td></tr><tr><td></td><td>다목적 활용</td><td>분석·AI·비즈니스 인텔리전스 지원</td></tr><tr><td>⚠ 단점</td><td>복잡성</td><td>다양한 도구 통합 난이도</td></tr><tr><td></td><td>유지보수 비용</td><td>인프라 관리 리소스 소요</td></tr><tr><td></td><td>보안 리스크</td><td>데이터 유출·오용 가능성</td></tr></tbody></table><h4 id=도전-과제>도전 과제<a hidden class=anchor aria-hidden=true href=#도전-과제>#</a></h4><ul><li><strong>실시간 처리</strong>: 저지연 스트리밍 데이터 대응 [4].</li><li><strong>데이터 품질</strong>: 노이즈·결측치 관리 [3].</li><li><strong>AI 통합</strong>: ML 모델 연동 파이프라인 구축 [8].</li></ul><h4 id=분류에-따른-종류-및-유형>분류에 따른 종류 및 유형<a hidden class=anchor aria-hidden=true href=#분류에-따른-종류-및-유형>#</a></h4><table><thead><tr><th>분류</th><th>유형</th><th>설명</th></tr></thead><tbody><tr><td>처리 방식</td><td><strong>배치 처리</strong>: 주기적 대량 데이터 (Spark)</td><td></td></tr><tr><td></td><td><strong>실시간 처리</strong>: 즉시 분석 (Kafka+Flink)</td><td></td></tr><tr><td>저장소</td><td><strong>레이크</strong>: 원시 데이터 저장 (S3)</td><td></td></tr><tr><td></td><td><strong>웨어하우스</strong>: 정제된 데이터 분석 (Redshift)</td><td></td></tr></tbody></table><h4 id=실무-적용-예시>실무 적용 예시<a hidden class=anchor aria-hidden=true href=#실무-적용-예시>#</a></h4><table><thead><tr><th>분야</th><th>예시</th><th>설명</th></tr></thead><tbody><tr><td>e-commerce</td><td>고객 행동 분석</td><td>클릭스트림 데이터 수집·분석</td></tr><tr><td>헬스케어</td><td>환자 데이터 통합</td><td>EHR(전자의무기록) 파이프라인 구축</td></tr></tbody></table><h4 id=활용-사례-시나리오-및-다이어그램>활용 사례 (시나리오 및 다이어그램)<a hidden class=anchor aria-hidden=true href=#활용-사례-시나리오-및-다이어그램>#</a></h4><p><strong>시나리오</strong>: 금융 사기 탐지 시스템</p><ol><li><strong>데이터 수집</strong>: 거래 로그·사용자 활동 데이터 수집 (Kafka)</li><li><strong>정제</strong>: 이상 패턴 식별 (Spark)</li><li><strong>저장</strong>: 정제 데이터 적재 (Redshift)</li><li><strong>분석</strong>: ML 모델로 사기 거래 예측 (SageMaker)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a class=lnlinks href=#hl-2-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[거래 로그] → [Kafka] → [Spark] → [Redshift] → [ML 모델]
</span></span></code></pre></td></tr></table></div></div><h4 id=실무에서-효과적으로-적용하기-위한-고려사항>실무에서 효과적으로 적용하기 위한 고려사항<a hidden class=anchor aria-hidden=true href=#실무에서-효과적으로-적용하기-위한-고려사항>#</a></h4><table><thead><tr><th>구분</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>설계</td><td>확장성</td><td>클라우드 네이티브 아키텍처 채택</td></tr><tr><td>보안</td><td>암호화</td><td>전송·저장 시 AES-256 적용</td></tr><tr><td>모니터링</td><td>대시보드</td><td>파이프라인 성능 시각화 (Grafana)</td></tr></tbody></table><hr><h3 id=8-2025-년-기준-최신-동향>8. 2025 년 기준 최신 동향<a hidden class=anchor aria-hidden=true href=#8-2025-년-기준-최신-동향>#</a></h3><table><thead><tr><th>주제</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>AI 통합</td><td>AutoML</td><td>코드 없이 모델 구축 (H2O.ai)</td></tr><tr><td>저장 기술</td><td>LakeDB</td><td>데이터 레이크·DB 통합 [5]</td></tr><tr><td>처리 기술</td><td>엣지 컴퓨팅</td><td>IoT 데이터 실시간 처리 [4]</td></tr><tr><td>아키텍처</td><td>데이터 메시</td><td>분산 데이터 관리 (Data Mesh)[5]</td></tr><tr><td>개발 환경</td><td>Data IDE</td><td>통합 데이터 개발 플랫폼 [10]</td></tr></tbody></table><hr><h3 id=9-주목할-내용>9. 주목할 내용<a hidden class=anchor aria-hidden=true href=#9-주목할-내용>#</a></h3><table><thead><tr><th>주제</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>AI/ML</td><td>생성형 AI</td><td>GPT-4 기반 데이터 정제 자동화 [4]</td></tr><tr><td>보안</td><td>연합 학습</td><td>개인정보 보호 모델 학습 [4]</td></tr><tr><td>클라우드</td><td>서버리스</td><td>AWS Lambda 기반 이벤트 처리 [5]</td></tr></tbody></table><hr><h3 id=10-앞으로의-전망>10. 앞으로의 전망<a hidden class=anchor aria-hidden=true href=#10-앞으로의-전망>#</a></h3><table><thead><tr><th>주제</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>기술</td><td>양자 컴퓨팅</td><td>복잡 문제 초고속 해결 [4]</td></tr><tr><td>표준</td><td>제로 ETL</td><td>데이터 이동 최소화 [5]</td></tr><tr><td>인력</td><td>시민 데이터 엔지니어</td><td>Low-Code 도구 활용 확대 [5]</td></tr></tbody></table><hr><h3 id=11-하위-주제별-추가-학습-필요-내용>11. 하위 주제별 추가 학습 필요 내용<a hidden class=anchor aria-hidden=true href=#11-하위-주제별-추가-학습-필요-내용>#</a></h3><table><thead><tr><th>카테고리</th><th>주제</th><th>설명</th></tr></thead><tbody><tr><td>클라우드</td><td>AWS/GCP/Azure</td><td>주요 플랫폼별 데이터 서비스</td></tr><tr><td>AI</td><td>MLOps</td><td>모델 배포·관리 자동화</td></tr><tr><td>보안</td><td>GDPR·CCPA</td><td>데이터 규정 준수</td></tr></tbody></table><hr><h3 id=12-추가-학습-필요-내용>12. 추가 학습 필요 내용<a hidden class=anchor aria-hidden=true href=#12-추가-학습-필요-내용>#</a></h3><table><thead><tr><th>카테고리</th><th>주제</th><th>설명</th></tr></thead><tbody><tr><td>프로그래밍</td><td>Python·Scala</td><td>Spark·Flink 개발 역량</td></tr><tr><td>도구</td><td>dbt·Airflow</td><td>데이터 변환·오케스트레이션</td></tr></tbody></table><hr><h2 id=용어-정리>용어 정리<a hidden class=anchor aria-hidden=true href=#용어-정리>#</a></h2><table><thead><tr><th>용어</th><th>설명</th></tr></thead><tbody><tr><td>ETL</td><td>데이터 추출·변환·적재 프로세스</td></tr><tr><td>Data Mesh</td><td>분산 데이터 관리 아키텍처</td></tr><tr><td>LakeDB</td><td>데이터 레이크와 DB 통합 기술</td></tr></tbody></table><hr><h2 id=참고-및-출처>참고 및 출처<a hidden class=anchor aria-hidden=true href=#참고-및-출처>#</a></h2><ul><li><a href=https://kbig.kr/sites/default/files/pds/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%9D%B8%EB%A0%A5%EC%96%91%EC%84%B1_%EC%BB%A4%EB%A6%AC%ED%81%98%EB%9F%BC(%EB%B0%B0%ED%8F%AC%EC%9A%A9).pdf>데이터 엔지니어링 커리큘럼 참조 모델</a></li><li><a href="https://news.hada.io/topic?id=18402">Data Engineering Weekly 2025 전망</a></li><li><a href=https://wonsjung.tistory.com/513>데이터 아키텍처 구성 원리</a></li><li><a href=https://brunch.co.kr/@sparkplus/469>데이터 엔지니어 로드맵</a></li></ul><hr><p>Data Engineering 은 원시 데이터를 수집, 저장, 처리하여 분석 가능한 형태로 변환하는 과정을 다루는 분야.<br>이는 데이터 기반 의사결정과 인사이트 도출을 위한 핵심적인 역할을 수행한다.</p><h3 id=중요성>중요성<a hidden class=anchor aria-hidden=true href=#중요성>#</a></h3><ul><li>비즈니스 의사결정 지원<ul><li>실시간 데이터 기반 의사결정</li><li>예측적 분석 가능</li><li>비즈니스 인텔리전스 강화</li></ul></li><li>디지털 트랜스포메이션 촉진<ul><li>레거시 시스템 현대화</li><li>데이터 중심 문화 구축</li><li>비즈니스 프로세스 최적화</li></ul></li><li>경쟁 우위 확보<ul><li>고객 인사이트 발굴</li><li>운영 효율성 증대</li><li>혁신 기회 포착</li></ul></li></ul><h3 id=발전-방향>발전 방향<a hidden class=anchor aria-hidden=true href=#발전-방향>#</a></h3><h4 id=기술적-트렌드>기술적 트렌드<a hidden class=anchor aria-hidden=true href=#기술적-트렌드>#</a></h4><ol><li>클라우드 네이티브: 클라우드 기반 서비스를 활용하여 확장성과 유연성을 높인다.<ul><li>서버리스 아키텍처</li><li>컨테이너화</li><li>마이크로서비스</li></ul></li><li>자동화<ul><li>DataOps</li><li>MLOps</li><li>자동 스케일링</li></ul></li><li>실시간 처리: 데이터를 생성 즉시 분석하여 신속한 대응을 가능하게 한다.<ul><li>스트림 프로세싱</li><li>이벤트 기반 아키텍처</li><li>실시간 분석</li></ul></li></ol><h4 id=도메인-트렌드>도메인 트렌드<a hidden class=anchor aria-hidden=true href=#도메인-트렌드>#</a></h4><ol><li>AI/ML 통합: 인공지능과 머신러닝을 데이터 파이프라인에 통합하여 자동화와 최적화를 강화한다.<ul><li>자동화된 특성 추출</li><li>모델 파이프라인</li><li>실시간 예측</li></ul></li><li>데이터 거버넌스: 데이터 보안, 규정 준수, 품질 관리에 대한 중요성이 증가한다.<ul><li>메타데이터 관리</li><li>데이터 카탈로그</li><li>규정 준수</li></ul></li><li>데이터 민주화<ul><li>셀프 서비스 분석</li><li>데이터 제품화</li><li>데이터 마켓플레이스</li></ul></li></ol><h3 id=데이터-엔지니어링의-주요-구성-요소>데이터 엔지니어링의 주요 구성 요소<a hidden class=anchor aria-hidden=true href=#데이터-엔지니어링의-주요-구성-요소>#</a></h3><ol><li><p>. 데이터 아키텍처</p></li><li><p>데이터 모델링</p><ul><li>논리적/물리적 데이터 모델</li><li>스키마 설계</li><li>데이터 관계 정의</li></ul></li><li><p>저장소 설계</p><ul><li>데이터 웨어하우스</li><li>데이터 레이크</li><li>하이브리드 아키텍처</li></ul></li><li><p>확장성 계획</p><ul><li>수평적/수직적 확장</li><li>분산 시스템 설계</li><li>성능 최적화</li></ul></li><li><p>데이터 통합</p></li><li><p>ETL/ELT 프로세스</p><ul><li>데이터 추출</li><li>데이터 변환</li><li>데이터 적재</li></ul></li><li><p>데이터 품질 관리</p><ul><li>데이터 검증</li><li>정합성 체크</li><li>오류 처리</li></ul></li><li><p>데이터 보안</p></li><li><p>접근 제어</p><ul><li>인증/인가</li><li>역할 기반 접근 제어</li><li>감사 로깅</li></ul></li><li><p>데이터 보호</p><ul><li>암호화</li><li>마스킹</li><li>개인정보 보호</li></ul></li></ol><h3 id=데이터-엔지니어링-파이프라인과-각-단계별-설명>데이터 엔지니어링 파이프라인과 각 단계별 설명<a hidden class=anchor aria-hidden=true href=#데이터-엔지니어링-파이프라인과-각-단계별-설명>#</a></h3><p><figure><img alt="Modern Data Integration: Data Engineering" loading=lazy src=/img/dataeng.png><figcaption>Source: https://opendatascience.com/ten-areas-of-data-engineering-every-team-should-excel-at/</figcaption></figure></p><ol><li><p>데이터 소스 (Source)</p><ul><li>다양한 소스 (데이터베이스, API, IoT 장치 등) 에서 데이터를 추출한다.</li><li>실시간 또는 배치 방식으로 데이터를 수집한다.</li></ul></li><li><p>데이터 수집 (Ingestion)</p><ul><li>추출된 데이터를 파이프라인으로 가져온다.</li><li>데이터의 형식, 속도, 볼륨을 고려하여 적절한 수집 방법을 선택한다.</li></ul></li><li><p>데이터 처리 (Processing)</p><ul><li>수집된 데이터를 정제, 변환, 집계한다.</li><li>ETL(Extract, Transform, Load) 또는 ELT(Extract, Load, Transform) 프로세스를 적용한다.</li><li>데이터의 품질을 검증하고 오류를 처리한다.</li></ul></li><li><p>데이터 저장 (Storage)</p><ul><li>처리된 데이터를 적절한 저장소에 저장한다.</li><li>데이터 웨어하우스, 데이터 레이크, 또는 특정 목적의 데이터베이스를 사용한다.</li></ul></li><li><p>데이터 분석 및 시각화 (Analysis and Visualization)</p><ul><li>저장된 데이터를 분석하고 인사이트를 도출한다.</li><li>BI 도구, 대시보드, 리포팅 시스템을 통해 데이터를 시각화한다.</li></ul></li><li><p>데이터 소비 (Consumption)</p><ul><li>최종 사용자나 애플리케이션이 처리된 데이터를 활용한다.</li><li>API, 데이터 마트, 또는 직접 쿼리를 통해 데이터에 접근한다.</li></ul></li></ol><h3 id=핵심-기술-스택>핵심 기술 스택<a hidden class=anchor aria-hidden=true href=#핵심-기술-스택>#</a></h3><ol><li>프로그래밍 언어</li></ol><ul><li>Python</li><li>SQL</li><li>Scala</li><li>Java</li></ul><ol><li>프레임워크 & 도구</li></ol><ul><li>Apache Spark</li><li>Apache Kafka</li><li>Apache Airflow</li><li>dbt</li></ul><ol><li>클라우드 플랫폼</li></ol><ul><li>AWS</li><li>Google Cloud</li><li>Azure</li><li>Snowflake</li></ul><hr><h2 id=용어-정리-1>용어 정리<a hidden class=anchor aria-hidden=true href=#용어-정리-1>#</a></h2><table><thead><tr><th>용어</th><th>설명</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><hr><h2 id=roadmap>Roadmap<a hidden class=anchor aria-hidden=true href=#roadmap>#</a></h2><hr><h2 id=참고-및-출처-1>참고 및 출처<a hidden class=anchor aria-hidden=true href=#참고-및-출처-1>#</a></h2><p><a href=https://www.ibm.com/kr-ko/topics/data-pipeline>데이터 파이프라인이란? | IBM</a><br><a href=https://aws.amazon.com/ko/what-is/data-pipeline/># 데이터 파이프라인이란 무엇인가요?</a><br><a href=https://blog.jetbrains.com/ko/blog/2021/07/07/big-data-world-part-3-building-data-pipelines/>빅데이터의 세계, 3부: 데이터 파이프라인 구축 | JetBrains 블로그</a><br><a href=https://playinpap.github.io/data-pipeline/>데이터 파이프라인 개념 정리 | Product Analytics Playground</a><br><a href=https://blog.voidmainvoid.net/265>데이터파이프라인이란 무엇인가?</a><br><a href=https://velog.io/@ginee_park/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B5%AC%EC%B6%95-%EC%9D%B4%EB%A1%A0>데이터 파이프라인 구축 - 이론</a><br><a href=https://seoyoungh.github.io/data-science/data-pipeline-detail/>데이터 파이프라인 자세히 알아보기 | Seoyoung Hong</a></p><p><a href=https://blog.banksalad.com/tech/datapipe/>데이터 분석가가 직접 정의, 배포, 관리하는 뱅크샐러드 데이터 파이프라인</a><br><a href=https://blog.doctor-cha.com/building-autopedia-data-warehouse>오토피디아 데이터 웨어하우스 구축하기</a><br><a href="https://blog.doctor-cha.com/buliding-streaming-data-pipeline-deploy-eks-with-terraform?ref=codenary">실시간 데이터 파이프라인 구축기 - Terraform으로 EKS를 띄워보자</a><br><a href="https://devocean.sk.com/search/techBoardDetail.do?ID=163549&amp;boardType=&amp;query=gateway&amp;searchData=&amp;page=&amp;subIndex=&amp;idList=">더 나은 빅데이터 처리·분석을 위한 변화 (CDH의 Apache Hadoop 전환기)</a><br><a href=https://jack-vanlightly.com/blog/2023/11/14/the-architecture-of-serverless-data-systems>The Architecture Of Serverless Data Systems</a><br><a href="https://news.hada.io/topic?id=6435">▲ 최신 데이터 인프라를 위한 새로운 아키텍처 2.0</a><br><a href=https://tech.kakao.com/2020/11/30/kakao-data-engineering/>데이터 엔지니어링이란</a><br><a href=https://tech.socarcorp.kr/data/2023/01/17/build-fms-data-pipeline-1.html>FMS(차량 관제 시스템) 데이터 파이프라인 구축기 1편. 스트리밍/배치 파이프라인 개발기</a><br><a href=https://tech.socarcorp.kr/data/2023/01/25/build-fms-data-pipeline-2.html>FMS(차량 관제 시스템) 데이터 파이프라인 구축기 2편. 신뢰성 높은 데이터를 위한 테스트 환경 구축기</a><br><a href=https://tech.kakao.com/2022/04/13/kafka-connect-streaming-data-platform/>제네시스 – 광고추천팀의 카프카 기반 스트리밍 데이터 플랫폼</a><br><a href=https://medium.com/coupang-engineering/data-platform-2022-global-expansion-in-petabytes-3dbbbf27f6fe>Data platform 2022: Global expansion in petabytes</a><br><a href=https://netmarble.engineering/data-pipeline-design-principles-a/>데이터 파이프라인 기본 원리와 원칙은 시간이 지나도 유효해야 한다(1/2)</a><br><a href=https://netmarble.engineering/data-pipeline-design-principles-b/>데이터 파이프라인 기본 원리와 원칙은 시간이 지나도 유효해야 한다(2/2)</a></p><hr><p>Citations:<br>[1] <a href=https://comp.utm.my/wp-content/uploads/filebase/academic_resource/SECPH%202023%202024.pdf>https://comp.utm.my/wp-content/uploads/filebase/academic_resource/SECPH%202023%202024.pdf</a><br>[2] <a href=https://kbig.kr/sites/default/files/pds/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%9D%B8%EB%A0%A5%EC%96%91%EC%84%B1_%EC%BB%A4%EB%A6%AC%ED%81%98%EB%9F%BC(%EB%B0%B0%ED%8F%AC%EC%9A%A9)>https://kbig.kr/sites/default/files/pds/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%9D%B8%EB%A0%A5%EC%96%91%EC%84%B1_%EC%BB%A4%EB%A6%AC%ED%81%98%EB%9F%BC(%EB%B0%B0%ED%8F%AC%EC%9A%A9)</a>.pdf<br>[3] <a href=https://wikidocs.net/179769>https://wikidocs.net/179769</a><br>[4] <a href="https://news.hada.io/topic?id=18402">https://news.hada.io/topic?id=18402</a><br>[5] <a href=https://digitalbourgeois.tistory.com/643>https://digitalbourgeois.tistory.com/643</a><br>[6] <a href=https://product.kyobobook.co.kr/detail/S000210626592>https://product.kyobobook.co.kr/detail/S000210626592</a><br>[7] <a href=https://brunch.co.kr/@sparkplus/469>https://brunch.co.kr/@sparkplus/469</a><br>[8] <a href=https://dsti.school/applied-msc-in-data-engineering-ai/>https://dsti.school/applied-msc-in-data-engineering-ai/</a><br>[9] <a href=https://wonsjung.tistory.com/513>https://wonsjung.tistory.com/513</a><br>[10] <a href=https://news.hada.io/weekly/202453>https://news.hada.io/weekly/202453</a><br>[11] <a href=https://www.dongguk.edu/dandae/154>https://www.dongguk.edu/dandae/154</a><br>[12] <a href=https://www.snu.ac.kr/webdata/uploads/kor/file/2025/04/Graduate_Course_Summary_2024.pdf>https://www.snu.ac.kr/webdata/uploads/kor/file/2025/04/Graduate_Course_Summary_2024.pdf</a><br>[13] <a href=https://grant-documents.thevc.kr/256628_%5BTTA%5D+2023+%EC%8B%A0%EB%A2%B0%ED%95%A0+%EC%88%98+%EC%9E%88%EB%8A%94+%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5+%EA%B0%9C%EB%B0%9C+%EC%95%88%EB%82%B4%EC%84%9C+-+%EC%9D%BC%EB%B0%98+%EB%B6%84%EC%95%BC.pdf>https://grant-documents.thevc.kr/256628_%5BTTA%5D+2023+%EC%8B%A0%EB%A2%B0%ED%95%A0+%EC%88%98+%EC%9E%88%EB%8A%94+%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5+%EA%B0%9C%EB%B0%9C+%EC%95%88%EB%82%B4%EC%84%9C+-+%EC%9D%BC%EB%B0%98+%EB%B6%84%EC%95%BC.pdf</a><br>[14] <a href=https://www.slideshare.net/DONGMINLEE15/data-engineering-142510599>https://www.slideshare.net/DONGMINLEE15/data-engineering-142510599</a><br>[15] <a href=https://www.snowflake.com/ko/blog/ai-data-predictions-2025/>https://www.snowflake.com/ko/blog/ai-data-predictions-2025/</a><br>[16] <a href=https://data-engineer-tech.tistory.com/69>https://data-engineer-tech.tistory.com/69</a><br>[17] <a href=https://dataengineeringcommunity.substack.com/p/data-engineering-digest-april-2025>https://dataengineeringcommunity.substack.com/p/data-engineering-digest-april-2025</a><br>[18] <a href=https://wikidocs.net/222913>https://wikidocs.net/222913</a><br>[19] <a href=https://brunch.co.kr/@@6uTE/58>https://brunch.co.kr/@@6uTE/58</a><br>[20] <a href=https://narangdesign.com/mail/jungwoo/202306/a1.html>https://narangdesign.com/mail/jungwoo/202306/a1.html</a><br>[21] <a href=https://hmdev.vercel.app/2021%EB%85%84-Data-Engineering-%ED%8A%B8%EB%A0%8C%EB%93%9C>https://hmdev.vercel.app/2021%EB%85%84-Data-Engineering-%ED%8A%B8%EB%A0%8C%EB%93%9C</a><br>[22] <a href=https://www.reddit.com/r/dataengineering/comments/105bgbj/pursing_data_engineering_as_a_computer_science/>https://www.reddit.com/r/dataengineering/comments/105bgbj/pursing_data_engineering_as_a_computer_science/</a><br>[23] <a href="https://www.sciencedirect.com/science/article/pii/S1877050923018380/pdf?md5=e444b8ccc4133f968c5c3b8b537b2e07&amp;pid=1-s2.0-S1877050923018380-main.pdf">https://www.sciencedirect.com/science/article/pii/S1877050923018380/pdf?md5=e444b8ccc4133f968c5c3b8b537b2e07&amp;pid=1-s2.0-S1877050923018380-main.pdf</a><br>[24] <a href=https://www.pickl.ai/blog/data-science-for-computer-science-engineers/>https://www.pickl.ai/blog/data-science-for-computer-science-engineers/</a><br>[25] <a href=https://sunscrapers.com/blog/what-is-the-best-language-for-data-engineering/>https://sunscrapers.com/blog/what-is-the-best-language-for-data-engineering/</a><br>[26] <a href=https://www.brainz.co.kr/tech-story/index/search_keyword/eNortjI0slJ6vWLHm-4Fr-eved09V8kaXDBlxgp1/search_field/eNortjIys1Jy1CsuTcpKTS7RdtQrSUwHksn5eSWpeSXFStZcMLkaCww~>https://www.brainz.co.kr/tech-story/index/search_keyword/eNortjI0slJ6vWLHm-4Fr-eved09V8kaXDBlxgp1/search_field/eNortjIys1Jy1CsuTcpKTS7RdtQrSUwHksn5eSWpeSXFStZcMLkaCww~</a><br>[27] <a href=https://www.gknu.ac.kr/data/fileManageStorage/%EC%9C%B5%ED%95%A9%EC%A0%84%EA%B3%B5%EB%B3%84%20%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95(25%EB%85%842%EC%9B%9424%EC%9D%BC)>https://www.gknu.ac.kr/data/fileManageStorage/%EC%9C%B5%ED%95%A9%EC%A0%84%EA%B3%B5%EB%B3%84%20%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95(25%EB%85%842%EC%9B%9424%EC%9D%BC)</a>.pdf<br>[28] <a href=https://jiniya.net/2025/04/code-complexity/>https://jiniya.net/2025/04/code-complexity/</a><br>[29] <a href=https://www.yu.ac.kr/cse/grad/cse.do>https://www.yu.ac.kr/cse/grad/cse.do</a><br>[30] <a href=https://evcdc.koreatech.ac.kr/attach_file/52c9d5bf92554ee387caabf3514e46cf.pdf>https://evcdc.koreatech.ac.kr/attach_file/52c9d5bf92554ee387caabf3514e46cf.pdf</a><br>[31] <a href="https://hrd4u.or.kr/portal/cmm/fms/FileDown.do?atchFileId=FILE_000000000600167&amp;fileSn=1&amp;bbsId">https://hrd4u.or.kr/portal/cmm/fms/FileDown.do?atchFileId=FILE_000000000600167&amp;fileSn=1&amp;bbsId</a>=<br>[32] <a href=https://curieux.tistory.com/290>https://curieux.tistory.com/290</a><br>[33] <a href=https://www.cisp.or.kr/wp-content/uploads/2021/03/2.%EA%B3%B5%EA%B3%B5SW%EC%82%AC%EC%97%85-%EC%A0%9C%EC%95%88%EC%9A%94%EC%B2%AD%EC%84%9C-%EC%9E%91%EC%84%B1%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD-%EA%B0%80%EC%9D%B4%EB%93%9C-20210219.pdf>https://www.cisp.or.kr/wp-content/uploads/2021/03/2.%EA%B3%B5%EA%B3%B5SW%EC%82%AC%EC%97%85-%EC%A0%9C%EC%95%88%EC%9A%94%EC%B2%AD%EC%84%9C-%EC%9E%91%EC%84%B1%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD-%EA%B0%80%EC%9D%B4%EB%93%9C-20210219.pdf</a><br>[34] <a href=https://assets.kpmg.com/content/dam/kpmg/kr/pdf/2020/kr-im-data-20200306.pdf>https://assets.kpmg.com/content/dam/kpmg/kr/pdf/2020/kr-im-data-20200306.pdf</a><br>[35] <a href=https://jojaeguri.tistory.com/29>https://jojaeguri.tistory.com/29</a><br>[36] <a href=https://www.cisp.or.kr/wp-content/uploads/2021/03/3.%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%EC%82%AC%EC%97%85-%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD-%EB%B6%84%EC%84%9D%EC%A0%81%EC%9A%A9-%EA%B0%80%EC%9D%B4%EB%93%9C_20210219.pdf>https://www.cisp.or.kr/wp-content/uploads/2021/03/3.%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%EC%82%AC%EC%97%85-%EC%9A%94%EA%B5%AC%EC%82%AC%ED%95%AD-%EB%B6%84%EC%84%9D%EC%A0%81%EC%9A%A9-%EA%B0%80%EC%9D%B4%EB%93%9C_20210219.pdf</a><br>[37] <a href="https://www.kiri.or.kr/report/downloadFile.do?docId=391039">https://www.kiri.or.kr/report/downloadFile.do?docId=391039</a><br>[38] <a href="https://biz.katech.re.kr/bb/down.html?bid=1&amp;fid=84&amp;file=202412%2Fmv_17337910101710916730601.xlsx&amp;force=1">https://biz.katech.re.kr/bb/down.html?bid=1&amp;fid=84&amp;file=202412%2Fmv_17337910101710916730601.xlsx&amp;force=1</a><br>[39] <a href=https://brunch.co.kr/@@1W5I/132>https://brunch.co.kr/@@1W5I/132</a><br>[40] <a href=https://kr.linkedin.com/posts/hyunsoo-ryan-lee_2025%EB%85%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%EC%97%90%EC%84%9C-%EB%9C%A8%EB%8A%94-5%EA%B0%80%EC%A7%80-%ED%8A%B8%EB%A0%8C%EB%93%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%8A%94-%EC%9D%B4%EC%A0%9C-activity-7307700297072549888-PI7m>https://kr.linkedin.com/posts/hyunsoo-ryan-lee_2025%EB%85%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%EC%97%90%EC%84%9C-%EB%9C%A8%EB%8A%94-5%EA%B0%80%EC%A7%80-%ED%8A%B8%EB%A0%8C%EB%93%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%8A%94-%EC%9D%B4%EC%A0%9C-activity-7307700297072549888-PI7m</a><br>[41] <a href=https://kr.linkedin.com/posts/%EC%83%81%EA%B8%B8-%EB%B0%95-b6ab145a_the-future-of-data-engineering-dews-2025-activity-7275437377613938688-Hmos>https://kr.linkedin.com/posts/%EC%83%81%EA%B8%B8-%EB%B0%95-b6ab145a_the-future-of-data-engineering-dews-2025-activity-7275437377613938688-Hmos</a><br>[42] <a href=https://seo.goover.ai/report/202504/go-public-report-ko-c1513958-94fa-4661-88f9-5bedcac796d1-0-0.html>https://seo.goover.ai/report/202504/go-public-report-ko-c1513958-94fa-4661-88f9-5bedcac796d1-0-0.html</a><br>[43] <a href=https://brunch.co.kr/@@7pqA/177>https://brunch.co.kr/@@7pqA/177</a><br>[44] <a href=https://www.threads.com/@hyunsoo.it/post/DHUv_SZv8gN/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%B4%EC%95%BC%EA%B8%B0-70-2025%EB%85%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%EC%97%90%EC%84%9C-%EB%9C%A8%EB%8A%94-5%EA%B0%80%EC%A7%80-%ED%8A%B8%EB%A0%8C%EB%93%9C-%EC%B4%88%EA%B1%B0%EB%8C%80-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8llm%EC%9D%98-%EB%93%B1%EC%9E%A5-ai%EA%B0%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC%EC%99%80-%EC%84%A4%EA%B3%84%EB%A5%BC-%EC%9E%90%EB%8F%99%ED%99%94%ED%95%98%EB%A9%B0-ra>https://www.threads.com/@hyunsoo.it/post/DHUv_SZv8gN/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%B4%EC%95%BC%EA%B8%B0-70-2025%EB%85%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%EC%97%90%EC%84%9C-%EB%9C%A8%EB%8A%94-5%EA%B0%80%EC%A7%80-%ED%8A%B8%EB%A0%8C%EB%93%9C-%EC%B4%88%EA%B1%B0%EB%8C%80-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8llm%EC%9D%98-%EB%93%B1%EC%9E%A5-ai%EA%B0%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC%EC%99%80-%EC%84%A4%EA%B3%84%EB%A5%BC-%EC%9E%90%EB%8F%99%ED%99%94%ED%95%98%EB%A9%B0-ra</a><br>[45] <a href="https://news.hada.io/topic?id=18402">https://news.hada.io/topic?id=18402</a><br>[46] <a href=https://rivery.io/downloads/the-top-5-data-engineering-trends-heading-into-2025/>https://rivery.io/downloads/the-top-5-data-engineering-trends-heading-into-2025/</a><br>[47] <a href=https://brunch.co.kr/@hnote/161>https://brunch.co.kr/@hnote/161</a><br>[48] <a href=https://www.spri.kr/download/23630>https://www.spri.kr/download/23630</a><br>[49] <a href=https://www.deloitte.com/kr/ko/services/tax/perspectives/customs-newsletter-2025-04-30.html>https://www.deloitte.com/kr/ko/services/tax/perspectives/customs-newsletter-2025-04-30.html</a><br>[50] <a href=https://fastcampus.co.kr/community/100383>https://fastcampus.co.kr/community/100383</a><br>[51] <a href=https://digitalbourgeois.tistory.com/643>https://digitalbourgeois.tistory.com/643</a><br>[52] <a href=https://blogs.nvidia.co.kr/blog/industry-ai-predictions-2025/>https://blogs.nvidia.co.kr/blog/industry-ai-predictions-2025/</a><br>[53] <a href=https://velog.io/@dlawlrb/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4-%EB%A1%9C%EB%93%9C%EB%A7%B5%EC%9D%84-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90>https://velog.io/@dlawlrb/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4-%EB%A1%9C%EB%93%9C%EB%A7%B5%EC%9D%84-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90</a><br>[54] <a href="https://www.keei.re.kr/boardDownload.es?bid=0022&amp;list_no=123436&amp;seq=1">https://www.keei.re.kr/boardDownload.es?bid=0022&amp;list_no=123436&amp;seq=1</a><br>[55] <a href=https://velog.io/@davidmin/Natural-Language-Processing-%EB%AA%A8%EB%93%88-%ED%95%99%EC%8A%B5-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B3%BC%EC%A0%9C>https://velog.io/@davidmin/Natural-Language-Processing-%EB%AA%A8%EB%93%88-%ED%95%99%EC%8A%B5-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B3%BC%EC%A0%9C</a><br>[56] <a href=https://discuss.pytorch.kr/t/llm-synthetic-data-survey/4764>https://discuss.pytorch.kr/t/llm-synthetic-data-survey/4764</a><br>[57] <a href=https://eair.tistory.com/46>https://eair.tistory.com/46</a><br>[58] <a href=https://www.ibm.com/kr-ko/think/topics/transfer-learning>https://www.ibm.com/kr-ko/think/topics/transfer-learning</a><br>[59] <a href=https://vulter3653.tistory.com/33>https://vulter3653.tistory.com/33</a><br>[60] <a href=https://velog.io/@skh951225/%EB%AC%B4%EC%97%87%EC%9D%84-%EC%96%B4%EB%94%94%EC%84%9C-%EA%B3%B5%EB%B6%80%ED%96%88%EB%8A%94%EC%A7%802023.03>https://velog.io/@skh951225/%EB%AC%B4%EC%97%87%EC%9D%84-%EC%96%B4%EB%94%94%EC%84%9C-%EA%B3%B5%EB%B6%80%ED%96%88%EB%8A%94%EC%A7%802023.03</a><br>[61] <a href=https://fastcampus.co.kr/data_online_udacityawsengineering>https://fastcampus.co.kr/data_online_udacityawsengineering</a><br>[62] <a href=https://data-analysis-hagrid.tistory.com/71>https://data-analysis-hagrid.tistory.com/71</a><br>[63] <a href=https://tech.kakao.com/2022/04/19/2022-kakao-tech-internship-data/>https://tech.kakao.com/2022/04/19/2022-kakao-tech-internship-data/</a><br>[64] <a href=https://aws.amazon.com/ko/certification/certified-data-engineer-associate/>https://aws.amazon.com/ko/certification/certified-data-engineer-associate/</a><br>[65] <a href=https://www.skelterlabs.com/blog/rag-vs-finetuning>https://www.skelterlabs.com/blog/rag-vs-finetuning</a></p><hr><p>Perplexity 로부터의 답변: pplx.ai/share</p><p><a href=https://tech.socarcorp.kr/data/2021/03/24/what-socar-data-engineering-team-does.html><figure><img alt="쏘카 데이터 그룹 - 데이터 엔지니어링 팀이 하는 일 - SOCAR Tech Blog" loading=lazy src="https://tse4.mm.bing.net/th/id/OIP.T4AHiWhjcEGl95DERb0wHwHaFs?pid=Api"></figure></a></p><p>데이터 엔지니어링 (Data Engineering) 은 데이터의 수집, 처리, 저장, 분석을 위한 시스템을 설계하고 구축하는 분야로, 현대의 데이터 중심 비즈니스에서 핵심적인 역할을 수행합니다. 이 분야는 컴퓨터 과학, 소프트웨어 엔지니어링, 데이터베이스, 클라우드 인프라 등을 포괄하며, 데이터 사이언스와 인공지능의 기반을 제공합니다.</p><hr><h2 id=1-주제의-분류-적절성>1. 주제의 분류 적절성<a hidden class=anchor aria-hidden=true href=#1-주제의-분류-적절성>#</a></h2><p>데이터 엔지니어링은 &ldquo;Computer Science and Engineering&rdquo; 분야에 속하는 것이 적절합니다. 이는 데이터 시스템의 설계, 알고리즘, 분산 처리, 데이터베이스, 네트워크, 클라우드 인프라 등 컴퓨터 과학과 소프트웨어 공학의 핵심 요소들을 포함하기 때문입니다.</p><hr><h2 id=2-요약-설명-200-자-내외>2. 요약 설명 (200 자 내외)<a hidden class=anchor aria-hidden=true href=#2-요약-설명-200-자-내외>#</a></h2><p>데이터 엔지니어링은 대규모 데이터를 수집, 처리, 저장, 분석하는 시스템을 설계하고 구축하는 분야로, 데이터 기반 의사결정과 인공지능의 기반을 제공합니다.</p><hr><h2 id=3-전체-개요-200-자-내외>3. 전체 개요 (200 자 내외)<a hidden class=anchor aria-hidden=true href=#3-전체-개요-200-자-내외>#</a></h2><p>데이터 엔지니어링은 데이터의 수집부터 저장, 처리, 분석까지의 전 과정을 담당하며, 안정적이고 확장 가능한 데이터 파이프라인과 인프라를 구축하여 데이터 사이언스, 머신러닝, 비즈니스 인텔리전스 등의 기반을 마련합니다.</p><hr><h2 id=4-핵심-개념-1>4. 핵심 개념<a hidden class=anchor aria-hidden=true href=#4-핵심-개념-1>#</a></h2><ul><li><p><strong>데이터 파이프라인 (Data Pipeline)</strong>: 데이터의 수집, 처리, 저장, 분석 과정을 자동화한 흐름</p></li><li><p><strong>ETL/ELT</strong>: Extract-Transform-Load 또는 Extract-Load-Transform 방식의 데이터 처리</p></li><li><p><strong>데이터 웨어하우스 (Data Warehouse)</strong>: 분석을 위한 구조화된 데이터 저장소</p></li><li><p><strong>데이터 레이크 (Data Lake)</strong>: 구조화되지 않은 원시 데이터를 저장하는 저장소</p></li><li><p><strong>워크플로우 오케스트레이션 (Workflow Orchestration)</strong>: 데이터 처리 작업의 순서와 의존성을 관리하는 시스템</p></li><li><p><strong>데이터 품질 (Data Quality)</strong>: 정확성, 완전성, 일관성, 적시성 등의 데이터 특성 (<a href="https://www.databricks.com/kr/resources/ebook/the-big-book-of-data-engineering?utm_source=chatgpt.com" title="데이터 엔지니어링 Big Book | Databricks">Databricks</a>)</p></li></ul><hr><h2 id=5-주제와-관련하여-조사할-내용>5. 주제와 관련하여 조사할 내용<a hidden class=anchor aria-hidden=true href=#5-주제와-관련하여-조사할-내용>#</a></h2><h3 id=목적-및-필요성-1>목적 및 필요성<a hidden class=anchor aria-hidden=true href=#목적-및-필요성-1>#</a></h3><ul><li><p><strong>데이터 기반 의사결정 지원</strong>: 정확하고 신뢰할 수 있는 데이터를 제공하여 비즈니스 의사결정을 지원합니다.</p></li><li><p><strong>데이터 사이언스 및 머신러닝의 기반 마련</strong>: 분석과 모델링을 위한 고품질의 데이터를 제공합니다.</p></li><li><p><strong>실시간 데이터 처리 및 분석</strong>: 스트리밍 데이터를 실시간으로 처리하여 즉각적인 인사이트를 도출합니다.</p></li></ul><h3 id=주요-기능-및-역할-1>주요 기능 및 역할<a hidden class=anchor aria-hidden=true href=#주요-기능-및-역할-1>#</a></h3><ul><li><p><strong>데이터 수집 및 통합</strong>: 다양한 소스에서 데이터를 수집하고 통합합니다.</p></li><li><p><strong>데이터 처리 및 변환</strong>: 데이터를 정제하고 변환하여 분석에 적합한 형태로 만듭니다.</p></li><li><p><strong>데이터 저장 및 관리</strong>: 데이터를 효율적으로 저장하고 관리합니다.</p></li><li><p><strong>데이터 파이프라인 구축 및 유지보수</strong>: 데이터 흐름을 자동화하고 안정적으로 운영합니다.</p></li></ul><h3 id=특징-1>특징<a hidden class=anchor aria-hidden=true href=#특징-1>#</a></h3><ul><li><p><strong>확장성 (Scalability)</strong>: 대용량 데이터를 효율적으로 처리할 수 있는 구조</p></li><li><p><strong>유연성 (Flexibility)</strong>: 다양한 데이터 소스와 포맷을 지원하는 구조</p></li><li><p><strong>신뢰성 (Reliability)</strong>: 데이터 처리의 정확성과 일관성을 보장하는 구조</p></li></ul><h3 id=핵심-원칙-1>핵심 원칙<a hidden class=anchor aria-hidden=true href=#핵심-원칙-1>#</a></h3><ul><li><p><strong>데이터 품질 유지</strong>: 정확하고 일관된 데이터를 유지하는 것이 중요합니다.</p></li><li><p><strong>자동화 및 오케스트레이션</strong>: 데이터 처리 과정을 자동화하여 효율성을 높입니다.</p></li><li><p><strong>보안 및 개인정보 보호</strong>: 데이터의 보안과 개인정보 보호를 철저히 관리합니다.</p></li></ul><h3 id=주요-원리-및-작동-원리-1>주요 원리 및 작동 원리<a hidden class=anchor aria-hidden=true href=#주요-원리-및-작동-원리-1>#</a></h3><p>데이터 엔지니어링의 주요 원리는 데이터를 수집, 처리, 저장, 분석하는 전 과정을 자동화하고 최적화하는 것입니다. 이를 위해 다양한 도구와 기술이 활용되며, 데이터 파이프라인을 통해 데이터 흐름을 관리합니다.</p><h3 id=구조-및-아키텍처-1>구조 및 아키텍처<a hidden class=anchor aria-hidden=true href=#구조-및-아키텍처-1>#</a></h3><p>데이터 엔지니어링의 구조는 일반적으로 다음과 같은 계층으로 구성됩니다:</p><ol><li><p><strong>데이터 수집 계층</strong>: 다양한 소스에서 데이터를 수집합니다.</p></li><li><p><strong>데이터 처리 계층</strong>: 수집된 데이터를 정제하고 변환합니다.</p></li><li><p><strong>데이터 저장 계층</strong>: 처리된 데이터를 저장합니다.</p></li><li><p><strong>데이터 분석 계층</strong>: 저장된 데이터를 분석하여 인사이트를 도출합니다.</p></li></ol><h3 id=구성-요소-1>구성 요소<a hidden class=anchor aria-hidden=true href=#구성-요소-1>#</a></h3><ul><li><p><strong>데이터 수집 도구</strong>: Apache Kafka, Flume 등</p></li><li><p><strong>데이터 처리 도구</strong>: Apache Spark, Beam 등</p></li><li><p><strong>데이터 저장소</strong>: Hadoop HDFS, Amazon S3 등</p></li><li><p><strong>데이터 웨어하우스</strong>: Amazon Redshift, Google BigQuery 등</p></li><li><p><strong>오케스트레이션 도구</strong>: Apache Airflow, Luigi 등</p></li></ul><h3 id=장점과-단점-1>장점과 단점<a hidden class=anchor aria-hidden=true href=#장점과-단점-1>#</a></h3><table><thead><tr><th>구분</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>✅ 장점</td><td>확장성</td><td>대용량 데이터를 효율적으로 처리할 수 있습니다.</td></tr><tr><td></td><td>유연성</td><td>다양한 데이터 소스와 포맷을 지원합니다.</td></tr><tr><td></td><td>자동화</td><td>데이터 처리 과정을 자동화하여 효율성을 높입니다.</td></tr><tr><td>⚠ 단점</td><td>복잡성</td><td>시스템이 복잡하여 구축과 유지보수가 어렵습니다.</td></tr><tr><td></td><td>비용</td><td>인프라 구축과 운영에 비용이 많이 들 수 있습니다.</td></tr></tbody></table><h3 id=도전-과제-1>도전 과제<a hidden class=anchor aria-hidden=true href=#도전-과제-1>#</a></h3><ul><li><p><strong>데이터 품질 관리</strong>: 정확하고 일관된 데이터를 유지하는 것이 어렵습니다.</p></li><li><p><strong>실시간 데이터 처리</strong>: 스트리밍 데이터를 실시간으로 처리하는 데 기술적 어려움이 있습니다.</p></li><li><p><strong>보안 및 개인정보 보호</strong>: 데이터의 보안과 개인정보 보호를 철저히 관리해야 합니다.</p></li></ul><h3 id=분류에-따른-종류-및-유형-1>분류에 따른 종류 및 유형<a hidden class=anchor aria-hidden=true href=#분류에-따른-종류-및-유형-1>#</a></h3><table><thead><tr><th>분류</th><th>유형</th><th>설명</th></tr></thead><tbody><tr><td>데이터 저장소</td><td>데이터 웨어하우스</td><td>분석을 위한 구조화된 데이터 저장소</td></tr><tr><td></td><td>데이터 레이크</td><td>구조화되지 않은 원시 데이터를 저장하는 저장소</td></tr><tr><td>데이터 처리 방식</td><td>배치 처리</td><td>일정량의 데이터를 모아서 한 번에 처리하는 방식</td></tr><tr><td></td><td>스트리밍 처리</td><td>실시간으로 데이터를 처리하는 방식</td></tr><tr><td>오케스트레이션 도구</td><td>Apache Airflow</td><td>워크플로우를 관리하는 오픈소스 도구</td></tr><tr><td></td><td>Luigi</td><td>Python 기반의 워크플로우 관리 도구</td></tr></tbody></table><h3 id=실무-적용-예시-1>실무 적용 예시<a hidden class=anchor aria-hidden=true href=#실무-적용-예시-1>#</a></h3><table><thead><tr><th>분야</th><th>적용 사례</th><th>설명</th></tr></thead><tbody><tr><td>전자상거래</td><td>추천 시스템</td><td>고객의 행동 데이터를 분석하여 개인화된 상품을 추천합니다.</td></tr><tr><td>금융</td><td>이상 거래 탐지</td><td>거래 데이터를 실시간으로 분석하여 이상 거래를 탐지합니다.</td></tr><tr><td>제조</td><td>예측 유지보수</td><td>센서 데이터를 분석하여 장비의 고장을 예측하고 유지보수를 계획합니다.</td></tr></tbody></table><h3 id=활용-사례>활용 사례<a hidden class=anchor aria-hidden=true href=#활용-사례>#</a></h3><p><strong>시나리오</strong>: 전자상거래 기업에서 고객의 행동 데이터를 분석하여 개인화된 추천 시스템을 구축합니다.</p><p><strong>과정</strong>:</p><ol><li><p>웹 로그, 구매 이력 등의 데이터를 수집합니다.</p></li><li><p>수집된 데이터를 정제하고 변환합니다.</p></li><li><p>데이터를 저장소에 저장합니다.</p></li><li><p>저장된 데이터를 분석하여 고객의 선호도를 파악합니다.</p></li><li><p>분석 결과를 바탕으로 개인화된 상품을 추천합니다.</p></li></ol><p><strong>다이어그램</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a class=lnlinks href=#hl-3-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-plaintext data-lang=plaintext><span class=line><span class=cl>[데이터 수집] → [데이터 처리] → [데이터 저장] → [데이터 분석] → [추천 시스템]
</span></span></code></pre></td></tr></table></div></div><h3 id=실무에서-효과적으로-적용하기-위한-고려사항-및-주의할-점>실무에서 효과적으로 적용하기 위한 고려사항 및 주의할 점<a hidden class=anchor aria-hidden=true href=#실무에서-효과적으로-적용하기-위한-고려사항-및-주의할-점>#</a></h3><table><thead><tr><th>항목</th><th>고려사항</th><th>설명</th></tr></thead><tbody><tr><td>데이터 품질</td><td>정합성 확보</td><td>정확하고 일관된 데이터를 유지해야 합니다.</td></tr><tr><td>인프라 설계</td><td>확장성과 탄력성 확보</td><td>수요 변화에 대응할 수 있도록 클라우드 기반 인프라 및 스케일 아웃 구조 설계가 필요합니다.</td></tr><tr><td>배포 전략</td><td>지속적 통합/배포 (CI/CD) 적용</td><td>데이터 파이프라인의 코드, 설정, 테스트를 자동화하여 신속하고 안정적인 배포를 지원합니다.</td></tr><tr><td>데이터 보안</td><td>권한 관리 및 암호화 적용</td><td>민감 데이터는 암호화하고, 접근 권한은 최소한으로 설정해야 합니다.</td></tr><tr><td>모니터링 및 로깅</td><td>실시간 로그 및 오류 감지</td><td>파이프라인 장애나 성능 저하를 조기 발견할 수 있도록 실시간 모니터링 시스템을 구축합니다.</td></tr><tr><td>데이터 거버넌스</td><td>메타데이터 관리와 추적성 보장</td><td>데이터의 출처, 흐름, 변경 이력을 관리하여 감사 및 품질 관리에 활용합니다.</td></tr></tbody></table><hr><h2 id=-성능을-최적화하기-위한-고려사항-및-주의할-점>⚙ 성능을 최적화하기 위한 고려사항 및 주의할 점<a hidden class=anchor aria-hidden=true href=#-성능을-최적화하기-위한-고려사항-및-주의할-점>#</a></h2><table><thead><tr><th>항목</th><th>고려사항</th><th>설명</th></tr></thead><tbody><tr><td>처리 방식 선택</td><td>배치 vs 스트리밍</td><td>데이터 성격과 실시간성 요구에 따라 적절한 처리 방식을 선택합니다.</td></tr><tr><td>데이터 파티셔닝</td><td>분산 처리 성능 향상</td><td>시간, 지역, 사용자 ID 등으로 데이터를 파티셔닝하여 병렬 처리 성능을 향상시킵니다.</td></tr><tr><td>스토리지 포맷</td><td>효율적인 I/O 처리</td><td>Parquet, ORC 등 컬럼 기반 포맷은 분석과 압축에 효율적입니다.</td></tr><tr><td>캐싱 전략</td><td>반복 쿼리 최적화</td><td>반복되는 데이터 접근은 Redis, Memcached 등의 캐싱 계층을 도입하여 성능을 향상시킵니다.</td></tr><tr><td>리소스 자동 조절</td><td>오토스케일링 설정</td><td>Kubernetes 나 클라우드 플랫폼의 오토스케일링 기능으로 처리량에 따라 자원을 자동 조절합니다.</td></tr></tbody></table><hr><h2 id=-2025-년-기준-최신-동향>📈 2025 년 기준 최신 동향<a hidden class=anchor aria-hidden=true href=#-2025-년-기준-최신-동향>#</a></h2><table><thead><tr><th>주제</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>실시간 처리</td><td>Lakehouse 기반 스트리밍</td><td>Delta Lake, Apache Hudi 등에서 실시간 분석 지원 기능 강화</td></tr><tr><td>자동화</td><td>DataOps</td><td>파이프라인 개발부터 테스트, 배포, 모니터링까지의 전체 흐름 자동화</td></tr><tr><td>클라우드 네이티브</td><td>Serverless 파이프라인</td><td>AWS Glue, Google Cloud Dataflow 등 무서버 기반 데이터 처리 확산</td></tr><tr><td>데이터 보안</td><td>Data Clean Rooms</td><td>기업 간 데이터 공유 시 개인정보 보호를 위한 격리된 분석 환경</td></tr><tr><td>AI 통합</td><td>AI 기반 품질 진단</td><td>머신러닝을 통한 자동 데이터 품질 점검 및 이상 탐지 강화</td></tr></tbody></table><hr><h2 id=-주제와-관련하여-주목할-내용>🔍 주제와 관련하여 주목할 내용<a hidden class=anchor aria-hidden=true href=#-주제와-관련하여-주목할-내용>#</a></h2><table><thead><tr><th>주제</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>데이터 파이프라인</td><td>Declarative Pipeline</td><td>코드가 아닌 선언형 구성으로 파이프라인을 정의하는 방식 (예: dbt)</td></tr><tr><td>데이터 품질</td><td>Data Contracts</td><td>데이터 생산자와 소비자 간 품질 보장을 위한 계약 기반 개발 방식</td></tr><tr><td>오케스트레이션</td><td>Event-Driven Pipeline</td><td>일정 기반이 아닌 이벤트 발생에 따라 작동하는 동적 워크플로우 구조</td></tr><tr><td>스토리지</td><td>Lakehouse 아키텍처</td><td>데이터 레이크와 웨어하우스를 통합한 최신 저장 아키텍처 모델</td></tr><tr><td>데이터 접근</td><td>Unified Query Layer</td><td>다양한 저장소를 통합 쿼리할 수 있는 데이터 가상화 기술 (예: Starburst, Presto)</td></tr></tbody></table><hr><h2 id=-앞으로의-전망>🔮 앞으로의 전망<a hidden class=anchor aria-hidden=true href=#-앞으로의-전망>#</a></h2><table><thead><tr><th>주제</th><th>항목</th><th>설명</th></tr></thead><tbody><tr><td>데이터 엔지니어링</td><td>자동화 가속</td><td>코드 작성 최소화, 구성 기반 파이프라인이 대세로 자리잡음</td></tr><tr><td>인프라 운영</td><td>하이브리드/멀티 클라우드 확산</td><td>이기종 환경을 아우르는 데이터 처리 전략의 중요성 증가</td></tr><tr><td>데이터 보안</td><td>AI 기반 보안 자동화</td><td>비정상 접근 및 이상 데이터 흐름을 탐지하는 AI 기반 보안 솔루션 확대</td></tr><tr><td>협업</td><td>Cross-functional 팀 구성</td><td>데이터 엔지니어, 사이언티스트, 분석가가 함께 일하는 구조 확대</td></tr><tr><td>개발 문화</td><td>GitOps + DataOps</td><td>코드와 인프라, 데이터까지 Git 중심으로 관리하는 문화 정착</td></tr></tbody></table><hr><h2 id=-학습해야-할-하위-주제-분류>📚 학습해야 할 하위 주제 분류<a hidden class=anchor aria-hidden=true href=#-학습해야-할-하위-주제-분류>#</a></h2><table><thead><tr><th>카테고리</th><th>주제</th><th>간략 설명</th></tr></thead><tbody><tr><td>데이터 모델링</td><td>스타 스키마, 정규화</td><td>분석 최적화 혹은 저장 최적화를 위한 데이터 구조 설계</td></tr><tr><td>처리 프레임워크</td><td>Apache Spark, Flink</td><td>대규모 데이터 처리를 위한 분산 처리 엔진</td></tr><tr><td>스토리지 기술</td><td>Delta Lake, Iceberg</td><td>ACID 트랜잭션이 가능한 현대적 데이터 레이크 스토리지</td></tr><tr><td>오케스트레이션</td><td>Airflow, Dagster</td><td>워크플로우 자동화 및 스케줄링 도구</td></tr><tr><td>실시간 처리</td><td>Kafka, Flink, Kinesis</td><td>스트리밍 데이터 처리 기술 및 시스템 설계</td></tr></tbody></table><hr><h2 id=-관련-분야-및-학습-주제>📘 관련 분야 및 학습 주제<a hidden class=anchor aria-hidden=true href=#-관련-분야-및-학습-주제>#</a></h2><table><thead><tr><th>카테고리</th><th>주제</th><th>간략 설명</th></tr></thead><tbody><tr><td>DevOps</td><td>CI/CD for Data Pipelines</td><td>데이터 엔지니어링 파이프라인의 테스트 및 배포 자동화</td></tr><tr><td>보안</td><td>Data Tokenization & Masking</td><td>민감 데이터 보호를 위한 처리 기법</td></tr><tr><td>클라우드 아키텍처</td><td>Cloud-native Data Stack</td><td>클라우드에 최적화된 데이터 엔지니어링 구성 요소 설계</td></tr><tr><td>MLOps</td><td>피처 스토어 및 데이터 버전 관리</td><td>모델 학습 및 재현성을 위한 데이터 관리 체계</td></tr><tr><td>Observability</td><td>데이터 관측성 시스템</td><td>로그, 메트릭, 트레이싱을 통한 데이터 흐름 감시 및 진단 체계</td></tr></tbody></table><hr><h2 id=용어-정리-2>용어 정리<a hidden class=anchor aria-hidden=true href=#용어-정리-2>#</a></h2><table><thead><tr><th>용어</th><th>설명</th></tr></thead><tbody><tr><td>ETL / ELT</td><td>데이터 추출 (Extract), 변환 (Transform), 적재 (Load) 의 흐름 또는 순서를 의미하는 데이터 처리 방식</td></tr><tr><td>데이터 웨어하우스</td><td>분석 목적으로 최적화된 구조화된 데이터 저장소 (예: Snowflake, BigQuery)</td></tr><tr><td>데이터 레이크</td><td>정형/비정형 데이터를 원시 상태로 저장하는 대규모 저장소</td></tr><tr><td>오케스트레이션 도구</td><td>데이터 워크플로우를 자동화 및 스케줄링하는 도구 (예: Airflow, Dagster)</td></tr><tr><td>Lakehouse</td><td>데이터 웨어하우스와 데이터 레이크의 장점을 결합한 통합형 아키텍처</td></tr><tr><td>DataOps</td><td>데이터 파이프라인의 개발, 배포, 테스트, 모니터링을 자동화하고 최적화하는 접근 방식</td></tr></tbody></table><hr><h2 id=참고-및-출처-2>참고 및 출처<a hidden class=anchor aria-hidden=true href=#참고-및-출처-2>#</a></h2><ul><li><p><a href=https://aws.amazon.com/blogs/big-data/>AWS Data Engineering 블로그</a></p></li><li><p><a href=https://www.databricks.com/blog/category/engineering>Databricks Engineering Blog</a></p></li><li><p><a href=https://www.kdnuggets.com/tag/data-engineering>KDNuggets - Data Engineering</a></p></li><li><p><a href=https://cloud.google.com/architecture/modern-data-stack-overview>Google Cloud - Modern Data Stack</a></p></li><li><p><a href=https://docs.getdbt.com/>dbt Docs - Transformations as Code</a></p></li></ul><hr><p>필요하다면 각 구성 요소에 대한 시각적 다이어그램, 코드 예제, 아키텍처 상세 설명도 단계별로 제공해드릴 수 있습니다. 다음으로 어떤 내용을 더 알고 싶으신가요?</p><p><a href=https://www.devkuma.com/docs/big-data/term/><figure><img alt="빅데이터 분석 기반이란? 데이터 파이프라인 구축 | devkuma" loading=lazy src="https://tse4.mm.bing.net/th?id=OIP.3CaXEGjyoTnut75U_c3pyAHaEo&pid=Api"></figure></a></p><p>데이터 엔지니어링의 핵심 구성 요소에 대한 시각적 다이어그램, 코드 예제, 아키텍처 상세 설명을 아래와 같이 제공합니다.</p><hr><h2 id=-데이터-엔지니어링-아키텍처-다이어그램>📊 데이터 엔지니어링 아키텍처 다이어그램<a hidden class=anchor aria-hidden=true href=#-데이터-엔지니어링-아키텍처-다이어그램>#</a></h2><p>데이터 엔지니어링 아키텍처는 일반적으로 다음과 같은 구성 요소로 이루어집니다:</p><ol><li><p><strong>데이터 소스 (Data Sources)</strong>: 내부 데이터베이스, API, 로그 파일, IoT 센서 등 다양한 형태의 원천 데이터를 제공합니다.</p></li><li><p><strong>데이터 수집 (Data Ingestion)</strong>: Apache Kafka, AWS Kinesis, Google Pub/Sub 등을 사용하여 데이터를 실시간 또는 배치 방식으로 수집합니다.</p></li><li><p><strong>데이터 처리 (Data Processing)</strong>: Apache Spark, Flink, Beam 등을 활용하여 데이터를 변환, 정제, 집계합니다.</p></li><li><p><strong>데이터 저장 (Data Storage)</strong>: 데이터 웨어하우스 (Snowflake, BigQuery) 나 데이터 레이크 (S3, HDFS) 에 데이터를 저장합니다.</p></li><li><p><strong>데이터 오케스트레이션 (Data Orchestration)</strong>: Apache Airflow, Prefect, Dagster 등을 사용하여 워크플로우를 관리합니다.</p></li><li><p><strong>데이터 소비 (Data Consumption)</strong>: BI 도구 (Tableau, Looker) 나 머신러닝 모델을 통해 데이터를 분석하고 시각화합니다.(<a href="https://www.geeksforgeeks.org/data-architecture-diagrams/?utm_source=chatgpt.com" title="Data Architecture Diagrams | GeeksforGeeks">GeeksforGeeks</a>)</p></li></ol><p>이러한 구성 요소들은 데이터의 흐름을 원활하게 관리하고, 데이터 품질을 유지하며, 실시간 분석 및 예측 모델링을 가능하게 합니다.<br><figure><img alt=data-engineering loading=lazy src=/img/data-engineering.png></figure></p><hr><h2 id=-etl-파이프라인-코드-예제-python-기반>🧪 ETL 파이프라인 코드 예제 (Python 기반)<a hidden class=anchor aria-hidden=true href=#-etl-파이프라인-코드-예제-python-기반>#</a></h2><p>다음은 Python 을 사용하여 간단한 ETL(Extract, Transform, Load) 파이프라인을 구현한 예제입니다:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1> 1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2> 2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3> 3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4> 4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5> 5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6> 6</a>
</span><span class=lnt id=hl-4-7><a class=lnlinks href=#hl-4-7> 7</a>
</span><span class=lnt id=hl-4-8><a class=lnlinks href=#hl-4-8> 8</a>
</span><span class=lnt id=hl-4-9><a class=lnlinks href=#hl-4-9> 9</a>
</span><span class=lnt id=hl-4-10><a class=lnlinks href=#hl-4-10>10</a>
</span><span class=lnt id=hl-4-11><a class=lnlinks href=#hl-4-11>11</a>
</span><span class=lnt id=hl-4-12><a class=lnlinks href=#hl-4-12>12</a>
</span><span class=lnt id=hl-4-13><a class=lnlinks href=#hl-4-13>13</a>
</span><span class=lnt id=hl-4-14><a class=lnlinks href=#hl-4-14>14</a>
</span><span class=lnt id=hl-4-15><a class=lnlinks href=#hl-4-15>15</a>
</span><span class=lnt id=hl-4-16><a class=lnlinks href=#hl-4-16>16</a>
</span><span class=lnt id=hl-4-17><a class=lnlinks href=#hl-4-17>17</a>
</span><span class=lnt id=hl-4-18><a class=lnlinks href=#hl-4-18>18</a>
</span><span class=lnt id=hl-4-19><a class=lnlinks href=#hl-4-19>19</a>
</span><span class=lnt id=hl-4-20><a class=lnlinks href=#hl-4-20>20</a>
</span><span class=lnt id=hl-4-21><a class=lnlinks href=#hl-4-21>21</a>
</span><span class=lnt id=hl-4-22><a class=lnlinks href=#hl-4-22>22</a>
</span><span class=lnt id=hl-4-23><a class=lnlinks href=#hl-4-23>23</a>
</span><span class=lnt id=hl-4-24><a class=lnlinks href=#hl-4-24>24</a>
</span><span class=lnt id=hl-4-25><a class=lnlinks href=#hl-4-25>25</a>
</span><span class=lnt id=hl-4-26><a class=lnlinks href=#hl-4-26>26</a>
</span><span class=lnt id=hl-4-27><a class=lnlinks href=#hl-4-27>27</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sqlalchemy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 데이터 추출 (Extract)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;source_data.csv&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 데이터 변환 (Transform)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>transform_data</span><span class=p>(</span><span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>[</span><span class=s1>&#39;total&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;quantity&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;price&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;total&#39;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>1000</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 데이터 적재 (Load)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_data</span><span class=p>(</span><span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>engine</span> <span class=o>=</span> <span class=n>sqlalchemy</span><span class=o>.</span><span class=n>create_engine</span><span class=p>(</span><span class=s1>&#39;postgresql://user:password@localhost:5432/mydatabase&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>to_sql</span><span class=p>(</span><span class=s1>&#39;sales_summary&#39;</span><span class=p>,</span> <span class=n>engine</span><span class=p>,</span> <span class=n>if_exists</span><span class=o>=</span><span class=s1>&#39;replace&#39;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ETL 파이프라인 실행</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_etl</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>extract_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>transformed_data</span> <span class=o>=</span> <span class=n>transform_data</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>load_data</span><span class=p>(</span><span class=n>transformed_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>run_etl</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>이 코드는 CSV 파일에서 데이터를 읽어와 특정 조건에 따라 변환한 후, PostgreSQL 데이터베이스에 저장합니다.</p><hr><h2 id=-아키텍처-상세-설명>🧱 아키텍처 상세 설명<a hidden class=anchor aria-hidden=true href=#-아키텍처-상세-설명>#</a></h2><p>데이터 엔지니어링 아키텍처는 다양한 구성 요소로 이루어져 있으며, 각 구성 요소는 특정한 역할을 수행합니다:</p><ul><li><p><strong>데이터 소스</strong>: 내부 시스템 (ERP, CRM), 외부 API, 로그 파일 등 다양한 형태의 데이터를 제공합니다.</p></li><li><p><strong>데이터 수집</strong>: Apache Kafka, AWS Kinesis 등을 사용하여 데이터를 실시간으로 수집하거나, 배치 방식으로 데이터를 가져옵니다.</p></li><li><p><strong>데이터 처리</strong>: Apache Spark, Flink 등을 활용하여 데이터를 변환, 정제, 집계합니다.</p></li><li><p><strong>데이터 저장</strong>: 데이터 웨어하우스 (Snowflake, BigQuery) 나 데이터 레이크 (S3, HDFS) 에 데이터를 저장하여 분석 및 머신러닝 모델링에 활용합니다.</p></li><li><p><strong>데이터 오케스트레이션</strong>: Apache Airflow, Prefect 등을 사용하여 데이터 파이프라인의 워크플로우를 관리하고, 스케줄링합니다.</p></li><li><p><strong>데이터 소비</strong>: BI 도구 (Tableau, Looker) 나 머신러닝 모델을 통해 데이터를 분석하고 시각화하여 비즈니스 인사이트를 도출합니다.</p></li></ul><p>이러한 아키텍처는 데이터의 수집부터 분석까지의 전 과정을 체계적으로 관리하며, 데이터 기반 의사결정을 지원합니다.</p><hr><h2 id=-참고-자료>📚 참고 자료<a hidden class=anchor aria-hidden=true href=#-참고-자료>#</a></h2><ul><li><p><a href=https://www.montecarlodata.com/blog-data-pipeline-architecture-explained/>Data Pipeline Architecture Explained</a></p></li><li><p><a href=https://medium.com/art-of-data-engineering/building-your-first-etl-pipeline-with-python-and-sql-3f4084a08ff1>Building Your First ETL Pipeline with Python and SQL</a></p></li><li><p><a href=https://www.instaclustr.com/education/data-architecture/data-architecture-diagrams-practical-2025-guide-with-examples/>Data Architecture Diagrams: Practical 2025 Guide with Examples</a></p></li></ul><hr><p>추가적으로, 특정 도구나 프레임워크에 대한 상세한 정보나 구현 방법에 대해 궁금하신 점이 있으시면 언제든지 문의해 주세요.</p></div><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Data Pipeline Pattern</h2></header><div class=entry-content><p>Data Pipeline Pattern 데이터 파이프라인 패턴은 데이터를 원천에서 목적지로 이동시키는 과정을 자동화하고 최적화하는 아키텍처 패턴이다.
이 패턴은 데이터의 수집, 처리, 저장, 분석에 이르는 전체 과정을 효율적으로 관리하는 데 사용된다.
데이터 파이프라인 패턴을 효과적으로 구현하면 데이터 기반 의사결정을 지원하고, 비즈니스 인텔리전스를 향상시킬 수 있다. 각 조직의 요구사항과 데이터 특성에 맞는 최적의 패턴을 선택하고 구현하는 것이 중요하다.
https://www.informatica.com/blogs/data-processing-pipeline-patterns.html
데이터 파이프라인의 주요 구성요소 데이터 수집 (Data Ingestion)
다양한 소스(데이터베이스, API, 로그 파일 등)에서 데이터를 추출한다. 실시간 또는 배치 방식으로 데이터를 수집할 수 있다. 데이터 처리 및 변환 (Data Processing and Transformation)
...</p></div><footer class=entry-footer><span title='2024-11-19 03:56:00 +0000 UTC'>November 19, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Data Pipeline Pattern" href=https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/data-pipeline/data-pipeline-design/data-pipeline-pattern/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Airflow</h2></header><div class=entry-content><p>Airflow Apache Airflow는 데이터 파이프라인을 구축, 관리, 모니터링하기 위한 오픈소스 플랫폼이다.
Airflow는 복잡한 데이터 파이프라인을 효율적으로 관리할 수 있게 해주는 강력한 도구이다.
데이터 엔지니어링 분야에서 널리 사용되며, 지속적으로 발전하고 있는 플랫폼이다.
기본적인 DAG(Directed Acyclic Graph) 예시:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime, timedelta # DAG 기본 설정 default_args = { 'owner': 'data_engineer', 'depends_on_past': False, 'start_date': datetime(2024, 1, 1), 'email': ['alert@example.com'], 'email_on_failure': True, 'retries': 1, 'retry_delay': timedelta(minutes=5) } # DAG 정의 dag = DAG( 'data_processing_pipeline', default_args=default_args, description='데이터 처리 파이프라인', schedule_interval='0 0 * * *' # 매일 자정에 실행 ) # 태스크 함수 정의 def extract_data(**context): # 데이터 추출 로직 raw_data = {'data': 'extracted_value'} context['task_instance'].xcom_push(key='raw_data', value=raw_data) def transform_data(**context): # 데이터 변환 로직 raw_data = context['task_instance'].xcom_pull(key='raw_data') transformed_data = {'data': f"transformed_{raw_data['data']}"} context['task_instance'].xcom_push(key='transformed_data', value=transformed_data) def load_data(**context): # 데이터 적재 로직 transformed_data = context['task_instance'].xcom_pull(key='transformed_data') print(f"Loading data: {transformed_data}") # 태스크 생성 extract_task = PythonOperator( task_id='extract_data', python_callable=extract_data, provide_context=True, dag=dag ) transform_task = PythonOperator( task_id='transform_data', python_callable=transform_data, provide_context=True, dag=dag ) load_task = PythonOperator( task_id='load_data', python_callable=load_data, provide_context=True, dag=dag ) # 태스크 의존성 설정 extract_task >> transform_task >> load_task Airflow의 주요 특징 Python 기반: DAG(Directed Acyclic Graph)를 Python 코드로 정의할 수 있어 유연성과 확장성이 뛰어나다. 스케줄링: 복잡한 워크플로우를 쉽게 스케줄링할 수 있다. 모니터링: 웹 인터페이스를 통해 작업 실행 상태를 실시간으로 모니터링할 수 있다. 확장성: 다양한 외부 시스템과 쉽게 통합할 수 있다. Airflow의 주요 구성 요소 DAG (Directed Acyclic Graph):
...</p></div><footer class=entry-footer><span title='2024-10-26 05:18:00 +0000 UTC'>October 26, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Me</footer><a class=entry-link aria-label="post link to Airflow" href=https://buenhyden.github.io/posts/data-science-and-engineering/data-engineering/data-pipeline/data-pipeline-tools/airflow/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://buenhyden.github.io/>hyunyoun's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>