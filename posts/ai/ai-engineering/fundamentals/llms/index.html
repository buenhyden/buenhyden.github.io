<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LLMs | hyunyoun's Blog</title>
<meta name=keywords content="AI,AI-Engineering,Fundamentals,LLMs"><meta name=description content="대규모 언어 모델(Large Language Models, 줄여서 LLMs)은 인공지능의 한 분야인 자연어 처리(NLP)에서 사용되는 거대한 규모의 신경망 모델이다.이 모델들은 인간의 언어를 이해하고 생성하는 능력을 가지고 있으며, 수십억 또는 수천억 개의 매개변수(parameters)를 포함하고 있다."><meta name=author content="Me"><link rel=canonical href=https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/llms/><meta name=google-site-verification content="googlee06938ebbfcbac49.html"><link crossorigin=anonymous href=/assets/css/stylesheet.8762af4fa9ee176c57f72565b721f234162fc7a9c882a271e0a1f68c4e89fb34.css integrity="sha256-h2KvT6nuF2xX9yVltyHyNBYvx6nIgqJx4KH2jE6J+zQ=" rel="preload stylesheet" as=style><link rel=icon href=https://buenhyden.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://buenhyden.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://buenhyden.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://buenhyden.github.io/favicons/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/llms/index.xml><link rel=alternate hreflang=en href=https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/llms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3156423099418350" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W8XTMYPTLC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W8XTMYPTLC")}</script><meta property="og:url" content="https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/llms/"><meta property="og:site_name" content="hyunyoun's Blog"><meta property="og:title" content="LLMs"><meta property="og:description" content="대규모 언어 모델(Large Language Models, 줄여서 LLMs)은 인공지능의 한 분야인 자연어 처리(NLP)에서 사용되는 거대한 규모의 신경망 모델이다.이 모델들은 인간의 언어를 이해하고 생성하는 능력을 가지고 있으며, 수십억 또는 수천억 개의 매개변수(parameters)를 포함하고 있다."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://buenhyden.github.io/images"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://buenhyden.github.io/images"><meta name=twitter:title content="LLMs"><meta name=twitter:description content="대규모 언어 모델(Large Language Models, 줄여서 LLMs)은 인공지능의 한 분야인 자연어 처리(NLP)에서 사용되는 거대한 규모의 신경망 모델이다.이 모델들은 인간의 언어를 이해하고 생성하는 능력을 가지고 있으며, 수십억 또는 수천억 개의 매개변수(parameters)를 포함하고 있다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"posts","item":"https://buenhyden.github.io/posts/"},{"@type":"ListItem","position":2,"name":"인공지능(Artificial Intelligence, AI)","item":"https://buenhyden.github.io/posts/ai/"},{"@type":"ListItem","position":3,"name":"AI Engineering","item":"https://buenhyden.github.io/posts/ai/ai-engineering/"},{"@type":"ListItem","position":4,"name":"Fundamentals of AI Engineering","item":"https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/"},{"@type":"ListItem","position":5,"name":"LLMs","item":"https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/llms/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://buenhyden.github.io/ accesskey=h title="Hy's Blog (Alt + H)"><img src=https://buenhyden.github.io/favicons/apple-touch-icon.png alt aria-label=logo height=35>Hy's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://buenhyden.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://buenhyden.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://buenhyden.github.io/til/ title="Today I Learned"><span>Today I Learned</span></a></li><li><a href=https://buenhyden.github.io/coding-test/ title="Coding Test"><span>Coding Test</span></a></li><li><a href=https://buenhyden.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://buenhyden.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://buenhyden.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://buenhyden.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/>posts</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/ai/>인공지능(Artificial Intelligence, AI)</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/ai/ai-engineering/>AI Engineering</a>&nbsp;»&nbsp;<a href=https://buenhyden.github.io/posts/ai/ai-engineering/fundamentals/>Fundamentals of AI Engineering</a></div><h1>LLMs</h1><div class=post-description>대규모 언어 모델(Large Language Models, 줄여서 LLMs)은 인공지능의 한 분야인 자연어 처리(NLP)에서 사용되는 거대한 규모의 신경망 모델이다.이 모델들은 인간의 언어를 이해하고 생성하는 능력을 가지고 있으며, 수십억 또는 수천억 개의 매개변수(parameters)를 포함하고 있다.</div></header><div class=post-content><h2 id=llms>LLMs<a hidden class=anchor aria-hidden=true href=#llms>#</a></h2><p>대규모 언어 모델(Large Language Models, 줄여서 LLMs)은 인공지능의 한 분야인 자연어 처리(NLP)에서 사용되는 거대한 규모의 신경망 모델이다.이 모델들은 인간의 언어를 이해하고 생성하는 능력을 가지고 있으며, 수십억 또는 수천억 개의 매개변수(parameters)를 포함하고 있다.</p><p>LLM이 무엇인지 쉽게 이해하기 위해 비유를 들어보면:<br>여러분이 외국어를 배우는 과정을 생각해보자!<br>처음에는 단어를 몇 개 배우고, 그다음 간단한 문장을 만들고, 점차 다양한 책과 글을 읽으면서 언어의 미묘한 뉘앙스와 문맥적 의미를 이해하게 된다.<br>LLM도 유사한 과정을 거치지만, 인터넷에서 가져온 방대한 양의 텍스트를 &lsquo;읽고&rsquo; 언어 패턴을 학습한다.</p><p>LLM의 주요 특징은 다음과 같다:</p><ol><li><strong>대규모 매개변수</strong>: 최신 모델들은 수천억 개의 매개변수를 가지고 있어 복잡한 언어 패턴을 포착할 수 있다.</li><li><strong>자기지도학습(Self-supervised learning)</strong>: 라벨이 없는 방대한 텍스트 데이터에서 스스로 패턴을 학습한다.</li><li><strong>전이 학습 능력</strong>: 다양한 과제에 쉽게 적용될 수 있는 일반적인 언어 이해 능력을 갖추고 있다.</li><li><strong>맥락 이해</strong>: 긴 문맥을 고려하여 텍스트를 이해하고 생성할 수 있다.</li></ol><p>대규모 언어 모델(LLM)은 인공지능의 새로운 시대를 열었으며, 이 분야는 계속해서 빠르게 발전하고 있다.</p><p>LLM의 기본 원리와 작동 방식을 이해하는 것에서 시작하여, 다양한 기술과 방법론을 배우고, 결국 실제 문제를 해결하는 애플리케이션을 개발하는 과정은 지속적인 학습과 실험을 요구한다.</p><p>중요한 것은 이론과 실습의 균형을 유지하는 것이다. 논문과 개념을 공부하는 것도 중요하지만, 직접 코드를 작성하고, 모델을 조정하고, 애플리케이션을 구축하는 경험이 진정한 이해와 성장을 가져다준다.</p><p>또한, LLM의 윤리적 측면과 사회적 영향을 항상 고려하는 책임감 있는 개발자가 되어야 한다. 이 강력한 기술이 긍정적인 방향으로 사용될 수 있도록 하는 것은 우리 모두의 책임이다.</p><h3 id=llm의-역사와-발전-과정>LLM의 역사와 발전 과정<a hidden class=anchor aria-hidden=true href=#llm의-역사와-발전-과정>#</a></h3><p>LLM의 발전 과정을 이해하면 현재의 기술이 얼마나 획기적인지 더 잘 알 수 있다.</p><ol><li><p>초기 언어 모델 (1990년대~2000년대 초반)<br>처음에는 N-gram 모델과 같은 통계적 접근법이 사용되었다. 이 모델들은 단어 시퀀스의 확률을 계산하는 방식으로 작동했지만, 긴 문맥을 고려하지 못하는 한계가 있었다.</p></li><li><p>신경망 기반 언어 모델의 등장 (2010년대 초반)<br>2013년 Word2Vec과 같은 단어 임베딩 모델이 등장하면서 단어의 의미를 벡터 공간에 매핑하는 방법이 개발되었다. 이후 RNN(Recurrent Neural Networks)과 LSTM(Long Short-Term Memory) 네트워크가 순차적 데이터 처리에 적용되기 시작했다.</p></li><li><p>트랜스포머의 혁명 (2017년~현재)<br>2017년, 구글에서 &ldquo;Attention is All You Need&rdquo; 논문을 통해 트랜스포머(Transformer) 아키텍처를 소개했다. 이는 어텐션 메커니즘을 활용하여 긴 문맥을 더 효과적으로 처리할 수 있게 해주었고, LLM 발전의 기반이 되었다.</p></li></ol><h4 id=주요-llm-모델의-발전-타임라인>주요 LLM 모델의 발전 타임라인<a hidden class=anchor aria-hidden=true href=#주요-llm-모델의-발전-타임라인>#</a></h4><ol><li><strong>BERT (2018)</strong>: 구글이 개발한 양방향 트랜스포머 모델로, 문맥을 고려한 단어 표현이 가능해졌다.</li><li><strong>GPT (2018)</strong>: OpenAI의 첫 번째 생성형 사전학습 트랜스포머 모델로, 117M 매개변수를 가졌다.</li><li><strong>GPT-2 (2019)</strong>: 15억 매개변수로 확장되어 더 자연스러운 텍스트 생성이 가능해졌다.</li><li><strong>GPT-3 (2020)</strong>: 1750억 매개변수로 대폭 확장되어 다양한 NLP 작업을 적은 예시만으로 수행할 수 있게 되었다.</li><li><strong>PaLM, LaMDA, Chinchilla (2022)</strong>: 구글, DeepMind 등에서 개발한 대규모 모델들이 등장했다.</li><li><strong>GPT-4, Claude, Gemini (2023-2024)</strong>: 멀티모달 능력과 정교한 추론 능력을 갖춘 더 발전된 모델들이 출시되었다.</li></ol><p>이러한 발전 과정에서 모델의 크기(매개변수 수)가 증가하고, 학습 데이터의 양과 질이 향상되면서 모델의 성능이 극적으로 개선되었다.</p><h3 id=llm의-작동-원리>LLM의 작동 원리<a hidden class=anchor aria-hidden=true href=#llm의-작동-원리>#</a></h3><p>LLM의 작동 원리를 이해하기 위해 주요 구성 요소와 학습 과정을 알아보자.</p><h4 id=트랜스포머-아키텍처>트랜스포머 아키텍처<a hidden class=anchor aria-hidden=true href=#트랜스포머-아키텍처>#</a></h4><p>현대 LLM의 기반이 되는 트랜스포머 아키텍처는 다음과 같은 주요 구성 요소를 가지고 있다:</p><ol><li><strong>토큰 임베딩(Token Embeddings)</strong>: 텍스트를 숫자 벡터로 변환한다.</li><li><strong>위치 인코딩(Positional Encoding)</strong>: 단어의 위치 정보를 모델에 제공한다.</li><li><strong>멀티헤드 어텐션(Multi-head Attention)</strong>: 텍스트 내 다른 위치 간의 관계를 계산한다.</li><li><strong>피드포워드 신경망(Feed-forward Neural Networks)</strong>: 각 위치의 표현을 독립적으로 처리한다.</li><li><strong>레이어 정규화(Layer Normalization)</strong>: 훈련을 안정화하는 데 도움을 준다.</li><li><strong>잔차 연결(Residual Connections)</strong>: 정보가 깊은 네트워크를 통과할 수 있게 한다.</li></ol><h4 id=어텐션-메커니즘의-이해>어텐션 메커니즘의 이해<a hidden class=anchor aria-hidden=true href=#어텐션-메커니즘의-이해>#</a></h4><p>어텐션 메커니즘은 현대 LLM의 핵심이다. 이는 모델이 텍스트의 어떤 부분에 &lsquo;주목&rsquo;해야 하는지 결정하는 방법이다.</p><p>간단한 예를 들어보면:<br>&ldquo;그녀는 책을 읽고 그것이 재미있다고 생각했다"라는 문장에서 &ldquo;그것"이 무엇을 가리키는지 이해하려면, &ldquo;그것"과 &ldquo;책&rdquo; 사이의 관계를 파악해야 한다.<br>어텐션 메커니즘은 이런 관계의 중요도를 계산하여 모델이 적절한 맥락을 파악할 수 있게 한다.</p><p>어텐션은 Query(Q), Key(K), Value(V)라는 세 가지 벡터를 사용하여 계산된다:</p><pre class=mermaid>Attention(Q, K, V) = softmax((Q * K^T) / sqrt(d_k)) * V
</pre><p>멀티헤드 어텐션은 이 과정을 여러 번 병렬로 수행하여 다양한 관점에서 텍스트를 분석한다.</p><h4 id=토크나이징tokenizing>토크나이징(Tokenizing)<a hidden class=anchor aria-hidden=true href=#토크나이징tokenizing>#</a></h4><p>LLM이 텍스트를 처리하기 위해서는 먼저 텍스트를 토큰(tokens)이라는 더 작은 단위로 나눠야 한다.<br>토큰은 단어, 부분 단어, 문자, 또는 문자 조합일 수 있다.</p><p>예를 들어, &ldquo;안녕하세요"라는 단어는 [&ldquo;안녕&rdquo;, &ldquo;하세요&rdquo;] 또는 [&ldquo;안&rdquo;, &ldquo;녕&rdquo;, &ldquo;하&rdquo;, &ldquo;세&rdquo;, &ldquo;요&rdquo;]와 같이 여러 토큰으로 나뉠 수 있다. 사용되는 토크나이저에 따라 분할 방식이 달라진다.</p><p>주요 토크나이징 방식:</p><ul><li><strong>단어 기반(Word-based)</strong>: 전체 단어를 토큰으로 사용 (어휘 크기가 매우 커짐)</li><li><strong>문자 기반(Character-based)</strong>: 개별 문자를 토큰으로 사용 (시퀀스가 매우 길어짐)</li><li><strong>부분 단어 기반(Subword-based)</strong>: BPE(Byte Pair Encoding), WordPiece, SentencePiece 등의 알고리즘을 사용하여 단어의 일부를 토큰으로 활용 (대부분의 현대 LLM이 채택)</li></ul><h4 id=학습-과정>학습 과정<a hidden class=anchor aria-hidden=true href=#학습-과정>#</a></h4><p>LLM의 학습은 크게 사전학습(Pre-training)과 미세조정(Fine-tuning)의 두 단계로 나뉜다:</p><ol><li><strong>사전학습</strong>:<ul><li>방대한 양의 텍스트 데이터를 사용한다 (수백 GB에서 수 TB).</li><li>주로 다음 토큰 예측(Next Token Prediction) 작업을 수행한다.</li><li>자기회귀적(Autoregressive) 모델은 이전 토큰을 기반으로 다음 토큰을 예측한다.</li><li>막대한 컴퓨팅 자원이 필요하며, 수천 개의 GPU를 사용하여 수주에서 수개월간 학습한다.</li></ul></li><li><strong>미세조정</strong>:<ul><li>특정 작업이나 도메인에 맞게 사전학습된 모델을 추가로 훈련한다.</li><li>지도학습(Supervised Learning)을 사용하여 특정 입력-출력 쌍에 맞게 조정한다.</li><li>RLHF(Reinforcement Learning from Human Feedback)와 같은 기법을 사용하여 인간의 선호도에 맞게 조정하기도 한다.</li></ul></li></ol><p>간단한 코드로 다음 토큰 예측 학습 방식을 이해해보면:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1> 1</a>
</span><span class=lnt id=hl-1-2><a class=lnlinks href=#hl-1-2> 2</a>
</span><span class=lnt id=hl-1-3><a class=lnlinks href=#hl-1-3> 3</a>
</span><span class=lnt id=hl-1-4><a class=lnlinks href=#hl-1-4> 4</a>
</span><span class=lnt id=hl-1-5><a class=lnlinks href=#hl-1-5> 5</a>
</span><span class=lnt id=hl-1-6><a class=lnlinks href=#hl-1-6> 6</a>
</span><span class=lnt id=hl-1-7><a class=lnlinks href=#hl-1-7> 7</a>
</span><span class=lnt id=hl-1-8><a class=lnlinks href=#hl-1-8> 8</a>
</span><span class=lnt id=hl-1-9><a class=lnlinks href=#hl-1-9> 9</a>
</span><span class=lnt id=hl-1-10><a class=lnlinks href=#hl-1-10>10</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 다음 토큰 예측의 개념적 표현</span>
</span></span><span class=line><span class=cl><span class=n>input_text</span> <span class=o>=</span> <span class=s2>&#34;나는 오늘 점심으로 맛있는&#34;</span>
</span></span><span class=line><span class=cl><span class=n>target_next_token</span> <span class=o>=</span> <span class=s2>&#34;피자&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 모델이 다음 토큰의 확률 분포를 예측</span>
</span></span><span class=line><span class=cl><span class=n>predicted_probabilities</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 실제 정답 토큰과의 차이(손실)를 계산하여 모델 학습</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>calculate_loss</span><span class=p>(</span><span class=n>predicted_probabilities</span><span class=p>,</span> <span class=n>target_next_token</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>update_weights</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=주요-llm-모델과-그-특징>주요 LLM 모델과 그 특징<a hidden class=anchor aria-hidden=true href=#주요-llm-모델과-그-특징>#</a></h3><p>현재 사용되고 있는 주요 LLM 모델들과 그 특징을 살펴보면:</p><ol><li><p>OpenAI 모델</p><ul><li><strong>GPT-3.5</strong>: 1750억 매개변수를 가진 모델로, ChatGPT의 기반이 되었다.</li><li><strong>GPT-4</strong>: 매개변수 수는 공개되지 않았지만, 멀티모달 능력(텍스트와 이미지 처리)과 향상된 추론 및 안전성을 갖추고 있다.</li><li><strong>특징</strong>: 다양한 작업에서 높은 성능을 보이며, API를 통해 접근할 수 있다.</li></ul></li><li><p>Google 모델</p><ul><li><strong>PaLM/PaLM 2</strong>: 5400억 매개변수(PaLM)를 가진 모델로, 다국어 능력과 추론 능력이 뛰어나다.</li><li><strong>Gemini</strong>: 멀티모달 처리 능력을 갖춘 최신 모델로, 다양한 크기(Ultra, Pro, Nano)로 제공된다.</li><li><strong>특징</strong>: 구글의 검색 및 AI 제품에 통합되어 있으며, Vertex AI를 통해 API로 제공된다.</li></ul></li><li><p>Meta 모델</p><ul><li><strong>LLaMA/LLaMA 2</strong>: 70억에서 700억 매개변수 범위의 오픈소스 모델이다.</li><li><strong>특징</strong>: 상업적 이용이 가능한 라이선스로 제공되어, 다양한 커뮤니티 프로젝트의 기반이 되고 있다.</li></ul></li><li><p>Anthropic 모델</p><ul><li><strong>Claude/Claude 2/Claude 3</strong>: 안전성과 유용성에 중점을 둔 모델로, 긴 문맥 처리 능력이 뛰어나다.</li><li><strong>특징</strong>: AI 안전성 연구에 중점을 두고 있으며, 유해한 출력을 최소화하도록 설계되었다.</li></ul></li><li><p>오픈소스 모델</p><ul><li><strong>Mistral</strong>: 7B 크기의 작은 모델임에도 우수한 성능을 보이는 프랑스 스타트업의 모델이다.</li><li><strong>Falcon</strong>: 아랍에미리트의 TII에서 개발한 모델로, 다양한 크기(7B, 40B, 180B)로 제공된다.</li><li><strong>BLOOM</strong>: 다국어 처리에 중점을 둔 1760억 매개변수 모델이다.</li><li><strong>특징</strong>: 무료로 사용 및 수정이 가능하며, 로컬 환경에서 실행할 수 있다.</li></ul></li></ol><p>각 모델은 크기, 학습 데이터, 아키텍처 등에 따라 성능과 특성이 다르다.<br>모델 선택 시 이러한 특성과 함께 라이선스, 계산 요구사항, 지원되는 언어 등을 고려해야 한다.</p><h3 id=llm-활용을-위한-주요-기술과-방법>LLM 활용을 위한 주요 기술과 방법<a hidden class=anchor aria-hidden=true href=#llm-활용을-위한-주요-기술과-방법>#</a></h3><p>LLM을 효과적으로 활용하기 위한 핵심 기술과 방법들을 알아보자.</p><h4 id=프롬프트-엔지니어링>프롬프트 엔지니어링<a hidden class=anchor aria-hidden=true href=#프롬프트-엔지니어링>#</a></h4><p>프롬프트 엔지니어링은 LLM에게 효과적인 지시를 제공하여 원하는 결과를 얻는 기술이다.<br>프롬프트는 모델에 제공하는 입력 텍스트로, 이를 통해 모델의 출력을 조정할 수 있다.</p><p><strong>기본 프롬프트 작성 기법</strong>:</p><ol><li><p><strong>명확하고 구체적인 지시</strong>: &ldquo;한국의 역사에 대해 설명해줘"보다 &ldquo;조선시대 세종대왕의 주요 업적 5가지를 연대순으로 설명해줘"가 더 좋은 결과를 얻을 수 있다.</p></li><li><p><strong>역할 부여</strong>: &ldquo;너는 고등학교 역사 선생님이야. 학생들이 쉽게 이해할 수 있도록 세종대왕의 업적을 설명해줘.&ldquo;와 같이 모델에 특정 역할을 부여하면 해당 맥락에 맞는 응답을 얻을 수 있다.</p></li><li><p><strong>단계별 지시</strong>: 복잡한 작업은 단계별로 나누어 지시하면 더 정확한 결과를 얻을 수 있다.</p></li><li><p><strong>예시 제공(Few-shot learning)</strong>: 몇 가지 예시를 제공하여 모델이 패턴을 이해하도록 돕는다.</p><pre class=mermaid>입력: 사과
출력: 사과는 붉은색 과일로, 비타민 C가 풍부하다.

입력: 바나나
출력: 바나나는 노란색 과일로, 칼륨이 풍부하다.

입력: 오렌지
출력:
</pre><p>이런 방식으로 제시하면 모델은 패턴을 파악하여 &ldquo;오렌지는 주황색 과일로, 비타민 C가 풍부하다.&ldquo;와 같은 형식의 응답을 할 가능성이 높다.</p></li></ol><h4 id=파인튜닝fine-tuning>파인튜닝(Fine-tuning)<a hidden class=anchor aria-hidden=true href=#파인튜닝fine-tuning>#</a></h4><p>파인튜닝은 사전학습된 LLM을 특정 작업이나 도메인에 맞게 추가로 학습시키는 과정이다.</p><p><strong>파인튜닝의 장점</strong>:</p><ul><li>특정 영역에 특화된 성능 향상</li><li>일관된 출력 형식 유지</li><li>기업 전용 지식이나 스타일 적용 가능</li></ul><p><strong>파인튜닝 과정</strong>:</p><ol><li>목표 작업에 맞는 데이터셋 준비 (입력-출력 쌍)</li><li>학습률(learning rate)과 같은 하이퍼파라미터 설정</li><li>사전학습된 모델을 기반으로 추가 학습 수행</li><li>성능 평가 및 모델 저장</li></ol><p>간단한 파인튜닝 코드 예시 (PyTorch와 Hugging Face Transformers 사용):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a class=lnlinks href=#hl-3-1> 1</a>
</span><span class=lnt id=hl-3-2><a class=lnlinks href=#hl-3-2> 2</a>
</span><span class=lnt id=hl-3-3><a class=lnlinks href=#hl-3-3> 3</a>
</span><span class=lnt id=hl-3-4><a class=lnlinks href=#hl-3-4> 4</a>
</span><span class=lnt id=hl-3-5><a class=lnlinks href=#hl-3-5> 5</a>
</span><span class=lnt id=hl-3-6><a class=lnlinks href=#hl-3-6> 6</a>
</span><span class=lnt id=hl-3-7><a class=lnlinks href=#hl-3-7> 7</a>
</span><span class=lnt id=hl-3-8><a class=lnlinks href=#hl-3-8> 8</a>
</span><span class=lnt id=hl-3-9><a class=lnlinks href=#hl-3-9> 9</a>
</span><span class=lnt id=hl-3-10><a class=lnlinks href=#hl-3-10>10</a>
</span><span class=lnt id=hl-3-11><a class=lnlinks href=#hl-3-11>11</a>
</span><span class=lnt id=hl-3-12><a class=lnlinks href=#hl-3-12>12</a>
</span><span class=lnt id=hl-3-13><a class=lnlinks href=#hl-3-13>13</a>
</span><span class=lnt id=hl-3-14><a class=lnlinks href=#hl-3-14>14</a>
</span><span class=lnt id=hl-3-15><a class=lnlinks href=#hl-3-15>15</a>
</span><span class=lnt id=hl-3-16><a class=lnlinks href=#hl-3-16>16</a>
</span><span class=lnt id=hl-3-17><a class=lnlinks href=#hl-3-17>17</a>
</span><span class=lnt id=hl-3-18><a class=lnlinks href=#hl-3-18>18</a>
</span><span class=lnt id=hl-3-19><a class=lnlinks href=#hl-3-19>19</a>
</span><span class=lnt id=hl-3-20><a class=lnlinks href=#hl-3-20>20</a>
</span><span class=lnt id=hl-3-21><a class=lnlinks href=#hl-3-21>21</a>
</span><span class=lnt id=hl-3-22><a class=lnlinks href=#hl-3-22>22</a>
</span><span class=lnt id=hl-3-23><a class=lnlinks href=#hl-3-23>23</a>
</span><span class=lnt id=hl-3-24><a class=lnlinks href=#hl-3-24>24</a>
</span><span class=lnt id=hl-3-25><a class=lnlinks href=#hl-3-25>25</a>
</span><span class=lnt id=hl-3-26><a class=lnlinks href=#hl-3-26>26</a>
</span><span class=lnt id=hl-3-27><a class=lnlinks href=#hl-3-27>27</a>
</span><span class=lnt id=hl-3-28><a class=lnlinks href=#hl-3-28>28</a>
</span><span class=lnt id=hl-3-29><a class=lnlinks href=#hl-3-29>29</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>GPT2LMHeadModel</span><span class=p>,</span> <span class=n>GPT2Tokenizer</span><span class=p>,</span> <span class=n>Trainer</span><span class=p>,</span> <span class=n>TrainingArguments</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 모델과 토크나이저 로드</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>GPT2LMHeadModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;gpt2&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>GPT2Tokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;gpt2&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 훈련 인자 설정</span>
</span></span><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./results&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>10_000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_total_limit</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 트레이너 초기화</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span>  <span class=c1># 사전 준비된 데이터셋</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 파인튜닝 시작</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 모델 저장</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=s2>&#34;./my_fine_tuned_model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=s2>&#34;./my_fine_tuned_model&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=ragretrieval-augmented-generation>RAG(Retrieval-Augmented Generation)<a hidden class=anchor aria-hidden=true href=#ragretrieval-augmented-generation>#</a></h4><p>RAG는 LLM의 지식 한계를 극복하기 위해 외부 지식 소스에서 관련 정보를 검색하여 모델의 생성 과정을 보강하는 기술이다.</p><p><strong>RAG의 작동 과정</strong>:</p><ol><li>사용자 쿼리 분석</li><li>관련 문서나 지식을 외부 데이터베이스에서 검색</li><li>검색된 정보를 프롬프트에 포함하여 LLM에 전달</li><li>LLM이 검색된 정보와 사전 지식을 결합하여 응답 생성</li></ol><p><strong>RAG의 장점</strong>:</p><ul><li>최신 정보 제공 가능</li><li>특정 도메인 지식 활용 가능</li><li>환각(hallucination) 감소</li><li>출처 인용 가능</li></ul><p>간단한 RAG 구현 예시:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1> 1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2> 2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3> 3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4> 4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5> 5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6> 6</a>
</span><span class=lnt id=hl-4-7><a class=lnlinks href=#hl-4-7> 7</a>
</span><span class=lnt id=hl-4-8><a class=lnlinks href=#hl-4-8> 8</a>
</span><span class=lnt id=hl-4-9><a class=lnlinks href=#hl-4-9> 9</a>
</span><span class=lnt id=hl-4-10><a class=lnlinks href=#hl-4-10>10</a>
</span><span class=lnt id=hl-4-11><a class=lnlinks href=#hl-4-11>11</a>
</span><span class=lnt id=hl-4-12><a class=lnlinks href=#hl-4-12>12</a>
</span><span class=lnt id=hl-4-13><a class=lnlinks href=#hl-4-13>13</a>
</span><span class=lnt id=hl-4-14><a class=lnlinks href=#hl-4-14>14</a>
</span><span class=lnt id=hl-4-15><a class=lnlinks href=#hl-4-15>15</a>
</span><span class=lnt id=hl-4-16><a class=lnlinks href=#hl-4-16>16</a>
</span><span class=lnt id=hl-4-17><a class=lnlinks href=#hl-4-17>17</a>
</span><span class=lnt id=hl-4-18><a class=lnlinks href=#hl-4-18>18</a>
</span><span class=lnt id=hl-4-19><a class=lnlinks href=#hl-4-19>19</a>
</span><span class=lnt id=hl-4-20><a class=lnlinks href=#hl-4-20>20</a>
</span><span class=lnt id=hl-4-21><a class=lnlinks href=#hl-4-21>21</a>
</span><span class=lnt id=hl-4-22><a class=lnlinks href=#hl-4-22>22</a>
</span><span class=lnt id=hl-4-23><a class=lnlinks href=#hl-4-23>23</a>
</span><span class=lnt id=hl-4-24><a class=lnlinks href=#hl-4-24>24</a>
</span><span class=lnt id=hl-4-25><a class=lnlinks href=#hl-4-25>25</a>
</span><span class=lnt id=hl-4-26><a class=lnlinks href=#hl-4-26>26</a>
</span><span class=lnt id=hl-4-27><a class=lnlinks href=#hl-4-27>27</a>
</span><span class=lnt id=hl-4-28><a class=lnlinks href=#hl-4-28>28</a>
</span><span class=lnt id=hl-4-29><a class=lnlinks href=#hl-4-29>29</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.document_loaders</span> <span class=kn>import</span> <span class=n>TextLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.text_splitter</span> <span class=kn>import</span> <span class=n>CharacterTextSplitter</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.embeddings</span> <span class=kn>import</span> <span class=n>OpenAIEmbeddings</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.vectorstores</span> <span class=kn>import</span> <span class=n>Chroma</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>RetrievalQA</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.llms</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 문서 로드 및 분할</span>
</span></span><span class=line><span class=cl><span class=n>loader</span> <span class=o>=</span> <span class=n>TextLoader</span><span class=p>(</span><span class=s2>&#34;./my_knowledge_base.txt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>documents</span> <span class=o>=</span> <span class=n>loader</span><span class=o>.</span><span class=n>load</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>text_splitter</span> <span class=o>=</span> <span class=n>CharacterTextSplitter</span><span class=p>(</span><span class=n>chunk_size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>texts</span> <span class=o>=</span> <span class=n>text_splitter</span><span class=o>.</span><span class=n>split_documents</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 임베딩 생성 및 벡터 저장소 구축</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span> <span class=o>=</span> <span class=n>OpenAIEmbeddings</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>db</span> <span class=o>=</span> <span class=n>Chroma</span><span class=o>.</span><span class=n>from_documents</span><span class=p>(</span><span class=n>texts</span><span class=p>,</span> <span class=n>embeddings</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># RAG 체인 생성</span>
</span></span><span class=line><span class=cl><span class=n>retriever</span> <span class=o>=</span> <span class=n>db</span><span class=o>.</span><span class=n>as_retriever</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>qa</span> <span class=o>=</span> <span class=n>RetrievalQA</span><span class=o>.</span><span class=n>from_chain_type</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span><span class=o>=</span><span class=n>OpenAI</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>chain_type</span><span class=o>=</span><span class=s2>&#34;stuff&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>retriever</span><span class=o>=</span><span class=n>retriever</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 질문에 대한 응답 생성</span>
</span></span><span class=line><span class=cl><span class=n>query</span> <span class=o>=</span> <span class=s2>&#34;인공지능의 윤리적 문제는 무엇인가요?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>answer</span> <span class=o>=</span> <span class=n>qa</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>answer</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=에이전트agent-시스템>에이전트(Agent) 시스템<a hidden class=anchor aria-hidden=true href=#에이전트agent-시스템>#</a></h4><p>LLM 에이전트는 모델이 추론 과정을 통해 문제를 해결하고, 필요에 따라 외부 도구를 사용할 수 있게 하는 프레임워크.</p><p><strong>에이전트의 주요 구성 요소</strong>:</p><ol><li><strong>LLM</strong>: 추론과 결정을 담당하는 핵심 모델</li><li><strong>도구(Tools)</strong>: API, 검색 엔진, 계산기 등 에이전트가 사용할 수 있는 외부 기능</li><li><strong>메모리(Memory)</strong>: 대화 기록과 중요 정보를 저장</li><li><strong>계획(Planning)</strong>: 복잡한 작업을 단계별로 분해하는 능력</li></ol><p><strong>에이전트의 작동 과정</strong>:</p><ol><li>사용자 입력 분석</li><li>작업 수행을 위한 계획 수립</li><li>필요한 도구 선택 및 사용</li><li>도구 결과 해석 및 다음 단계 결정</li><li>최종 결과 생성 및 제공</li></ol><p>LangChain을 사용한 간단한 에이전트 구현 예시:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-5-1><a class=lnlinks href=#hl-5-1> 1</a>
</span><span class=lnt id=hl-5-2><a class=lnlinks href=#hl-5-2> 2</a>
</span><span class=lnt id=hl-5-3><a class=lnlinks href=#hl-5-3> 3</a>
</span><span class=lnt id=hl-5-4><a class=lnlinks href=#hl-5-4> 4</a>
</span><span class=lnt id=hl-5-5><a class=lnlinks href=#hl-5-5> 5</a>
</span><span class=lnt id=hl-5-6><a class=lnlinks href=#hl-5-6> 6</a>
</span><span class=lnt id=hl-5-7><a class=lnlinks href=#hl-5-7> 7</a>
</span><span class=lnt id=hl-5-8><a class=lnlinks href=#hl-5-8> 8</a>
</span><span class=lnt id=hl-5-9><a class=lnlinks href=#hl-5-9> 9</a>
</span><span class=lnt id=hl-5-10><a class=lnlinks href=#hl-5-10>10</a>
</span><span class=lnt id=hl-5-11><a class=lnlinks href=#hl-5-11>11</a>
</span><span class=lnt id=hl-5-12><a class=lnlinks href=#hl-5-12>12</a>
</span><span class=lnt id=hl-5-13><a class=lnlinks href=#hl-5-13>13</a>
</span><span class=lnt id=hl-5-14><a class=lnlinks href=#hl-5-14>14</a>
</span><span class=lnt id=hl-5-15><a class=lnlinks href=#hl-5-15>15</a>
</span><span class=lnt id=hl-5-16><a class=lnlinks href=#hl-5-16>16</a>
</span><span class=lnt id=hl-5-17><a class=lnlinks href=#hl-5-17>17</a>
</span><span class=lnt id=hl-5-18><a class=lnlinks href=#hl-5-18>18</a>
</span><span class=lnt id=hl-5-19><a class=lnlinks href=#hl-5-19>19</a>
</span><span class=lnt id=hl-5-20><a class=lnlinks href=#hl-5-20>20</a>
</span><span class=lnt id=hl-5-21><a class=lnlinks href=#hl-5-21>21</a>
</span><span class=lnt id=hl-5-22><a class=lnlinks href=#hl-5-22>22</a>
</span><span class=lnt id=hl-5-23><a class=lnlinks href=#hl-5-23>23</a>
</span><span class=lnt id=hl-5-24><a class=lnlinks href=#hl-5-24>24</a>
</span><span class=lnt id=hl-5-25><a class=lnlinks href=#hl-5-25>25</a>
</span><span class=lnt id=hl-5-26><a class=lnlinks href=#hl-5-26>26</a>
</span><span class=lnt id=hl-5-27><a class=lnlinks href=#hl-5-27>27</a>
</span><span class=lnt id=hl-5-28><a class=lnlinks href=#hl-5-28>28</a>
</span><span class=lnt id=hl-5-29><a class=lnlinks href=#hl-5-29>29</a>
</span><span class=lnt id=hl-5-30><a class=lnlinks href=#hl-5-30>30</a>
</span><span class=lnt id=hl-5-31><a class=lnlinks href=#hl-5-31>31</a>
</span><span class=lnt id=hl-5-32><a class=lnlinks href=#hl-5-32>32</a>
</span><span class=lnt id=hl-5-33><a class=lnlinks href=#hl-5-33>33</a>
</span><span class=lnt id=hl-5-34><a class=lnlinks href=#hl-5-34>34</a>
</span><span class=lnt id=hl-5-35><a class=lnlinks href=#hl-5-35>35</a>
</span><span class=lnt id=hl-5-36><a class=lnlinks href=#hl-5-36>36</a>
</span><span class=lnt id=hl-5-37><a class=lnlinks href=#hl-5-37>37</a>
</span><span class=lnt id=hl-5-38><a class=lnlinks href=#hl-5-38>38</a>
</span><span class=lnt id=hl-5-39><a class=lnlinks href=#hl-5-39>39</a>
</span><span class=lnt id=hl-5-40><a class=lnlinks href=#hl-5-40>40</a>
</span><span class=lnt id=hl-5-41><a class=lnlinks href=#hl-5-41>41</a>
</span><span class=lnt id=hl-5-42><a class=lnlinks href=#hl-5-42>42</a>
</span><span class=lnt id=hl-5-43><a class=lnlinks href=#hl-5-43>43</a>
</span><span class=lnt id=hl-5-44><a class=lnlinks href=#hl-5-44>44</a>
</span><span class=lnt id=hl-5-45><a class=lnlinks href=#hl-5-45>45</a>
</span><span class=lnt id=hl-5-46><a class=lnlinks href=#hl-5-46>46</a>
</span><span class=lnt id=hl-5-47><a class=lnlinks href=#hl-5-47>47</a>
</span><span class=lnt id=hl-5-48><a class=lnlinks href=#hl-5-48>48</a>
</span><span class=lnt id=hl-5-49><a class=lnlinks href=#hl-5-49>49</a>
</span><span class=lnt id=hl-5-50><a class=lnlinks href=#hl-5-50>50</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>Tool</span><span class=p>,</span> <span class=n>AgentExecutor</span><span class=p>,</span> <span class=n>LLMSingleActionAgent</span><span class=p>,</span> <span class=n>AgentOutputParser</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.prompts</span> <span class=kn>import</span> <span class=n>StringPromptTemplate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain</span> <span class=kn>import</span> <span class=n>OpenAI</span><span class=p>,</span> <span class=n>SerpAPIWrapper</span><span class=p>,</span> <span class=n>LLMChain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Union</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.schema</span> <span class=kn>import</span> <span class=n>AgentAction</span><span class=p>,</span> <span class=n>AgentFinish</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 검색 도구 설정</span>
</span></span><span class=line><span class=cl><span class=n>search</span> <span class=o>=</span> <span class=n>SerpAPIWrapper</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>tools</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=n>Tool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;Search&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>func</span><span class=o>=</span><span class=n>search</span><span class=o>.</span><span class=n>run</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;인터넷에서 정보를 검색할 때 유용합니다&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 프롬프트 템플릿 설정</span>
</span></span><span class=line><span class=cl><span class=n>template</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;어떤 질문에 답해야 합니다. 필요하다면 다음 도구를 사용할 수 있습니다:
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2></span><span class=si>{tools}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>질문: </span><span class=si>{input}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>다음 형식으로 생각을 정리하세요:
</span></span></span><span class=line><span class=cl><span class=s2>Thought: 내가 어떻게 이 문제를 해결할지 생각해보자
</span></span></span><span class=line><span class=cl><span class=s2>Action: 사용할 도구 이름
</span></span></span><span class=line><span class=cl><span class=s2>Action Input: 도구에 전달할 입력
</span></span></span><span class=line><span class=cl><span class=s2>Observation: 도구로부터 받은 결과
</span></span></span><span class=line><span class=cl><span class=s2>… (필요에 따라 Thought/Action/Action Input/Observation 반복)
</span></span></span><span class=line><span class=cl><span class=s2>Thought: 이제 질문에 답할 수 있겠다
</span></span></span><span class=line><span class=cl><span class=s2>Final Answer: 질문에 대한 최종 답변
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>시작해보세요!
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>Thought: </span><span class=si>{agent_scratchpad}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 에이전트 설정 및 실행</span>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=n>StringPromptTemplate</span><span class=o>.</span><span class=n>from_template</span><span class=p>(</span><span class=n>template</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>llm_chain</span> <span class=o>=</span> <span class=n>LLMChain</span><span class=p>(</span><span class=n>llm</span><span class=o>=</span><span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>),</span> <span class=n>prompt</span><span class=o>=</span><span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>agent</span> <span class=o>=</span> <span class=n>LLMSingleActionAgent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm_chain</span><span class=o>=</span><span class=n>llm_chain</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>output_parser</span><span class=o>=</span><span class=n>CustomOutputParser</span><span class=p>(),</span>  <span class=c1># 별도 정의 필요</span>
</span></span><span class=line><span class=cl>    <span class=n>stop</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Observation:&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>allowed_tools</span><span class=o>=</span><span class=p>[</span><span class=n>tool</span><span class=o>.</span><span class=n>name</span> <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=n>tools</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>agent_executor</span> <span class=o>=</span> <span class=n>AgentExecutor</span><span class=o>.</span><span class=n>from_agent_and_tools</span><span class=p>(</span><span class=n>agent</span><span class=o>=</span><span class=n>agent</span><span class=p>,</span> <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 에이전트 실행</span>
</span></span><span class=line><span class=cl><span class=n>agent_executor</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=s2>&#34;2023년 노벨 물리학상 수상자는 누구인가요?&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=llm-애플리케이션-개발-실습>LLM 애플리케이션 개발 실습<a hidden class=anchor aria-hidden=true href=#llm-애플리케이션-개발-실습>#</a></h3><p>이제 실제로 LLM을 활용한 간단한 애플리케이션을 개발해보겠습니다. 여기서는 초보 개발자도 쉽게 구현할 수 있는 예제를 중심으로 설명하겠습니다.</p><h4 id=기본-개발-환경-설정>기본 개발 환경 설정<a hidden class=anchor aria-hidden=true href=#기본-개발-환경-설정>#</a></h4><p>LLM 애플리케이션 개발을 위한 기본 환경을 설정해보겠습니다:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-6-1><a class=lnlinks href=#hl-6-1>1</a>
</span><span class=lnt id=hl-6-2><a class=lnlinks href=#hl-6-2>2</a>
</span><span class=lnt id=hl-6-3><a class=lnlinks href=#hl-6-3>3</a>
</span><span class=lnt id=hl-6-4><a class=lnlinks href=#hl-6-4>4</a>
</span><span class=lnt id=hl-6-5><a class=lnlinks href=#hl-6-5>5</a>
</span><span class=lnt id=hl-6-6><a class=lnlinks href=#hl-6-6>6</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 가상 환경 생성</span>
</span></span><span class=line><span class=cl>python -m venv llm-env
</span></span><span class=line><span class=cl><span class=nb>source</span> llm-env/bin/activate  <span class=c1># Windows: llm-env\Scripts\activate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 필요한 패키지 설치</span>
</span></span><span class=line><span class=cl>pip install openai langchain python-dotenv streamlit
</span></span></code></pre></td></tr></table></div></div><h4 id=openai-api를-활용한-간단한-채팅봇>OpenAI API를 활용한 간단한 채팅봇<a hidden class=anchor aria-hidden=true href=#openai-api를-활용한-간단한-채팅봇>#</a></h4><p>OpenAI API를 사용하여 간단한 채팅봇을 만들어보겠습니다:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-7-1><a class=lnlinks href=#hl-7-1> 1</a>
</span><span class=lnt id=hl-7-2><a class=lnlinks href=#hl-7-2> 2</a>
</span><span class=lnt id=hl-7-3><a class=lnlinks href=#hl-7-3> 3</a>
</span><span class=lnt id=hl-7-4><a class=lnlinks href=#hl-7-4> 4</a>
</span><span class=lnt id=hl-7-5><a class=lnlinks href=#hl-7-5> 5</a>
</span><span class=lnt id=hl-7-6><a class=lnlinks href=#hl-7-6> 6</a>
</span><span class=lnt id=hl-7-7><a class=lnlinks href=#hl-7-7> 7</a>
</span><span class=lnt id=hl-7-8><a class=lnlinks href=#hl-7-8> 8</a>
</span><span class=lnt id=hl-7-9><a class=lnlinks href=#hl-7-9> 9</a>
</span><span class=lnt id=hl-7-10><a class=lnlinks href=#hl-7-10>10</a>
</span><span class=lnt id=hl-7-11><a class=lnlinks href=#hl-7-11>11</a>
</span><span class=lnt id=hl-7-12><a class=lnlinks href=#hl-7-12>12</a>
</span><span class=lnt id=hl-7-13><a class=lnlinks href=#hl-7-13>13</a>
</span><span class=lnt id=hl-7-14><a class=lnlinks href=#hl-7-14>14</a>
</span><span class=lnt id=hl-7-15><a class=lnlinks href=#hl-7-15>15</a>
</span><span class=lnt id=hl-7-16><a class=lnlinks href=#hl-7-16>16</a>
</span><span class=lnt id=hl-7-17><a class=lnlinks href=#hl-7-17>17</a>
</span><span class=lnt id=hl-7-18><a class=lnlinks href=#hl-7-18>18</a>
</span><span class=lnt id=hl-7-19><a class=lnlinks href=#hl-7-19>19</a>
</span><span class=lnt id=hl-7-20><a class=lnlinks href=#hl-7-20>20</a>
</span><span class=lnt id=hl-7-21><a class=lnlinks href=#hl-7-21>21</a>
</span><span class=lnt id=hl-7-22><a class=lnlinks href=#hl-7-22>22</a>
</span><span class=lnt id=hl-7-23><a class=lnlinks href=#hl-7-23>23</a>
</span><span class=lnt id=hl-7-24><a class=lnlinks href=#hl-7-24>24</a>
</span><span class=lnt id=hl-7-25><a class=lnlinks href=#hl-7-25>25</a>
</span><span class=lnt id=hl-7-26><a class=lnlinks href=#hl-7-26>26</a>
</span><span class=lnt id=hl-7-27><a class=lnlinks href=#hl-7-27>27</a>
</span><span class=lnt id=hl-7-28><a class=lnlinks href=#hl-7-28>28</a>
</span><span class=lnt id=hl-7-29><a class=lnlinks href=#hl-7-29>29</a>
</span><span class=lnt id=hl-7-30><a class=lnlinks href=#hl-7-30>30</a>
</span><span class=lnt id=hl-7-31><a class=lnlinks href=#hl-7-31>31</a>
</span><span class=lnt id=hl-7-32><a class=lnlinks href=#hl-7-32>32</a>
</span><span class=lnt id=hl-7-33><a class=lnlinks href=#hl-7-33>33</a>
</span><span class=lnt id=hl-7-34><a class=lnlinks href=#hl-7-34>34</a>
</span><span class=lnt id=hl-7-35><a class=lnlinks href=#hl-7-35>35</a>
</span><span class=lnt id=hl-7-36><a class=lnlinks href=#hl-7-36>36</a>
</span><span class=lnt id=hl-7-37><a class=lnlinks href=#hl-7-37>37</a>
</span><span class=lnt id=hl-7-38><a class=lnlinks href=#hl-7-38>38</a>
</span><span class=lnt id=hl-7-39><a class=lnlinks href=#hl-7-39>39</a>
</span><span class=lnt id=hl-7-40><a class=lnlinks href=#hl-7-40>40</a>
</span><span class=lnt id=hl-7-41><a class=lnlinks href=#hl-7-41>41</a>
</span><span class=lnt id=hl-7-42><a class=lnlinks href=#hl-7-42>42</a>
</span><span class=lnt id=hl-7-43><a class=lnlinks href=#hl-7-43>43</a>
</span><span class=lnt id=hl-7-44><a class=lnlinks href=#hl-7-44>44</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>openai</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 환경 변수 로드</span>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>openai</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;OPENAI_API_KEY&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>chat_with_gpt</span><span class=p>(</span><span class=n>messages</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    OpenAI API를 사용하여 채팅 응답을 생성합니다.
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        messages: 채팅 메시지 기록
</span></span></span><span class=line><span class=cl><span class=s2>        
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        모델의 응답 텍스트
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>ChatCompletion</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-3.5-turbo&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 간단한 채팅 루프</span>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;당신은 유용한 AI 비서입니다.&#34;</span><span class=p>}]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;AI 비서와 대화를 시작합니다. 종료하려면 &#39;quit&#39;를 입력하세요.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>user_input</span> <span class=o>=</span> <span class=nb>input</span><span class=p>(</span><span class=s2>&#34;You: &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>user_input</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=o>==</span> <span class=s1>&#39;quit&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 사용자 메시지 추가</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>user_input</span><span class=p>})</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># AI 응답 생성</span>
</span></span><span class=line><span class=cl>    <span class=n>ai_response</span> <span class=o>=</span> <span class=n>chat_with_gpt</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;AI: </span><span class=si>{</span><span class=n>ai_response</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># AI 응답 메시지 추가</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>ai_response</span><span class=p>})</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=streamlit을-활용한-웹-인터페이스-구현>Streamlit을 활용한 웹 인터페이스 구현<a hidden class=anchor aria-hidden=true href=#streamlit을-활용한-웹-인터페이스-구현>#</a></h4><p>위 코드를 웹 애플리케이션으로 확장해보겠습니다:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-8-1><a class=lnlinks href=#hl-8-1> 1</a>
</span><span class=lnt id=hl-8-2><a class=lnlinks href=#hl-8-2> 2</a>
</span><span class=lnt id=hl-8-3><a class=lnlinks href=#hl-8-3> 3</a>
</span><span class=lnt id=hl-8-4><a class=lnlinks href=#hl-8-4> 4</a>
</span><span class=lnt id=hl-8-5><a class=lnlinks href=#hl-8-5> 5</a>
</span><span class=lnt id=hl-8-6><a class=lnlinks href=#hl-8-6> 6</a>
</span><span class=lnt id=hl-8-7><a class=lnlinks href=#hl-8-7> 7</a>
</span><span class=lnt id=hl-8-8><a class=lnlinks href=#hl-8-8> 8</a>
</span><span class=lnt id=hl-8-9><a class=lnlinks href=#hl-8-9> 9</a>
</span><span class=lnt id=hl-8-10><a class=lnlinks href=#hl-8-10>10</a>
</span><span class=lnt id=hl-8-11><a class=lnlinks href=#hl-8-11>11</a>
</span><span class=lnt id=hl-8-12><a class=lnlinks href=#hl-8-12>12</a>
</span><span class=lnt id=hl-8-13><a class=lnlinks href=#hl-8-13>13</a>
</span><span class=lnt id=hl-8-14><a class=lnlinks href=#hl-8-14>14</a>
</span><span class=lnt id=hl-8-15><a class=lnlinks href=#hl-8-15>15</a>
</span><span class=lnt id=hl-8-16><a class=lnlinks href=#hl-8-16>16</a>
</span><span class=lnt id=hl-8-17><a class=lnlinks href=#hl-8-17>17</a>
</span><span class=lnt id=hl-8-18><a class=lnlinks href=#hl-8-18>18</a>
</span><span class=lnt id=hl-8-19><a class=lnlinks href=#hl-8-19>19</a>
</span><span class=lnt id=hl-8-20><a class=lnlinks href=#hl-8-20>20</a>
</span><span class=lnt id=hl-8-21><a class=lnlinks href=#hl-8-21>21</a>
</span><span class=lnt id=hl-8-22><a class=lnlinks href=#hl-8-22>22</a>
</span><span class=lnt id=hl-8-23><a class=lnlinks href=#hl-8-23>23</a>
</span><span class=lnt id=hl-8-24><a class=lnlinks href=#hl-8-24>24</a>
</span><span class=lnt id=hl-8-25><a class=lnlinks href=#hl-8-25>25</a>
</span><span class=lnt id=hl-8-26><a class=lnlinks href=#hl-8-26>26</a>
</span><span class=lnt id=hl-8-27><a class=lnlinks href=#hl-8-27>27</a>
</span><span class=lnt id=hl-8-28><a class=lnlinks href=#hl-8-28>28</a>
</span><span class=lnt id=hl-8-29><a class=lnlinks href=#hl-8-29>29</a>
</span><span class=lnt id=hl-8-30><a class=lnlinks href=#hl-8-30>30</a>
</span><span class=lnt id=hl-8-31><a class=lnlinks href=#hl-8-31>31</a>
</span><span class=lnt id=hl-8-32><a class=lnlinks href=#hl-8-32>32</a>
</span><span class=lnt id=hl-8-33><a class=lnlinks href=#hl-8-33>33</a>
</span><span class=lnt id=hl-8-34><a class=lnlinks href=#hl-8-34>34</a>
</span><span class=lnt id=hl-8-35><a class=lnlinks href=#hl-8-35>35</a>
</span><span class=lnt id=hl-8-36><a class=lnlinks href=#hl-8-36>36</a>
</span><span class=lnt id=hl-8-37><a class=lnlinks href=#hl-8-37>37</a>
</span><span class=lnt id=hl-8-38><a class=lnlinks href=#hl-8-38>38</a>
</span><span class=lnt id=hl-8-39><a class=lnlinks href=#hl-8-39>39</a>
</span><span class=lnt id=hl-8-40><a class=lnlinks href=#hl-8-40>40</a>
</span><span class=lnt id=hl-8-41><a class=lnlinks href=#hl-8-41>41</a>
</span><span class=lnt id=hl-8-42><a class=lnlinks href=#hl-8-42>42</a>
</span><span class=lnt id=hl-8-43><a class=lnlinks href=#hl-8-43>43</a>
</span><span class=lnt id=hl-8-44><a class=lnlinks href=#hl-8-44>44</a>
</span><span class=lnt id=hl-8-45><a class=lnlinks href=#hl-8-45>45</a>
</span><span class=lnt id=hl-8-46><a class=lnlinks href=#hl-8-46>46</a>
</span><span class=lnt id=hl-8-47><a class=lnlinks href=#hl-8-47>47</a>
</span><span class=lnt id=hl-8-48><a class=lnlinks href=#hl-8-48>48</a>
</span><span class=lnt id=hl-8-49><a class=lnlinks href=#hl-8-49>49</a>
</span><span class=lnt id=hl-8-50><a class=lnlinks href=#hl-8-50>50</a>
</span><span class=lnt id=hl-8-51><a class=lnlinks href=#hl-8-51>51</a>
</span><span class=lnt id=hl-8-52><a class=lnlinks href=#hl-8-52>52</a>
</span><span class=lnt id=hl-8-53><a class=lnlinks href=#hl-8-53>53</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># app.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>streamlit</span> <span class=k>as</span> <span class=nn>st</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>openai</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 환경 변수 로드</span>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>openai</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;OPENAI_API_KEY&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 앱 제목</span>
</span></span><span class=line><span class=cl><span class=n>st</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;AI 챗봇 도우미&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 세션 상태 초기화</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=s2>&#34;messages&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>messages</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;당신은 유용한 AI 비서입니다.&#34;</span><span class=p>}]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 이전 메시지 표시</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>message</span> <span class=ow>in</span> <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>messages</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>message</span><span class=p>[</span><span class=s2>&#34;role&#34;</span><span class=p>]</span> <span class=o>!=</span> <span class=s2>&#34;system&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>role</span> <span class=o>=</span> <span class=s2>&#34;사용자&#34;</span> <span class=k>if</span> <span class=n>message</span><span class=p>[</span><span class=s2>&#34;role&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=s2>&#34;user&#34;</span> <span class=k>else</span> <span class=s2>&#34;AI&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>st</span><span class=o>.</span><span class=n>chat_message</span><span class=p>(</span><span class=n>message</span><span class=p>[</span><span class=s2>&#34;role&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>            <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 사용자 입력 처리</span>
</span></span><span class=line><span class=cl><span class=n>user_input</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>chat_input</span><span class=p>(</span><span class=s2>&#34;메시지를 입력하세요&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>user_input</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 사용자 메시지 표시</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>st</span><span class=o>.</span><span class=n>chat_message</span><span class=p>(</span><span class=s2>&#34;user&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>user_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 사용자 메시지 저장</span>
</span></span><span class=line><span class=cl>    <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>user_input</span><span class=p>})</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># AI 응답 생성</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>st</span><span class=o>.</span><span class=n>chat_message</span><span class=p>(</span><span class=s2>&#34;assistant&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>message_placeholder</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>empty</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>ChatCompletion</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-3.5-turbo&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>stream</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>full_response</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=n>response</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>content</span> <span class=o>=</span> <span class=n>chunk</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>delta</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;content&#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>full_response</span> <span class=o>+=</span> <span class=n>content</span>
</span></span><span class=line><span class=cl>            <span class=n>message_placeholder</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>full_response</span> <span class=o>+</span> <span class=s2>&#34;▌&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>message_placeholder</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>full_response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># AI 응답 저장</span>
</span></span><span class=line><span class=cl>    <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>full_response</span><span class=p>})</span>
</span></span></code></pre></td></tr></table></div></div><p>이 코드를 실행하려면 터미널에서 다음 명령어를 실행하세요:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-9-1><a class=lnlinks href=#hl-9-1>1</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>streamlit run app.py
</span></span></code></pre></td></tr></table></div></div><h4 id=문서-기반-질의응답-시스템-구현>문서 기반 질의응답 시스템 구현<a hidden class=anchor aria-hidden=true href=#문서-기반-질의응답-시스템-구현>#</a></h4><p>이번에는 RAG를 활용하여 특정 문서에 대한 질의응답 시스템을 만들어보겠습니다:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-10-1><a class=lnlinks href=#hl-10-1> 1</a>
</span><span class=lnt id=hl-10-2><a class=lnlinks href=#hl-10-2> 2</a>
</span><span class=lnt id=hl-10-3><a class=lnlinks href=#hl-10-3> 3</a>
</span><span class=lnt id=hl-10-4><a class=lnlinks href=#hl-10-4> 4</a>
</span><span class=lnt id=hl-10-5><a class=lnlinks href=#hl-10-5> 5</a>
</span><span class=lnt id=hl-10-6><a class=lnlinks href=#hl-10-6> 6</a>
</span><span class=lnt id=hl-10-7><a class=lnlinks href=#hl-10-7> 7</a>
</span><span class=lnt id=hl-10-8><a class=lnlinks href=#hl-10-8> 8</a>
</span><span class=lnt id=hl-10-9><a class=lnlinks href=#hl-10-9> 9</a>
</span><span class=lnt id=hl-10-10><a class=lnlinks href=#hl-10-10>10</a>
</span><span class=lnt id=hl-10-11><a class=lnlinks href=#hl-10-11>11</a>
</span><span class=lnt id=hl-10-12><a class=lnlinks href=#hl-10-12>12</a>
</span><span class=lnt id=hl-10-13><a class=lnlinks href=#hl-10-13>13</a>
</span><span class=lnt id=hl-10-14><a class=lnlinks href=#hl-10-14>14</a>
</span><span class=lnt id=hl-10-15><a class=lnlinks href=#hl-10-15>15</a>
</span><span class=lnt id=hl-10-16><a class=lnlinks href=#hl-10-16>16</a>
</span><span class=lnt id=hl-10-17><a class=lnlinks href=#hl-10-17>17</a>
</span><span class=lnt id=hl-10-18><a class=lnlinks href=#hl-10-18>18</a>
</span><span class=lnt id=hl-10-19><a class=lnlinks href=#hl-10-19>19</a>
</span><span class=lnt id=hl-10-20><a class=lnlinks href=#hl-10-20>20</a>
</span><span class=lnt id=hl-10-21><a class=lnlinks href=#hl-10-21>21</a>
</span><span class=lnt id=hl-10-22><a class=lnlinks href=#hl-10-22>22</a>
</span><span class=lnt id=hl-10-23><a class=lnlinks href=#hl-10-23>23</a>
</span><span class=lnt id=hl-10-24><a class=lnlinks href=#hl-10-24>24</a>
</span><span class=lnt id=hl-10-25><a class=lnlinks href=#hl-10-25>25</a>
</span><span class=lnt id=hl-10-26><a class=lnlinks href=#hl-10-26>26</a>
</span><span class=lnt id=hl-10-27><a class=lnlinks href=#hl-10-27>27</a>
</span><span class=lnt id=hl-10-28><a class=lnlinks href=#hl-10-28>28</a>
</span><span class=lnt id=hl-10-29><a class=lnlinks href=#hl-10-29>29</a>
</span><span class=lnt id=hl-10-30><a class=lnlinks href=#hl-10-30>30</a>
</span><span class=lnt id=hl-10-31><a class=lnlinks href=#hl-10-31>31</a>
</span><span class=lnt id=hl-10-32><a class=lnlinks href=#hl-10-32>32</a>
</span><span class=lnt id=hl-10-33><a class=lnlinks href=#hl-10-33>33</a>
</span><span class=lnt id=hl-10-34><a class=lnlinks href=#hl-10-34>34</a>
</span><span class=lnt id=hl-10-35><a class=lnlinks href=#hl-10-35>35</a>
</span><span class=lnt id=hl-10-36><a class=lnlinks href=#hl-10-36>36</a>
</span><span class=lnt id=hl-10-37><a class=lnlinks href=#hl-10-37>37</a>
</span><span class=lnt id=hl-10-38><a class=lnlinks href=#hl-10-38>38</a>
</span><span class=lnt id=hl-10-39><a class=lnlinks href=#hl-10-39>39</a>
</span><span class=lnt id=hl-10-40><a class=lnlinks href=#hl-10-40>40</a>
</span><span class=lnt id=hl-10-41><a class=lnlinks href=#hl-10-41>41</a>
</span><span class=lnt id=hl-10-42><a class=lnlinks href=#hl-10-42>42</a>
</span><span class=lnt id=hl-10-43><a class=lnlinks href=#hl-10-43>43</a>
</span><span class=lnt id=hl-10-44><a class=lnlinks href=#hl-10-44>44</a>
</span><span class=lnt id=hl-10-45><a class=lnlinks href=#hl-10-45>45</a>
</span><span class=lnt id=hl-10-46><a class=lnlinks href=#hl-10-46>46</a>
</span><span class=lnt id=hl-10-47><a class=lnlinks href=#hl-10-47>47</a>
</span><span class=lnt id=hl-10-48><a class=lnlinks href=#hl-10-48>48</a>
</span><span class=lnt id=hl-10-49><a class=lnlinks href=#hl-10-49>49</a>
</span><span class=lnt id=hl-10-50><a class=lnlinks href=#hl-10-50>50</a>
</span><span class=lnt id=hl-10-51><a class=lnlinks href=#hl-10-51>51</a>
</span><span class=lnt id=hl-10-52><a class=lnlinks href=#hl-10-52>52</a>
</span><span class=lnt id=hl-10-53><a class=lnlinks href=#hl-10-53>53</a>
</span><span class=lnt id=hl-10-54><a class=lnlinks href=#hl-10-54>54</a>
</span><span class=lnt id=hl-10-55><a class=lnlinks href=#hl-10-55>55</a>
</span><span class=lnt id=hl-10-56><a class=lnlinks href=#hl-10-56>56</a>
</span><span class=lnt id=hl-10-57><a class=lnlinks href=#hl-10-57>57</a>
</span><span class=lnt id=hl-10-58><a class=lnlinks href=#hl-10-58>58</a>
</span><span class=lnt id=hl-10-59><a class=lnlinks href=#hl-10-59>59</a>
</span><span class=lnt id=hl-10-60><a class=lnlinks href=#hl-10-60>60</a>
</span><span class=lnt id=hl-10-61><a class=lnlinks href=#hl-10-61>61</a>
</span><span class=lnt id=hl-10-62><a class=lnlinks href=#hl-10-62>62</a>
</span><span class=lnt id=hl-10-63><a class=lnlinks href=#hl-10-63>63</a>
</span><span class=lnt id=hl-10-64><a class=lnlinks href=#hl-10-64>64</a>
</span><span class=lnt id=hl-10-65><a class=lnlinks href=#hl-10-65>65</a>
</span><span class=lnt id=hl-10-66><a class=lnlinks href=#hl-10-66>66</a>
</span><span class=lnt id=hl-10-67><a class=lnlinks href=#hl-10-67>67</a>
</span><span class=lnt id=hl-10-68><a class=lnlinks href=#hl-10-68>68</a>
</span><span class=lnt id=hl-10-69><a class=lnlinks href=#hl-10-69>69</a>
</span><span class=lnt id=hl-10-70><a class=lnlinks href=#hl-10-70>70</a>
</span><span class=lnt id=hl-10-71><a class=lnlinks href=#hl-10-71>71</a>
</span><span class=lnt id=hl-10-72><a class=lnlinks href=#hl-10-72>72</a>
</span><span class=lnt id=hl-10-73><a class=lnlinks href=#hl-10-73>73</a>
</span><span class=lnt id=hl-10-74><a class=lnlinks href=#hl-10-74>74</a>
</span><span class=lnt id=hl-10-75><a class=lnlinks href=#hl-10-75>75</a>
</span><span class=lnt id=hl-10-76><a class=lnlinks href=#hl-10-76>76</a>
</span><span class=lnt id=hl-10-77><a class=lnlinks href=#hl-10-77>77</a>
</span><span class=lnt id=hl-10-78><a class=lnlinks href=#hl-10-78>78</a>
</span><span class=lnt id=hl-10-79><a class=lnlinks href=#hl-10-79>79</a>
</span><span class=lnt id=hl-10-80><a class=lnlinks href=#hl-10-80>80</a>
</span><span class=lnt id=hl-10-81><a class=lnlinks href=#hl-10-81>81</a>
</span><span class=lnt id=hl-10-82><a class=lnlinks href=#hl-10-82>82</a>
</span><span class=lnt id=hl-10-83><a class=lnlinks href=#hl-10-83>83</a>
</span><span class=lnt id=hl-10-84><a class=lnlinks href=#hl-10-84>84</a>
</span><span class=lnt id=hl-10-85><a class=lnlinks href=#hl-10-85>85</a>
</span><span class=lnt id=hl-10-86><a class=lnlinks href=#hl-10-86>86</a>
</span><span class=lnt id=hl-10-87><a class=lnlinks href=#hl-10-87>87</a>
</span><span class=lnt id=hl-10-88><a class=lnlinks href=#hl-10-88>88</a>
</span><span class=lnt id=hl-10-89><a class=lnlinks href=#hl-10-89>89</a>
</span><span class=lnt id=hl-10-90><a class=lnlinks href=#hl-10-90>90</a>
</span><span class=lnt id=hl-10-91><a class=lnlinks href=#hl-10-91>91</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># doc_qa.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>streamlit</span> <span class=k>as</span> <span class=nn>st</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.document_loaders</span> <span class=kn>import</span> <span class=n>PyPDFLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.text_splitter</span> <span class=kn>import</span> <span class=n>RecursiveCharacterTextSplitter</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.embeddings</span> <span class=kn>import</span> <span class=n>OpenAIEmbeddings</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.vectorstores</span> <span class=kn>import</span> <span class=n>FAISS</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chat_models</span> <span class=kn>import</span> <span class=n>ChatOpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>ConversationalRetrievalChain</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tempfile</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dotenv</span> <span class=kn>import</span> <span class=n>load_dotenv</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 환경 변수 로드</span>
</span></span><span class=line><span class=cl><span class=n>load_dotenv</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 앱 제목</span>
</span></span><span class=line><span class=cl><span class=n>st</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;문서 기반 질의응답 시스템&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 파일 업로드</span>
</span></span><span class=line><span class=cl><span class=n>uploaded_file</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>file_uploader</span><span class=p>(</span><span class=s2>&#34;PDF 파일을 업로드하세요&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=s2>&#34;pdf&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>uploaded_file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 업로드된 파일 처리</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>tempfile</span><span class=o>.</span><span class=n>NamedTemporaryFile</span><span class=p>(</span><span class=n>delete</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>suffix</span><span class=o>=</span><span class=s1>&#39;.pdf&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>tmp_file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>tmp_file</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>uploaded_file</span><span class=o>.</span><span class=n>getvalue</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=n>tmp_path</span> <span class=o>=</span> <span class=n>tmp_file</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 문서 로드 및 분할</span>
</span></span><span class=line><span class=cl>    <span class=n>loader</span> <span class=o>=</span> <span class=n>PyPDFLoader</span><span class=p>(</span><span class=n>tmp_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span> <span class=o>=</span> <span class=n>loader</span><span class=o>.</span><span class=n>load</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>text_splitter</span> <span class=o>=</span> <span class=n>RecursiveCharacterTextSplitter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>200</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>chunks</span> <span class=o>=</span> <span class=n>text_splitter</span><span class=o>.</span><span class=n>split_documents</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 임베딩 및 벡터 DB 생성</span>
</span></span><span class=line><span class=cl>    <span class=n>embeddings</span> <span class=o>=</span> <span class=n>OpenAIEmbeddings</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>vectorstore</span> <span class=o>=</span> <span class=n>FAISS</span><span class=o>.</span><span class=n>from_documents</span><span class=p>(</span><span class=n>chunks</span><span class=p>,</span> <span class=n>embeddings</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 채팅 모델 초기화</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOpenAI</span><span class=p>(</span><span class=n>model_name</span><span class=o>=</span><span class=s2>&#34;gpt-3.5-turbo&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 대화 체인 생성</span>
</span></span><span class=line><span class=cl>    <span class=n>qa_chain</span> <span class=o>=</span> <span class=n>ConversationalRetrievalChain</span><span class=o>.</span><span class=n>from_llm</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>llm</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>vectorstore</span><span class=o>.</span><span class=n>as_retriever</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>return_source_documents</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 세션 상태 초기화</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;chat_history&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>chat_history</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 채팅 인터페이스</span>
</span></span><span class=line><span class=cl>    <span class=n>st</span><span class=o>.</span><span class=n>subheader</span><span class=p>(</span><span class=s2>&#34;문서에 질문하기&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>query</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>text_input</span><span class=p>(</span><span class=s2>&#34;질문을 입력하세요&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>query</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 답변 생성</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=n>qa_chain</span><span class=p>({</span><span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=n>query</span><span class=p>,</span> <span class=s2>&#34;chat_history&#34;</span><span class=p>:</span> <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>chat_history</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=n>answer</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;answer&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>source_docs</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;source_documents&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 채팅 기록 업데이트</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>chat_history</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>query</span><span class=p>,</span> <span class=n>answer</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 결과 표시</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&#34;### 답변:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>answer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 참조 문서 표시</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>st</span><span class=o>.</span><span class=n>expander</span><span class=p>(</span><span class=s2>&#34;참조 문서&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>doc</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>source_docs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;**출처 </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>**&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>doc</span><span class=o>.</span><span class=n>page_content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&#34;---&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 채팅 기록 표시</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>chat_history</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>subheader</span><span class=p>(</span><span class=s2>&#34;채팅 기록&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>user_q</span><span class=p>,</span> <span class=n>ai_a</span> <span class=ow>in</span> <span class=n>st</span><span class=o>.</span><span class=n>session_state</span><span class=o>.</span><span class=n>chat_history</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;**Q:** </span><span class=si>{</span><span class=n>user_q</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;**A:** </span><span class=si>{</span><span class=n>ai_a</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>st</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&#34;---&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 임시 파일 삭제</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>unlink</span><span class=p>(</span><span class=n>tmp_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>st</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;PDF 파일을 업로드하면 해당 문서에 대해 질문할 수 있습니다.&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>이 애플리케이션은 사용자가 PDF 파일을 업로드하면 해당 문서의 내용을 기반으로 질문에 답변합니다. 문서는 청크(chunk)로 분할되어 벡터 데이터베이스에 저장되고, 사용자 질문과 관련된 문서 조각을 검색하여 답변을 생성합니다.</p><h3 id=7-llm-성능-최적화-및-비용-효율화>7. LLM 성능 최적화 및 비용 효율화<a hidden class=anchor aria-hidden=true href=#7-llm-성능-최적화-및-비용-효율화>#</a></h3><p>LLM을 실제 서비스에 적용할 때는 성능과 비용 모두를 고려해야 합니다. 여기서는 LLM 활용 시 성능을 최적화하고 비용을 절감하는 방법을 알아보겠습니다.</p><h4 id=토큰-사용량-최적화>토큰 사용량 최적화<a hidden class=anchor aria-hidden=true href=#토큰-사용량-최적화>#</a></h4><p>LLM API 사용 시 비용은 주로 토큰 사용량에 따라 결정된다.</p><p>토큰 사용을 최적화하는 방법을 살펴보면:</p><ol><li><p><strong>프롬프트 최적화</strong>:</p><ul><li>간결하면서도 명확한 지시 제공</li><li>불필요한 맥락 제거</li><li>필요한 정보만 포함</li></ul></li><li><p><strong>청크 크기 관리</strong>:</p><ul><li>RAG 시스템에서 문서 청크 크기를 적절히 조정</li><li>너무 크면 관련 없는 정보가 포함되고, 너무 작으면 맥락이 손실됨</li></ul></li><li><p><strong>토큰 카운팅 도구 활용</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-11-1><a class=lnlinks href=#hl-11-1>1</a>
</span><span class=lnt id=hl-11-2><a class=lnlinks href=#hl-11-2>2</a>
</span><span class=lnt id=hl-11-3><a class=lnlinks href=#hl-11-3>3</a>
</span><span class=lnt id=hl-11-4><a class=lnlinks href=#hl-11-4>4</a>
</span><span class=lnt id=hl-11-5><a class=lnlinks href=#hl-11-5>5</a>
</span><span class=lnt id=hl-11-6><a class=lnlinks href=#hl-11-6>6</a>
</span><span class=lnt id=hl-11-7><a class=lnlinks href=#hl-11-7>7</a>
</span><span class=lnt id=hl-11-8><a class=lnlinks href=#hl-11-8>8</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>GPT2Tokenizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>GPT2Tokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;gpt2&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;이 텍스트는 몇 개의 토큰으로 구성될까요?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;토큰 수: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;토큰 목록: </span><span class=si>{</span><span class=n>tokens</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;디코딩된 토큰: </span><span class=si>{</span><span class=p>[</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>([</span><span class=n>token</span><span class=p>])</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>캐싱 활용</strong>:</p><ul><li>동일한 쿼리에 대한 응답 캐싱</li><li>사용자 세션 간 컨텍스트 재사용</li></ul></li></ol><h4 id=추론-최적화>추론 최적화<a hidden class=anchor aria-hidden=true href=#추론-최적화>#</a></h4><p>모델 추론 과정을 최적화하여 응답 시간과 자원 사용을 개선할 수 있다:</p><ol><li><p><strong>모델 크기 선택</strong>:</p><ul><li>작업 복잡성에 맞는 적절한 크기의 모델 선택</li><li>간단한 작업에는 작은 모델(GPT-3.5 등) 사용</li><li>복잡한 추론이 필요한 작업에만 대형 모델(GPT-4 등) 사용</li></ul></li><li><p><strong>배치 처리</strong>:</p><ul><li>여러 쿼리를 배치로 처리하여 API 호출 최소화</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-12-1><a class=lnlinks href=#hl-12-1> 1</a>
</span><span class=lnt id=hl-12-2><a class=lnlinks href=#hl-12-2> 2</a>
</span><span class=lnt id=hl-12-3><a class=lnlinks href=#hl-12-3> 3</a>
</span><span class=lnt id=hl-12-4><a class=lnlinks href=#hl-12-4> 4</a>
</span><span class=lnt id=hl-12-5><a class=lnlinks href=#hl-12-5> 5</a>
</span><span class=lnt id=hl-12-6><a class=lnlinks href=#hl-12-6> 6</a>
</span><span class=lnt id=hl-12-7><a class=lnlinks href=#hl-12-7> 7</a>
</span><span class=lnt id=hl-12-8><a class=lnlinks href=#hl-12-8> 8</a>
</span><span class=lnt id=hl-12-9><a class=lnlinks href=#hl-12-9> 9</a>
</span><span class=lnt id=hl-12-10><a class=lnlinks href=#hl-12-10>10</a>
</span><span class=lnt id=hl-12-11><a class=lnlinks href=#hl-12-11>11</a>
</span><span class=lnt id=hl-12-12><a class=lnlinks href=#hl-12-12>12</a>
</span><span class=lnt id=hl-12-13><a class=lnlinks href=#hl-12-13>13</a>
</span><span class=lnt id=hl-12-14><a class=lnlinks href=#hl-12-14>14</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 배치 처리 예시</span>
</span></span><span class=line><span class=cl><span class=n>messages_batch</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;파리는 어느 나라의 수도인가요?&#34;</span><span class=p>}],</span>
</span></span><span class=line><span class=cl>    <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;케냐의 수도는 어디인가요?&#34;</span><span class=p>}],</span>
</span></span><span class=line><span class=cl>    <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;일본의 수도는 어디인가요?&#34;</span><span class=p>}]</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span>  <span class=n>s</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>messages</span> <span class=ow>in</span> <span class=n>messages_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>ChatCompletion</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-3.5-turbo&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=n>messages</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>responses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>스트리밍 활용</strong>:</p><ul><li>긴 응답의 경우 스트리밍 API 사용으로 사용자 경험 개선</li><li>초기 응답 시간 단축 및 UX 향상</li></ul></li></ol><h4 id=오픈소스-모델-활용>오픈소스 모델 활용<a hidden class=anchor aria-hidden=true href=#오픈소스-모델-활용>#</a></h4><p>비용 절감을 위해 오픈소스 모델을 활용하는 방법도 있다:</p><ol><li><p><strong>로컬 배포 옵션</strong>:</p><ul><li>Llama 2, Mistral 등의 오픈소스 모델을 로컬 환경이나 자체 서버에 배포</li><li>양자화(Quantization)를 통한 경량화 활용</li></ul></li><li><p><strong>Hugging Face 모델 활용</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-13-1><a class=lnlinks href=#hl-13-1>1</a>
</span><span class=lnt id=hl-13-2><a class=lnlinks href=#hl-13-2>2</a>
</span><span class=lnt id=hl-13-3><a class=lnlinks href=#hl-13-3>3</a>
</span><span class=lnt id=hl-13-4><a class=lnlinks href=#hl-13-4>4</a>
</span><span class=lnt id=hl-13-5><a class=lnlinks href=#hl-13-5>5</a>
</span><span class=lnt id=hl-13-6><a class=lnlinks href=#hl-13-6>6</a>
</span><span class=lnt id=hl-13-7><a class=lnlinks href=#hl-13-7>7</a>
</span><span class=lnt id=hl-13-8><a class=lnlinks href=#hl-13-8>8</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>pipeline</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 텍스트 생성 파이프라인 초기화</span>
</span></span><span class=line><span class=cl><span class=n>generator</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span><span class=s1>&#39;text-generation&#39;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s1>&#39;mistralai/Mistral-7B-Instruct-v0.1&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 텍스트 생성</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>generator</span><span class=p>(</span><span class=s2>&#34;당신의 이름은 무엇인가요?&#34;</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;generated_text&#39;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>셀프 호스팅 솔루션</strong>:</p><ul><li>LM Studio, Ollama, LocalAI 등의 도구를 활용한 로컬 모델 실행</li><li>클라우드 비용 없이 API 형태로 모델 활용 가능</li></ul></li><li><p><strong>하이브리드 접근법</strong>:</p><ul><li>단순 작업은 로컬 모델로, 복잡한 작업은 클라우드 API로 처리</li><li>중요도와 복잡성에 따라 다양한 모델 활용</li></ul></li></ol><h3 id=llm의-한계와-윤리적-고려사항>LLM의 한계와 윤리적 고려사항<a hidden class=anchor aria-hidden=true href=#llm의-한계와-윤리적-고려사항>#</a></h3><p>LLM은 강력한 도구이지만, 여러 한계와 윤리적 문제도 존재한다.<br>개발자로서 이러한 측면을 이해하고 대응하는 것이 중요하다.</p><h4 id=기술적-한계>기술적 한계<a hidden class=anchor aria-hidden=true href=#기술적-한계>#</a></h4><ol><li><strong>환각(Hallucination)</strong>:<ul><li>LLM은 사실이 아닌 정보를 사실인 것처럼 자신감 있게 제시할 수 있다.</li><li>해결 방안:<ul><li>RAG 시스템 활용하여 외부 지식 제공</li><li>모델 출력 검증 메커니즘 구현</li><li>사용자에게 정보의 불확실성 전달</li></ul></li></ul></li><li><strong>컨텍스트 윈도우 제한</strong>:<ul><li>모델이 한 번에 처리할 수 있는 텍스트 길이에 제한이 있다.</li><li>해결 방안:<ul><li>긴 텍스트는 청크로 분할하여 처리</li><li>요약 기법 활용</li><li>최신 확장 컨텍스트 모델 활용(Claude, GPT-4 Turbo 등)</li></ul></li></ul></li><li><strong>최신 정보 부족</strong>:<ul><li>모델은 학습 데이터 이후의 정보를 알지 못한다.</li><li>해결 방안:<ul><li>RAG 시스템으로 최신 정보 제공</li><li>정기적인 모델 업데이트</li><li>데이터 시한성 명시</li></ul></li></ul></li></ol><h4 id=윤리적-고려사항>윤리적 고려사항<a hidden class=anchor aria-hidden=true href=#윤리적-고려사항>#</a></h4><ol><li><strong>편향성과 공정성</strong>:<ul><li>LLM은 학습 데이터에 존재하는 사회적, 문화적 편향을 반영할 수 있다.</li><li>대응 방안:<ul><li>다양한 데이터로 파인튜닝</li><li>편향 감지 및 평가 도구 활용</li><li>시스템 출력 모니터링 및 피드백 수집</li></ul></li></ul></li><li><strong>개인 정보 보호</strong>:<ul><li>LLM은 학습 데이터에 포함된 개인 정보를 노출하거나, 사용자 데이터를 유출할 위험이 있다.</li><li>보호 방안:<ul><li>개인 정보 필터링 및 마스킹</li><li>데이터 최소화 원칙 적용</li><li>명확한 개인정보 처리방침 제공</li></ul></li></ul></li><li><strong>오용 가능성</strong>:<ul><li>LLM은 가짜 뉴스 생성, 사기, 스팸 등 악의적 목적으로 사용될 수 있다.</li><li>방지 방안:<ul><li>사용 제한 및 모니터링</li><li>출력 필터링 및 안전 가드레일 구현</li><li>사용자 교육 및 가이드라인 제공</li></ul></li></ul></li></ol><h4 id=안전-가드레일-구현>안전 가드레일 구현<a hidden class=anchor aria-hidden=true href=#안전-가드레일-구현>#</a></h4><p>LLM 애플리케이션에 안전 장치를 구현하는 방법:</p><ol><li><p><strong>입력 필터링</strong>:</p><ul><li>유해하거나 부적절한 프롬프트 감지 및 차단</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-14-1><a class=lnlinks href=#hl-14-1> 1</a>
</span><span class=lnt id=hl-14-2><a class=lnlinks href=#hl-14-2> 2</a>
</span><span class=lnt id=hl-14-3><a class=lnlinks href=#hl-14-3> 3</a>
</span><span class=lnt id=hl-14-4><a class=lnlinks href=#hl-14-4> 4</a>
</span><span class=lnt id=hl-14-5><a class=lnlinks href=#hl-14-5> 5</a>
</span><span class=lnt id=hl-14-6><a class=lnlinks href=#hl-14-6> 6</a>
</span><span class=lnt id=hl-14-7><a class=lnlinks href=#hl-14-7> 7</a>
</span><span class=lnt id=hl-14-8><a class=lnlinks href=#hl-14-8> 8</a>
</span><span class=lnt id=hl-14-9><a class=lnlinks href=#hl-14-9> 9</a>
</span><span class=lnt id=hl-14-10><a class=lnlinks href=#hl-14-10>10</a>
</span><span class=lnt id=hl-14-11><a class=lnlinks href=#hl-14-11>11</a>
</span><span class=lnt id=hl-14-12><a class=lnlinks href=#hl-14-12>12</a>
</span><span class=lnt id=hl-14-13><a class=lnlinks href=#hl-14-13>13</a>
</span><span class=lnt id=hl-14-14><a class=lnlinks href=#hl-14-14>14</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>check_prompt_safety</span><span class=p>(</span><span class=n>prompt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;프롬프트의 안전성을 확인하는 함수&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 간단한 키워드 기반 필터링 (실제로는 더 정교한 방법 필요)</span>
</span></span><span class=line><span class=cl>    <span class=n>harmful_keywords</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;해킹&#34;</span><span class=p>,</span> <span class=s2>&#34;불법&#34;</span><span class=p>,</span> <span class=s2>&#34;공격&#34;</span><span class=p>,</span> <span class=s2>&#34;상해&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>keyword</span> <span class=ow>in</span> <span class=n>harmful_keywords</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>keyword</span> <span class=ow>in</span> <span class=n>prompt</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=kc>False</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;부적절한 키워드 &#39;</span><span class=si>{</span><span class=n>keyword</span><span class=si>}</span><span class=s2>&#39;가 포함되어 있습니다.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 또는 콘텐츠 필터링 API 사용</span>
</span></span><span class=line><span class=cl>    <span class=c1># response = openai.Moderation.create(input=prompt)</span>
</span></span><span class=line><span class=cl>    <span class=c1># return not response.results[0].flagged, &#34;콘텐츠 정책에 위배됩니다.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=kc>True</span><span class=p>,</span> <span class=s2>&#34;안전한 프롬프트입니다.&#34;</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>출력 필터링</strong>:</p><ul><li>모델 응답의 안전성 검사</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-15-1><a class=lnlinks href=#hl-15-1>1</a>
</span><span class=lnt id=hl-15-2><a class=lnlinks href=#hl-15-2>2</a>
</span><span class=lnt id=hl-15-3><a class=lnlinks href=#hl-15-3>3</a>
</span><span class=lnt id=hl-15-4><a class=lnlinks href=#hl-15-4>4</a>
</span><span class=lnt id=hl-15-5><a class=lnlinks href=#hl-15-5>5</a>
</span><span class=lnt id=hl-15-6><a class=lnlinks href=#hl-15-6>6</a>
</span><span class=lnt id=hl-15-7><a class=lnlinks href=#hl-15-7>7</a>
</span><span class=lnt id=hl-15-8><a class=lnlinks href=#hl-15-8>8</a>
</span><span class=lnt id=hl-15-9><a class=lnlinks href=#hl-15-9>9</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>filter_response</span><span class=p>(</span><span class=n>response</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;모델 응답을 필터링하는 함수&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 모더레이션 API를 통한 검사</span>
</span></span><span class=line><span class=cl>    <span class=n>moderation</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>Moderation</span><span class=o>.</span><span class=n>create</span><span class=p>(</span><span class=nb>input</span><span class=o>=</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>moderation</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>flagged</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;죄송합니다. 적절한 응답을 제공할 수 없습니다.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>사용자 피드백 메커니즘</strong>:</p><ul><li>부적절한 응답 신고 기능 구현</li><li>피드백을 통한 지속적 개선</li></ul></li><li><p><strong>사용 정책 및 가이드라인</strong>:</p><ul><li>명확한 사용 제한 및 가이드라인 제시</li><li>투명한 정보 처리 방침 제공</li></ul></li></ol><h3 id=llm-발전-동향-및-미래-전망>LLM 발전 동향 및 미래 전망<a hidden class=anchor aria-hidden=true href=#llm-발전-동향-및-미래-전망>#</a></h3><p>LLM 기술은 빠르게 발전하고 있다.</p><h4 id=최신-연구-동향>최신 연구 동향<a hidden class=anchor aria-hidden=true href=#최신-연구-동향>#</a></h4><ol><li><strong>효율성 향상</strong>:<ul><li>모델 크기는 유지하면서 학습 및 추론 효율성 개선</li><li>지식 증류(Knowledge Distillation)를 통한 소형 모델 성능 향상</li><li>희소 모델(Sparse Models)과 혼합 전문가 모델(Mixture of Experts) 연구</li></ul></li><li><strong>멀티모달 통합</strong>:<ul><li>텍스트, 이미지, 오디오, 비디오 등 다양한 모달리티 처리</li><li>GPT-4V, Claude 3, Gemini와 같은 통합 모델 등장</li><li>다중 감각 이해 및 추론 능력 강화</li></ul></li><li><strong>장기 맥락 이해</strong>:<ul><li>컨텍스트 윈도우 확장 (8K → 32K → 100K+ 토큰)</li><li>재귀적 요약 및 압축 메커니즘</li><li>계층적 메모리 구조 연구</li></ul></li><li><strong>추론 능력 강화</strong>:<ul><li>Chain-of-Thought, Tree-of-Thought와 같은 복잡한 추론 기법</li><li>외부 도구 활용 능력 향상</li><li>수학적, 논리적 문제 해결 능력 개선</li></ul></li></ol><h4 id=산업-응용의-확장>산업 응용의 확장<a hidden class=anchor aria-hidden=true href=#산업-응용의-확장>#</a></h4><ol><li><strong>특화된 도메인 모델</strong>:<ul><li>의료, 법률, 금융 등 특정 분야에 특화된 LLM</li><li>도메인 지식으로 파인튜닝된 전문가 시스템</li><li>규제 준수 및 산업 표준 통합</li></ul></li><li><strong>기업 내부 LLM</strong>:<ul><li>기업 데이터로 학습된 비공개 모델</li><li>내부 지식베이스와 통합</li><li>민감한 정보 처리를 위한 보안 강화 모델</li></ul></li><li><strong>개인화된 AI 어시스턴트</strong>:<ul><li>사용자 선호도와 습관을 학습하는 맞춤형 AI</li><li>장기 기억 및 개인 생활 맥락 이해</li><li>다양한 디바이스에 걸친 일관된 사용자 경험</li></ul></li></ol><h4 id=초보-개발자를-위한-접근-방향>초보 개발자를 위한 접근 방향<a hidden class=anchor aria-hidden=true href=#초보-개발자를-위한-접근-방향>#</a></h4><p>LLM 분야에 입문하는 개발자가 앞으로 집중해야 할 방향은 다음과 같다:</p><ol><li><strong>기본 NLP 이해 강화</strong>:<ul><li>언어 모델의 기본 원리 학습</li><li>토큰화, 임베딩, 어텐션 메커니즘 이해</li><li>평가 지표 및 벤치마크 파악</li></ul></li><li><strong>특화된 영역 개발</strong>:<ul><li>특정 산업이나 영역에 LLM을 적용하는 전문성 개발</li><li>도메인 지식과 AI 기술 결합</li><li>실제 문제 해결에 중점</li></ul></li><li><strong>오픈소스 참여</strong>:<ul><li>Hugging Face, LangChain 등의 오픈소스 생태계 참여</li><li>공개 모델 개선 및 파인튜닝 실험</li><li>커뮤니티 협업 및 지식 공유</li></ul></li><li><strong>윤리적 AI 개발</strong>:<ul><li>책임 있는 AI 개발 원칙 학습</li><li>편향 감지 및 완화 기술 연구</li><li>투명성과 설명 가능성 중시</li></ul></li></ol><hr><h2 id=용어-정리>용어 정리<a hidden class=anchor aria-hidden=true href=#용어-정리>#</a></h2><table><thead><tr><th>용어</th><th>설명</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><hr><h2 id=참고-및-출처>참고 및 출처<a hidden class=anchor aria-hidden=true href=#참고-및-출처>#</a></h2></div></main><footer class=footer><span>&copy; 2025 <a href=https://buenhyden.github.io/>hyunyoun's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>